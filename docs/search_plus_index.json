{"./":{"url":"./","title":"前言","keywords":"","body":"Introduction new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/":{"url":"notes/20.10/","title":"20.10","keywords":"","body":" java热部署原理及实践 jvm markdown标题数字.md maven vscode插件 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/java热部署原理及实践/":{"url":"notes/20.10/java热部署原理及实践/","title":"java热部署原理及实践","keywords":"","body":" Java实现热部署（一）：类加载机制以及简单热部署的实现.md Java实现热部署（二）：java类加载过程代码分析.md Java实现热部署（四）：热部署插件分析.md agent源码.md attach源码.md java实现热部署（三）：agent instrumentation attach等手段实现方法体级别的热替换.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/java热部署原理及实践/Java实现热部署（一）：类加载机制以及简单热部署的实现.html":{"url":"notes/20.10/java热部署原理及实践/Java实现热部署（一）：类加载机制以及简单热部署的实现.html","title":"Java实现热部署（一）：类加载机制以及简单热部署的实现.md","keywords":"","body":" 类加载机制以及热部署的实现 类加载器 类加载时机与过程 类加载器种类 类加载器特性 双亲委派模型 自定义类加载器 MyClassLoader 测试类 通过main方法调用 类似springboot启动的方式 [TOC] 类加载机制以及热部署的实现 回顾一下Java类加载相关的知识点，主要是类加载器，加载模型等。并且实现一个小的Java热部署的demo 类加载器 类加载时机与过程 类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)7个阶段。其中准备、验证、解析3个部分统称为连接（Linking）。如图所示 加载过程中的一些概念详见：https://juejin.im/post/6844903887866953735 类加载器种类 Bootstrap ClassLoader/启动类加载器 主要负责jdk_home/lib目录下的核心 api 或 -Xbootclasspath 选项指定的jar包装入工作。 Extension ClassLoader/扩展类加载器 主要负责jdk_home/lib/ext目录下的jar包或 -Djava.ext.dirs 指定目录下的jar包装入工作。 Application ClassLoader/应用程序类加载器 负责加载用户类路径（classpath）上的指定类库，我们可以直接使用这个类加载器。一般情况，如果我们没有自定义类加载器默认就是用这个加载器。 User Custom ClassLoader/用户自定义类加载器(java.lang.ClassLoader的子类) 在程序运行期间, 通过java.lang.ClassLoader的子类动态加载class文件, 体现java动态实时类装入特性。 一个class文件发送请求加载,会先找到自定义的类加载器,当然这里没画出来 APPClassLoader得到加载器请求后,向上委托交给ExtClassLoader,ExtClassLoader同理会交给BoostrapClassLoader,这是向上委托方向 最终到达BoostrapClassLoader,会先在缓存中找,没有就尝试在自己能加载的路径去加载,找不到就交给ExtClassLoader,同理一直到用户自定义的ClassLoader,这就是向下查找方向 前面说的类的唯一性由类和类加载器共同决定, 这样保证了确保了类的唯一性 类加载器特性 每个ClassLoader都维护了一份自己的名称空间， 同一个名称空间里不能出现两个同名的类。 为了实现java安全沙箱模型顶层的类加载器安全机制， java默认采用了 \" 双亲委派的加载链 \" 结构。 双亲委派模型 什么是双亲委派模型？ 双亲委派模型工作过程是：如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即ClassNotFoundException），子加载器才会尝试自己去加载。 为什么需要双亲委派模型？ 假设没有双亲委派模型，试想一个场景： 黑客自定义一个java.lang.String类，该String类具有系统的String类一样的功能，只是在某个函数稍作修改。比如equals函数，这个函数经常使用，如果在这这个函数中，黑客加入一些“病毒代码”。并且通过自定义类加载器加入到JVM中。此时，如果没有双亲委派模型，那么JVM就可能误以为黑客自定义的java.lang.String类是系统的String类，导致“病毒代码”被执行。 而有了双亲委派模型，黑客自定义的java.lang.String类永远都不会被加载进内存。因为首先是最顶端的类加载器加载系统的java.lang.String类，最终自定义的类加载器无法加载java.lang.String类。 或许你会想，我在自定义的类加载器里面强制加载自定义的java.lang.String类，不去通过调用父加载器不就好了吗?确实，这样是可行。但是，在JVM中，判断一个对象是否是某个类型时，如果该对象的实际类型与待比较的类型的类加载器不同，那么会返回false。 举个简单例子： ClassLoader1、ClassLoader2都加载java.lang.String类，对应Class1、Class2对象。那么Class1对象不属于ClassLoad2对象加载的java.lang.String类型。 线程上下文类加载器? 如何打破双亲委派模型？ 自定义一个classLoader重写loadClass() 自定义类加载器 MyClassLoader 下面我们定义一个ClassLoader，我这里是重写的findClass()方法。使用commons.io.monitor来监听文件夹，如果class文件变动则动态的加载到JVM中。 ClassLoader的相关代码在这篇文章：https://blog.csdn.net/it_zhonghua/article/details/109243855 public class MyClassLoader extends ClassLoader { public String rootPath; public String[] classPaths; public List clazzs; public MyClassLoader(String rootPath, String... classPaths) throws Exception { this.rootPath = rootPath; clazzs = new ArrayList<>(); this.classPaths = classPaths; for (String classPath : classPaths) { this.findClass(classPath); } } @Override protected Class findClass(String name) throws ClassNotFoundException { Class clazz = findLoadedClass(name); if (clazz == null) { File file = new File(name); if (file.isDirectory()) { for (File f : Objects.requireNonNull(file.listFiles())) { this.findClass(f.getPath()); } } else { try { String fileName = file.getName(); String filePath = file.getPath(); String endName = fileName.substring(fileName.lastIndexOf(\".\") + 1); if (endName.equals(\"class\")) { FileInputStream fileInputStream = new FileInputStream(file); byte[] bytes = new byte[(int) file.length()]; fileInputStream.read(bytes); String className = filePath.replace(rootPath, \"\").replaceAll(\"/\", \".\"); className = className.substring(1, className.lastIndexOf(\".\")); clazzs.add(className); // class文件已经到了虚拟机了 return defineClass(className, bytes, 0, bytes.length); } } catch (Exception e) { return super.findClass(name); } } } return clazz; } } 测试类 public class Test { public Test() { } public void hello() { System.out.println(\"test 1.0\"); System.out.println(\"当前使用的类加载器是：\" + getClass().getClassLoader()); } } 通过main方法调用 public static void main(String[] args) throws Exception { // 模拟一个web项目，一直运行。如果是一个web项目，可以提供一个接口，调用接口就reload。 while (true) { // 同一个classloader只会存在同一个类的一份class，所以如果需要替换之前的class需要new一个classloader。 String path = MyClassLoader.class.getResource(\"/\").getPath().replaceAll(\"%20\", \" \"); String rootPath = new File(path).getPath(); MyClassLoader myClassLoader = new MyClassLoader(rootPath, rootPath + \"/dsvshx\"); Class aClass = myClassLoader.loadClass(\"dsvshx.Test\"); Object o = aClass.newInstance(); aClass.getMethod(\"hello\").invoke(o); // 这种方式的话new一个对象的方式还是不能使用热加载的类。如何改变new的对象的classloader？ new Test().hello(); Thread.sleep(2000); } // 全盘委托 该方法所述的类是由哪个类加载器加载的，那么这个方法中new出来的对象也都是由改类加载器加载的。 } 下面查看hello()方法打印出来的日志： test 1.0 当前使用的类加载器是：dsvshx.loader.MyClassLoader@60e53b93 test 1.0 当前使用的类加载器是：sun.misc.Launcher$AppClassLoader@18b4aac2 现在修改一下1.0变成2.0然后编译一下。 test 2.0 当前使用的类加载器是：dsvshx.loader.MyClassLoader@4ccabbaa test 1.0 当前使用的类加载器是：sun.misc.Launcher$AppClassLoader@18b4aac2 下面我们来分析一下。前两行是通过自己的类加载器加载之后反射出来的。后两行new出来的对象还是用应用类加载器。这里就涉及到了jvm类加载的另一个特性：全盘委派。 “全盘委派”是指当一个ClassLoader装载一个类时，除非显示地使用另一个ClassLoader，则该类所依赖及引用的类也由这个CladdLoader载入。 例如，系统类加载器AppClassLoader加载入口类（含有main方法的类）时，会把main方法所依赖的类及引用的类也载入，依此类推。“全盘负责”机制也可称为当前类加载器负责机制。显然，入口类所依赖的类及引用的类的当前类加载器就是入口类的类加载器。 所以第二个new的对象并没有实现热加载。使用的还是之前的class文件。那么怎么打破全盘委派的影响呢。其实可以参考springboot这种框架的启动方式。具体思路就是不使用main方法来启动应用，而是通过自定义的加载器加载入口类，在通过反射的方式来启动应用入口。这样启动入口就是通过自定义加载器加载，过程中用到的类也会通过自定义的加载器来加载。 类似springboot启动的方式 public class Application { public static String rootPath; public static void run(Class clazz) throws Exception { String path = clazz.getResource(\"/\").getPath().replaceAll(\"%20\", \" \"); String rootPath = new File(path).getPath(); Application.rootPath = rootPath; FileLisener.startFileMino(rootPath); MyClassLoader myClassLoader = new MyClassLoader(rootPath, rootPath + \"/dsvshx\"); start0(myClassLoader); } public void start() { System.out.println(\"启动。。。。。。。。。\"); Test test = new Test(); test.hello(); System.out.println(Test.class.getClassLoader()); } public static void start0(MyClassLoader myClassLoader) throws Exception { Class aClass = myClassLoader.loadClass(\"dsvshx.Application\"); Object o = aClass.newInstance(); aClass.getMethod(\"start\").invoke(o); } public static void main(String[] args) throws Exception { Application.run(MyClassLoader.class); } } public class FileLisener extends FileAlterationListenerAdaptor { @Override public void onFileChange(File file) { if (file.getPath().contains(\".class\")) { try { MyClassLoader myClassLoader = new MyClassLoader(Application.rootPath, Application.rootPath + \"/dsvshx\"); Application.start0(myClassLoader); } catch (Exception e) { e.printStackTrace(); } } } public static void startFileMino(String rootPath) throws Exception{ FileAlterationObserver fileAlterationObserver = new FileAlterationObserver(rootPath); fileAlterationObserver.addListener(new FileLisener()); FileAlterationMonitor fileAlterationMonitor = new FileAlterationMonitor(5000); fileAlterationMonitor.addObserver(fileAlterationObserver); fileAlterationMonitor.start(); } } 以上模拟了一个简单的demo，使用filelisener来监听文件夹，如果变动了则使用自定义的加载器来重新加载该class文件。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/java热部署原理及实践/Java实现热部署（二）：java类加载过程代码分析.html":{"url":"notes/20.10/java热部署原理及实践/Java实现热部署（二）：java类加载过程代码分析.html","title":"Java实现热部署（二）：java类加载过程代码分析.md","keywords":"","body":"从Launcher看起 ExtClassLoader 和 AppClassLoader不是继承关系，而是通过指定 parent 属性来形成的组合模型 public Launcher() { Launcher.ExtClassLoader var1; try { // 获取扩展类加载器，getExtClassLoader()是用了double check的单例模式，和之前背过的东西相遇了。 var1 = Launcher.ExtClassLoader.getExtClassLoader(); } catch (IOException var10) { throw new InternalError(\"Could not create extension class loader\", var10); } try { // 获取应用类加载器，并且吧拓展类加载器设置成parent this.loader = Launcher.AppClassLoader.getAppClassLoader(var1); } catch (IOException var9) { throw new InternalError(\"Could not create application class loader\", var9); } // 指定APPClassloader为线程上下文加载器 Thread.currentThread().setContextClassLoader(this.loader); String var2 = System.getProperty(\"java.security.manager\"); if (var2 != null) { SecurityManager var3 = null; if (!\"\".equals(var2) && !\"default\".equals(var2)) { try { // 调用loadClass var3 = (SecurityManager)this.loader.loadClass(var2).newInstance(); } catch (IllegalAccessException var5) { } catch (InstantiationException var6) { } catch (ClassNotFoundException var7) { } catch (ClassCastException var8) { } } else { var3 = new SecurityManager(); } if (var3 == null) { throw new InternalError(\"Could not create SecurityManager: \" + var2); } System.setSecurityManager(var3); } } private static volatile Launcher.ExtClassLoader instance; public static Launcher.ExtClassLoader getExtClassLoader() throws IOException { if (instance == null) { Class var0 = Launcher.ExtClassLoader.class; synchronized(Launcher.ExtClassLoader.class) { if (instance == null) { instance = createExtClassLoader(); } } } return instance; } ```java protected Class loadClass(String name, boolean resolve) throws ClassNotFoundException { // 方法有同步块（synchronized）,多线程情况不会出现重复加载的情况。 synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { // 如果父类加载器不为空则使用父类加载器来加载。 if (parent != null) { c = parent.loadClass(name, false); } else { // parent为空，交给BootstrapClassLoader c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } ```new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/java热部署原理及实践/Java实现热部署（四）：热部署插件分析.html":{"url":"notes/20.10/java热部署原理及实践/Java实现热部署（四）：热部署插件分析.html","title":"Java实现热部署（四）：热部署插件分析.md","keywords":"","body":" 插件介绍 代码分析 agent boot core registry web 插件介绍 介绍一个插件，插件地址：https://github.com/liuzhengyang/lets-hotfix。这个插件可以实现热部署，插件的原理原理和前几篇文章中说的原理是一样的。这个插件的具体的使用方式在GitHub上面有详细的说明。插件可以在网页端使用也可以安装idea插件进行热部署。 代码分析 GitHub中的代项目目录大致分成了这几个部分，我们来一个一个分析。整体的结构和实现的功能图如下： agent 这部分原理很好懂，之前我们也讲到过。这里插件实现的主要功能就是通过后端传递过来的文件名找到对应的文件（文件已经被后端下载到指定的文件夹下）。如果是Java文件则编译成class文件在进行下一步操作。接下来需要看该类是不是已经被加载过了，如果被加载过的话则调用instrumentation.redefineClasses()，如果该类是个新的类则调用defineClass(className, bytes, 0, bytes.length);定义新的类。所以由于这里的限制，该插件可以添加一个新类或者修改方法体但是不能增加方法或者字段。 boot 该部分的主要作用是在服务器部署服务，并且把agent文件保存到本地。起到初始化项目的作用。 core 这部分主要是用到的一些工具类，比如编译工具。 registry 就是一个eureka的注册中心。 web web这部分比较重要，大部分的逻辑集中在这个地方。首先有一个前端界面，可以选择上传一个文件，选择相应的进程，这样就可以实现热部署。 后端收到文件之后，会保存到一个临时文件夹下，之后会通过attach调用agent，把文件路径传给agent，agent收到之后会读取文件并进行热部署的相关工作。 以上就是我对lets hotfix的一些理解，感谢大佬的开源，这个工具也确实能节省很多的时间和人力成本。我也添加了一些测试，以及前几篇文章里的一些测试用例我都上传到了我fork的仓库下了，欢迎大家提出建议：https://github.com/dongzhonghua/lets-hotfix。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/java热部署原理及实践/agent源码.html":{"url":"notes/20.10/java热部署原理及实践/agent源码.html","title":"agent源码.md","keywords":"","body":"https://www.infoq.cn/article/javaagent-illustrated/new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/java热部署原理及实践/attach源码.html":{"url":"notes/20.10/java热部署原理及实践/attach源码.html","title":"attach源码.md","keywords":"","body":"http://lovestblog.cn/blog/2014/06/18/jvm-attach/new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/java热部署原理及实践/java实现热部署（三）：agent instrumentation attach等手段实现方法体级别的热替换.html":{"url":"notes/20.10/java热部署原理及实践/java实现热部署（三）：agent instrumentation attach等手段实现方法体级别的热替换.html","title":"java实现热部署（三）：agent instrumentation attach等手段实现方法体级别的热替换.md","keywords":"","body":" Instrument agent agent加载 agent premain举例 attach attach api原理 [TOC] Instrument Instrumentation是Java提供的一个来自JVM的接口，该接口提供了一系列查看和操作Java类定义的方法，例如修改类的字节码、向classLoader的classpath下加入jar文件等。使得开发者可以通过Java语言来操作和监控JVM内部的一些状态，进而实现Java程序的监控分析，甚至实现一些特殊功能（如AOP、热部署）。 基于 Instrumentation 来实现的有： APM 产品: pinpoint、skywalking、newrelic、听云的 APM 产品等都基于 Instrumentation 实现 热部署工具：Intellij idea 的 HotSwap、Jrebel 等 Java 诊断工具：Arthas、Btrace 等 由于对字节码修改功能的巨大需求，JDK 从 JDK5 版本开始引入了java.lang.instrument 包。它可以通过 addTransformer 方法设置一个 ClassFileTransformer，可以在这个 ClassFileTransformer 实现类的转换。 JDK 1.5 支持静态 Instrumentation，基本的思路是在 JVM 启动的时候添加一个代理（javaagent），每个代理是一个 jar 包，其 MANIFEST.MF 文件里指定了代理类，这个代理类包含一个 premain 方法。JVM 在类加载时候会先执行代理类的 premain 方法，再执行 Java 程序本身的 main 方法，这就是 premain 名字的来源。在 premain 方法中可以对加载前的 class 文件进行修改。这种机制可以认为是虚拟机级别的 AOP，无需对原有应用做任何修改，就可以实现类的动态修改和增强。 从 JDK 1.6 开始支持更加强大的动态 Instrument，在JVM 启动后通过 Attach API 远程加载。 public interface Instrumentation { /** * 注册一个Transformer，从此之后的类加载都会被Transformer拦截。 * Transformer可以直接对类的字节码byte[]进行修改 */ void addTransformer(ClassFileTransformer transformer); /** * 对JVM已经加载的类重新触发类加载。使用的就是上面注册的Transformer。 * retransformation可以修改方法体，但是不能变更方法签名、增加和删除方法/类的成员属性 */ void retransformClasses(Class... classes) throws UnmodifiableClassException; /** * 获取一个对象的大小 */ long getObjectSize(Object objectToSize); /** * 将一个jar加入到bootstrap classloader的 classpath里 */ void appendToBootstrapClassLoaderSearch(JarFile jarfile); /** * 获取当前被JVM加载的所有类对象 */ Class[] getAllLoadedClasses(); } 其中最常用的方法就是addTransformer(ClassFileTransformer transformer)了，这个方法可以在类加载时做拦截，对输入的类的字节码进行修改，其参数是一个ClassFileTransformer接口，定义如下： /** * 传入参数表示一个即将被加载的类，包括了classloader，classname和字节码byte[] * 返回值为需要被修改后的字节码byte[] */ byte[] transform(ClassLoader loader, String className, Class classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException; addTransformer方法配置之后，后续的类加载都会被Transformer拦截。对于已经加载过的类，可以执行retransformClasses来重新触发这个Transformer的拦截。类加载的字节码被修改后，除非再次被retransform，否则不会恢复。 主流的JVM都提供了Instrumentation的实现，但是鉴于Instrumentation的特殊功能，并不适合直接提供在JDK的runtime里，而更适合出现在Java程序的外层，以上帝视角在合适的时机出现。因此如果想使用Instrumentation功能，拿到Instrumentation实例，我们必须通过Java agent。 agent Java agent是一种特殊的Java程序（Jar文件），它是Instrumentation的客户端。与普通Java程序通过main方法启动不同，agent并不是一个可以单独启动的程序，而必须依附在一个Java应用程序（JVM）上，与它运行在同一个进程中，通过Instrumentation API与虚拟机交互。 Java agent与Instrumentation密不可分，二者也需要在一起使用。因为Instrumentation的实例会作为参数注入到Java agent的启动方法中。 Java agent以jar包的形式部署在JVM中，jar文件的manifest需要指定agent的类名。根据不同的启动时机，agent类需要实现不同的方法（二选一）。 /** * 以vm参数的形式载入，在程序main方法执行之前执行 * 其jar包的manifest需要配置属性Premain-Class */ public static void premain(String agentArgs, Instrumentation inst); /** * 以Attach的方式载入，在Java程序启动后执行 * 其jar包的manifest需要配置属性Agent-Class */ public static void agentmain(String agentArgs, Instrumentation inst); 如果想自己写一个java agent程序，只需定义一个包含premain或者agentmain的类，在方法中实现你的逻辑，然后在打包jar时配置一下manifest即可。可以参考如下的maven plugin配置： maven-assembly-plugin **.**.InstrumentTest **.**..InstrumentTest true true agent加载 一个Java agent既可以在VM启动时加载，也可以在VM启动后加载： 启动时加载：通过vm的启动参数-javaagent:**.jar来启动 启动后加载：启动时加载是有一定的缺点的，因为项目在一开始运行的时候不知道到底要不要使用agent，所以jdk1.6之后可以在vm启动后的任何时间点，通过attach api，动态地启动agent agent加载时，Java agent的jar包先会被加入到system class path中，然后agent的类会被system class loader加载。没错，这个system class loader就是所在的Java程序的class loader，这样agent就可以很容易的获取到想要的class。 对于VM启动时加载的Java agent，其premain方法会在程序main方法执行之前被调用，此时大部分Java类都没有被加载（“大部分”是因为，agent类本身和它依赖的类还是无法避免的会先加载的），是一个对类加载埋点做手脚（addTransformer）的好机会。如果此时premain方法执行失败或抛出异常，那么JVM的启动会被终止。 对于VM启动后加载的Java agent，其agentmain方法会在加载之时立即执行。如果agentmain执行失败或抛出异常，JVM会忽略掉错误，不会影响到正在running的Java程序。 agent premain举例 举例，我想要监听某个类，并对这个类的每个方法都做一层AOP，打印出方法调用的耗时。那么使用Instrumentation的解决方式，就是修改这个类的字节码，对每个方法作如下改动： // 原方法 public void method1(){ dosomething(); } ↓ ↓ ↓ ↓ ↓ // 修改后的方法 public void method1(){ long stime = System.currentTimeMillis(); dosomething(); System.out.println(\"method1 cost:\" + (System.currentTimeMillis() - stime) + \" ms\"); }   要想实现这种效果，我们需要在transform方法的实现中，对指定的类，做指定的字节码增强。通常来说，做字节码增强都需要使用到框架，比如ASM,CGLIB,Byte Buddy,Javassist。不过如果你喜欢，你可以直接用位运算操作byte[]，不需要任何框架，例如JDK反射(method.invoke())的实现，就真的是用位操作拼装了一个类。   言归正传，操作字节码的高手可能更喜欢ASM，因为它提供的方法更底层，功能更强大更直白。对于字节码不熟悉的开发者，更适合javassist，它可以直接以Java代码方式直接修改方法体。我们以javassist为例，看看怎么实现上述的功能。 public class AgentTest { public static void premain(String agentOps, Instrumentation inst) { System.out.println(\"=========premain方法执行========\"); // 添加Transformer inst.addTransformer(new MyTransformer()); System.out.println(agentOps); } public static void main(String[] args) throws InterruptedException { System.out.println(\"=======main方法执行=========\"); } } public class MyTransformer implements ClassFileTransformer { final static String prefix = \"\\nlong startTime = System.currentTimeMillis();\\n\"; final static String postfix = \"\\nlong endTime = System.currentTimeMillis();\\n\"; // 被处理的方法列表 final static Map> methodMap = new HashMap<>(); public MyTransformer() { add(\"dsvshx.agent.TimeTest.sayHello\"); add(\"dsvshx.agent.TimeTest.sayHello2\"); } private void add(String methodString) { String className = methodString.substring(0, methodString.lastIndexOf(\".\")); String methodName = methodString.substring(methodString.lastIndexOf(\".\") + 1); List list = methodMap.computeIfAbsent(className, k -> new ArrayList<>()); list.add(methodName); } @Override public byte[] transform(ClassLoader loader, String className, Class classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) { className = className.replace(\"/\", \".\"); if (methodMap.containsKey(className)) {// 判断加载的class的包路径是不是需要监控的类 CtClass ctclass; try { ctclass = ClassPool.getDefault().get(className);// 使用全称,用于取得字节码类 for (String methodName : methodMap.get(className)) { String outputStr = \"\\nSystem.out.println(\\\"this method \" + methodName + \" cost:\\\" +(endTime - startTime) +\\\"ms.\\\");\"; CtMethod ctmethod = ctclass.getDeclaredMethod(methodName);// 得到这方法实例 String newMethodName = methodName + \"$old\";// 新定义一个方法叫做比如sayHello$old ctmethod.setName(newMethodName);// 将原来的方法名字修改 // 创建新的方法，复制原来的方法，名字为原来的名字 CtMethod newMethod = CtNewMethod.copy(ctmethod, methodName, ctclass, null); // 构建新的方法体 String bodyStr = \"{\" + prefix + newMethodName + \"($$);\\n\"// 调用原有代码，类似于method();($$)表示所有的参数 + postfix + outputStr + \"}\"; newMethod.setBody(bodyStr);// 替换新方法 ctclass.addMethod(newMethod);// 增加新方法 } return ctclass.toBytecode(); } catch (Exception e) { System.out.println(e.getMessage()); e.printStackTrace(); } } return null; } } 测试类： public class TimeTest { public static void main(String[] args) { sayHello(); sayHello2(\"hello world222222222\"); } public static void sayHello() { try { Thread.sleep(2000); System.out.println(\"hello world!!\"); } catch (InterruptedException e) { e.printStackTrace(); } } public static void sayHello2(String hello) { try { Thread.sleep(1000); System.out.println(hello); } catch (InterruptedException e) { e.printStackTrace(); } } } 使用方式，xxx.TimeTest，指定入口，然后打包成jar包，这几个文件可以放在一个项目里，命令以及结果 java -javaagent:xxx.jar=Hello1 -jar xxx.jar =========premain方法执行======== Hello1 hello world!! this method sayHello cost:2002ms. hello world222222222 this method sayHello2 cost:1005ms. attach 上面提到，Java agent可以在JVM启动后再加载，就是通过Attach API实现的。当然，Attach API可不仅仅是为了实现动态加载agent，Attach API其实是跨JVM进程通讯的工具，能够将某种指令从一个JVM进程发送给另一个JVM进程。 加载agent只是Attach API发送的各种指令中的一种， 诸如jstack打印线程栈、jps列出Java进程、jmap做内存dump等功能，都属于Attach API可以发送的指令。 使用attach的方式，不需要实现premain函数，需要attachmain。 public void agentmain(String agentArgs, Instrumentation inst); 由于是进程间通讯，那代表着使用Attach API的程序需要是一个独立的Java程序，通过attach目标进程，与其进行通讯。下面的代码表示了向进程pid为1234的JVM发起通讯，加载一个名为agent.jar的Java agent。 // VirtualMachine等相关Class位于JDK的tools.jar VirtualMachine vm = VirtualMachine.attach(\"1234\"); // 1234表示目标JVM进程pid try { vm.loadAgent(\".../agent.jar\"); // 指定agent的jar包路径，发送给目标进程 } finally { vm.detach(); }   vm.loadAgent之后，相应的agent就会被目标JVM进程加载，并执行agentmain方法。 attach api原理 按惯例，以Hotspot虚拟机，Linux系统为例。当external process执行VirtualMachine.attach时，需要通过操作系统提供的进程通信方法，例如信号、socket，进行握手和通信。其具体内部实现流程如下所示： external process（attach发起的进程） target VM（目标JVM进程，假设pid为XXX） 1. 创建文件：.attach_pidXXX 2. 检查.java_pidXXX 文件是否存在，如果存在则跳过4 3. 向目标JVM发送SIGQUIT信号 → 4. 轮询等待.java_pidXXX 文件的创建（5秒超时） 1. JVM的Signal Dispatcher线程收到SIGQUIT信号 4. 轮询等待 ………… 2. 检查.attach_pidXXX 文件是否存在，若不存在则继续，否则忽略信号 4. 轮询等待 ………… 2. 创建一个新线程Attach Listener，专门负责接收各种attach请求指令 4. 轮询等待 ………… 3. 创建.java_pidXXX文件 4. 轮询等待 ………… 4. 开始监听socket(. java_pidXXX) 5. 尝试连接socket (.java_pidXXX ) 上面提到了两个文件： .attach_pidXXX 后面的XXX代表pid，例如pid为1234则文件名为.attach_pid1234。该文件目的是给目标JVM一个标记，表示触发SIGQUIT信号的是attach请求。这样目标JVM才可以把SIGQUIT信号当做attach连接请求，再来做初始化。其默认全路径为/proc/XXX/cwd/.attach_pidXXX，若创建失败则使用/tmp/attach_pidXXX .java_pidXXX 后面的XXX代表pid，例如pid为1234则文件名为.java_pid1234。由于Unix domain socket通讯是基于文件的，该文件就是表示external process与target VM进行socket通信所使用的文件，如果存在说明目标JVM已经做好连接准备。其默认全路径为/proc/XXX/cwd/.java_pidXXX，若创建失败则使用/tmp/java_pidXXX VirtualMachine.attach动作类似TCP创建连接的三次握手，目的就是搭建attach通信的连接。而后面执行的操作，例如vm.loadAgent，其实就是向这个socket写入数据流，接收方target VM会针对不同的传入数据来做不同的处理。 参考： 谈谈Java Intrumentation和相关应用 https://www.cnblogs.com/aspirant/p/8796974.html new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/jvm/":{"url":"notes/20.10/jvm/","title":"jvm","keywords":"","body":" jvm可视化工具.md jvm的方法区元空间等.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/jvm/jvm可视化工具.html":{"url":"notes/20.10/jvm/jvm可视化工具.html","title":"jvm可视化工具.md","keywords":"","body":" jvisualvm 堆内存溢出 栈内存溢出 死锁检测 jconsole [TOC] jvisualvm和jconsole都是JVM自带的强大的JVM分析工具。在命令行输入相应的命令就可以打开用户界面。 jvisualvm 堆内存溢出 直接使用jvisualvm来分析一个堆内存溢出异常。 设置堆栈信息，设得小一点：-Xms5m -Xmx5m -XX:+HeapDumpOnOutOfMemoryError。这样很快就会有内存溢出了。 import java.util.ArrayList; import java.util.List; public class Main { public static void main(String[] args) { List list = new ArrayList<>(); for( ; ; ) { list.add(new Main()); } } } 使用idea运行之后可以发现堆栈信息已经生成了，现在可以到jvisualvm里面导入。 导入之后的界面是这样的。 还可以看到类的信息。 在这里我们就可以清晰的看出，因为该类实例太多占据97%， 通过分析每一个实例对象可以看到详细信息，比如该类是由Appclassloader加载的，其父是扩展类加载器，在往上是启动类加载器 他也可以进行监控，可以手动执行垃圾回收和dump。 栈内存溢出 设置栈内存为最小值160k方便快速看到效果 -Xss160k public class Main { private int time; public int gettime() { return time; } public void goon() { this.time++; try { Thread.sleep(40); //防止主线程结束太快，不好监测 } catch (InterruptedException e) { e.printStackTrace(); } goon(); } public static void main(String[] args) { Main jtext2 = new Main(); try { jtext2.goon(); } catch (Throwable e) { System.out.println(jtext2.gettime()); e.printStackTrace(); } } } 可以看到，函数循环调用了七百多次之后发生了栈内存溢出。 使用jvisualvm查看线程dump 可以看到main线程的调用堆栈和状态。这样可以初步排查到问题。 死锁检测 public class Main { public static void main(String[] args) { new Thread(new A(), \"Thread-A\").start(); new Thread(new B(), \"Thread-B\").start(); try { Thread.sleep(50000);//不让main线程快速结束，以便进行线程dunmp } catch (InterruptedException e) { e.printStackTrace(); } } } class A implements Runnable { private static final Object lock1 = new Object(); public static void amethod() { synchronized (lock1) { System.out.println(\"进入A\"); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } B.bmethod(); } } @Override public void run() { amethod(); } } class B implements Runnable { private static final Object lock2 = new Object(); public static void bmethod() { synchronized (lock2) { System.out.println(\"进入B\"); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } A.amethod(); } } @Override public void run() { bmethod(); } } jconsole jconsole和jvisualvm类似。我们用jconsole分析一下元空间（方法区）的内存溢出。 在 Java 虚拟机（以下简称JVM）中，类包含其对应的元数据，比如类的层级信息，方法数据和方法信息（如字节码，栈和变量大小），运行时常量池，已确定的符号引用和虚方法表。在过去（当自定义类加载器使用不普遍的时候），类几乎是“静态的”并且很少被卸载和回收，因此类也可以被看成“永久的”。另外由于类作为 JVM 实现的一部分，它们不由程序来创建，因为它们也被认为是“非堆”的内存。在 JDK8 之前的 HotSpot虚拟机中，类的这些“永久的”数据存放在一个叫做永久代的区域。永久代一段连续的内存空间，永久代的垃圾回收和老年代的垃圾回收是绑定的，一旦其中一个区域被占满，这两个区都要进行垃圾回收。 Java8之后，永久代和堆内存已经不连在一起了，元数据被移动到一个在本地内存区域中，该区域称为元空间，J7之前的的hotspot虚拟机中，纳入字符串常量池的字符串被储存在永久代中，因此会导致一系列性能问题和内存溢出问题，而J8中由于改为在本地内存中，所以元空间的内存管理由元空间虚拟机来完成元空间的最大可分配空间就是系统可用内存空间 元空间的内存管理由元空间虚拟机来完成，其采用的形式为组块分配。元空间会被分配给其他类加载器，我们可以这样理解，每个类加载器加载完一个类后，他的命名空间中就多了这个类的信息，对应的元空间虚拟机便会分给该加载器一块区域来保存这个类的元数据，当一个类加载器消亡，他的命名空间不复存在，他对应拥有元空间的组块也全部清除并归还，一旦某个虚拟内存映射区域清空，这部分内存就会返回给操作系统。由于元空间按照组块分配，元空间虚拟机还未支持压缩功能，所以会产生碎片化问题。 接下来通过循环动态生成类，使得新类一直被加载并在元空间中分配区域直到元空间溢出; import org.springframework.cglib.proxy.Enhancer; import org.springframework.cglib.proxy.MethodInterceptor; public class Main { public static void main(String[] args) { for(;;){ Enhancer enhancer = new Enhancer( ) ; enhancer.setSuperclass (Main.class); enhancer.setUseCache(false) ;//是否使用缓存 enhancer.setCallback((MethodInterceptor) (obj, method, args1, proxy) -> proxy. invokeSuper(obj, args1)); System.out.println(\"RUN\"); enhancer.create(); } } } 设置元空间最大内存：-XX:MaxMetaspaceSize=200m 可以看到元空间到达200M之后，程序异常退出。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/jvm/jvm的方法区元空间等.html":{"url":"notes/20.10/jvm/jvm的方法区元空间等.html","title":"jvm的方法区元空间等.md","keywords":"","body":" 方法区？ JDK7 之前 JDK7 JDK8 及以后 为什么移除永久代？ 常量池、运行时常量池、字符串常量池 常量池分类 Class文件常量池 运行时常量池（Constant Pool） String常量池， [TOC] 方法区？ 方法区（Method area）是可供各个线程共享的运行时内存区域，它存储了每一个类的结构信息，相当于把程序中共性的部分抽离出来。 例如：运行时常量池（Runtime constant pool）。字段和方法数据、构造函数和普通方法的字节码内容，还包括一些在类、实例、接口初始化时用到的特殊方法。 方法区在虚拟机启动的时候创建，方法区的容量可以是固定的，也可以随着程序的执行实现动态扩展，并在不需要过多空间的时候自动回收。方法区在实际内存中可以是不连续的。 JDK7 之前 在 JDK 之前，方法区位于永久代（PermGen），永久代和堆相互隔离，永久代的大小在 JVM 中可以设定一个固定值，不可变。方法区是一种jvm的规范，而永久代是一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。 永久代是 Hotspot 虚拟机特有的概念，是方法区的一种实现，别的 JVM 都没有这个东西。永久代与新生代和老年代相样，前者并不是位于堆中，后后两者是位于堆中的。 在这个时候永久代就是方法区的实现，这个时期默认方法区即永久代。在这个时候永久代里面存放了很多东西，例如，符号引用（Symbols）、字符串常量池（interned strings）、类的静态变量（class static variables）、运行时常量池以及其它信息。由于这个时候方法区是由永久代实现的，那么方法区出现异常后会抛出这样的信息：java.lang.OutOfMemoryError: PermGen， 这里的 PermGen 就是永久代的意思，从这个就可以看出此时的方法区的实现是永久代。 JDK7 在这个时候官方以及发现用永久代实现方法区容易导致内存泄漏的问题了，同时为了后面将 Hotspot 虚拟机与其他虚拟机整合，已经有将方法区改用其他的方式类实现了，但是并没有动工！此时只是将原本位于永久代中的字符串常量、类的静态变量池转移到了 Java Heap 中，还有符号引用转移到了 Native Memory 此时你使用 String 类的 intern() 方法，你会发现与 jdk6 及以前出现不一样的 结果。 在 Jdk6 以及以前的版本中，字符串的常量池是放在堆的 Perm 区的，Perm 区是一个类静态的区域，主要存储一些加载类的信息，常量池，方法片段等内容，默认大小只有 4m，一旦常量池中大量使用 intern 是会直接产生 java.lang.OutOfMemoryError:PermGen space 错误的。 JDK8 及以后 取消永久代，方法区由元空间（Metaspace）实现，元空间仍然与堆不相连，但与堆共享物理内存，逻辑上可认为在堆中。 元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。，理论上取决于 32 位/64 位系统可虚拟的内存大小。可见也不是无限制的，需要配置参数。 在之前的永久代实现中，如果要修改方法区的大小配置，需要使用 PermSize ，MaxPermSize 参数，而改为元空间之后，就需要使用 MetaspaceSize，MaxMetaspaceSize。 为什么移除永久代？ 字符串存在永久代中，容易出现性能问题和内存溢出。 永久代大小不容易确定，PermSize 指定太小容易造成永久代 OOM 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。 Oracle 可能会将 HotSpot 与 JRockit 合二为一。 常量池、运行时常量池、字符串常量池 在JDK7之前，字符串常量是存在永久带Perm 区的，JDK7开始在将常量池迁移到堆中，这个变化也导致了String的新特性，接下来，我们按照jdk7开始后的版本进行介绍。 常量池分类 运行时常量池 Class文件常量池 字符串常量池 Class文件常量池 .java经过编译后生成的.class文件，是Class文件的资源仓库。 常量池中主要存放俩大常量：字面量（文本字符串，final常量）和符号引用（类和接口的全局定名，字段的名称和描述，方法的名称和描述），如下图： 运行时常量池（Constant Pool） 运行时常量池是方法区的一部分。在Class常量池中，用于存放编译期间生成的字面量和符号量，在类加载完之后，存入运行时常量池中。而运行时常量池期间也有可能加入新的常量（如：String.intern方法） String常量池， String常量池，JVM为了减少字符串对象的重复创建，在堆区开一段内存存放字符串。 h1 { counter-reset: h2counter; } h2 { counter-reset: h3counter; } h3 { counter-reset: h4counter; } h4 { counter-reset: h5counter; } h5 { counter-reset: h6counter; } h6 { } h2:before { counter-increment: h2counter; content: counter(h2counter) \".\\0000a0\\0000a0\"; } h3:before { counter-increment: h3counter; content: counter(h2counter) \".\" counter(h3counter) \".\\0000a0\\0000a0\"; } h4:before { counter-increment: h4counter; content: counter(h2counter) \".\" counter(h3counter) \".\" counter(h4counter) \".\\0000a0\\0000a0\"; } h5:before { counter-increment: h5counter; content: counter(h2counter) \".\" counter(h3counter) \".\" counter(h4counter) \".\" counter(h5counter) \".\\0000a0\\0000a0\"; } h6:before { counter-increment: h6counter; content: counter(h2counter) \".\" counter(h3counter) \".\" counter(h4counter) \".\" counter(h5counter) \".\" counter(h6counter) \".\\0000a0\\0000a0\"; } new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/markdown标题数字.html":{"url":"notes/20.10/markdown标题数字.html","title":"markdown标题数字.md","keywords":"","body":" title a b c b d a b title a b c b d a b 这种方式通过修改css的方式来完成，但是主流的博客网站都不支持，所以这种方式只能在本地来做。 ``` h1 { counter-reset: h2counter; } h2 { counter-reset: h3counter; } h3 { counter-reset: h4counter; } h4 { counter-reset: h5counter; } h5 { counter-reset: h6counter; } h1 { text-align: center; } h2:before { counter-increment: h2counter; content: counter(h2counter) \".\\0000a0\\0000a0\"; } h3:before { counter-increment: h3counter; content: counter(h2counter) \".\" counter(h3counter) \".\\0000a0\\0000a0\"; } h4:before { counter-increment: h4counter; content: counter(h2counter) \".\" counter(h3counter) \".\" counter(h4counter) \".\\0000a0\\0000a0\"; } h5:before { counter-increment: h5counter; content: counter(h2counter) \".\" counter(h3counter) \".\" counter(h4counter) \".\" counter(h5counter) \".\\0000a0\\0000a0\"; } h6:before { counter-increment: h6counter; content: counter(h2counter) \".\" counter(h3counter) \".\" counter(h4counter) \".\" counter(h5counter) \".\" counter(h6counter) \".\\0000a0\\0000a0\"; } ```new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/maven/":{"url":"notes/20.10/maven/","title":"maven","keywords":"","body":" 一maven打包工具.md 三manifest和maven.md 二通过maven来启动main方法.md 五maven构建的生命周期和常用命令.md 四dependencyManagement和dependencies.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/maven/一maven打包工具.html":{"url":"notes/20.10/maven/一maven打包工具.html","title":"一maven打包工具.md","keywords":"","body":" mvn系列文章 maven打包插件 maven-assembly-plugin，maven-shade-plugin与maven-assembly-plugin 一、介绍 二、 打包准备 三、 maven-jar-plugin插件（maven默认打包插件） 四、 maven-shade-plugin 五、 maven-assembly-plugin id与formats fileSets/fileSet files/file dependencySets/dependencySet [TOC] mvn系列文章 有很多习以为常的东西本来觉得自己会了，但是其实很多细节上的东西都没理解好。写mvn是因为我对于maven的插件有不知道的地方，结果在查这个的时候又发现了其他很多自己不太理解的东西，也结合之前搜过的不会的东西，整理一个集合。后续其他学过的东西还是得整理一下，不然时间长了没有积累的东西很快就会忘了。 maven打包插件 maven-assembly-plugin，maven-shade-plugin与maven-assembly-plugin 一、介绍 maven提供的打包插件有如下三种： plugin function maven-jar-plugin maven 默认打包插件，用来创建 project jar maven-shade-plugin 用来打可执行包，executable(fat) jar maven-assembly-plugin 支持定制化打包方式，例如 apache 项目的打包方式 二、 打包准备 需要设定文件的编码格式（如果不设定，将会以系统的默认编码进行处理）与JDK版本版本变量，代码如下： UTF-8 1.8 需要确定依赖的scope：默认的scope包括如下 | scope | 说明 | | ------------- | ------------------------------------------------------------ | | compile | 默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用，同时它们也会被打包 | | provided | 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如， 如果你开发了一个web 应用，你可能在编译 classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包。 | | runtime | 依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC驱动实现。 | | test | test范围依赖 在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用 | | system | system范围依赖与provided 类似，但是你必须显式的提供一个对于本地系统中JAR 文件的路径。这么做是为了允许基于本地对象编译，而这些对象是系统类库的一部分。这样的构件应该是一直可用的，Maven 也不会在仓库中去寻找它。如果你将一个依赖范围设置成系统范围，你必须同时提供一个 systemPath 元素。注意该范围是不推荐使用的（你应该一直尽量去从公共或定制的 Maven 仓库中引用依赖） | maven的build: build分为两种： a. base build（既为project的子元素） install ${basedir}/target ${artifactId}-${version} filters/filter1.properties ... 上述例子中： defaultGoal:执行build任务时，如果没有指定目标，将使用的默认值,上述例子犹如 mvn install. directory：build目标文件的存放目录，默认在${basedir}/target目录； finalName：build目标文件的文件名，默认情况下为${artifactId}-${version}； b. 指定一个特定的resource位置。例如 ... META-INF/plexus false ${basedir}/src/main/plexus configuration.xml **/*.properties ... ... 1、resources：一个resource元素的列表，每一个都描述与项目关联的文件是什么和在哪里； 2、targetPath：指定build后的resource存放的文件夹。该路径默认是basedir。通常被打包在JAR中的resources的目标路径为META-INF； 3、filtering：true/false，表示为这个resource，filter是否激活。 4、directory：定义resource所在的文件夹，默认为${basedir}/src/main/resources； 5、includes：指定作为resource的文件的匹配模式，用*作为通配符； 6、excludes：指定哪些文件被忽略，如果一个文件同时符合includes和excludes，则excludes生效； 7、testResources：定义和resource类似，但只在test时使用，默认的test resource文件夹路径是${basedir}/src/test/resources，test resource不被部署。 c. plugins,如下代码所示： ... org.apache.maven.plugins maven-jar-plugin 2.0 false true test ... ... 除了groupId:artifactId:version标准坐标，plugin还需要如下属性： 1、extensions：true/false，是否加载plugin的extensions，默认为false； 2、inherited：true/false，这个plugin是否应用到该POM的孩子POM，默认true； 3、configuration：配置该plugin期望得到的properies，如上面的例子，我们为maven-jar-plugin的Mojo设置了classifier属性；如果你的POM有一个parent，它可以从parent的build/plugins或者pluginManagement集成plugin配置。 三、 maven-jar-plugin插件（maven默认打包插件） 使用 Maven 构建一个 JAR 文件比较容易：只要定义项目包装为 “jar”，然后执行包装生命周期阶段即可。但是定义一个可执行 JAR 文件却比较麻烦。 可行的方案是创建一个MANIFEST.MF 文件中定义一个 main 类。或者可以使用两个 Maven 插件帮助您完成：maven-jar-plugin 和 maven-dependency-plugin。 1.指定manfestFile位置：具体配置如下： ... org.apache.maven.plugins maven-jar-plugin 3.0.2 ${project.build.outputDirectory}/META-INF/MANIFEST.MF ... ... 使用maven-jar-plugin 修改 MANIFEST.MF文件，具体代码如下： org.apache.maven.plugins maven-jar-plugin true lib/ com.mypackage.MyClass 所有 Maven 插件通过一个 元素公布了其配置，在本例中，maven-jar-plugin 修改它的 archive 属性，特别是存档文件的 manifest 属性，它控制 MANIFEST.MF 文件的内容。包括 3 个元素： addClassPath：将该元素设置为 true 告知 maven-jar-plugin 添加一个 Class-Path 元素到 MANIFEST.MF 文件，以及在 Class-Path 元素中包括所有依赖项。 classpathPrefix：如果您计划在同一目录下包含有您的所有依赖项，作为您将构建的 JAR，那么您可以忽略它；否则使用 classpathPrefix 来指定所有依赖 JAR 文件的前缀。在清单 1 中，classpathPrefix 指出，相对存档文件，所有的依赖项应该位于 “lib” 文件夹。 mainClass：当用户使用 lib 命令执行 JAR 文件时，使用该元素定义将要执行的类名。上述可以通过是用maven-dependency-plugin将依赖包添加进去 四、 maven-shade-plugin 五、 maven-assembly-plugin 日常使用的以maven-assembly-plugin为最多，因为大数据项目中往往有很多shell脚本、SQL脚本、.properties及.xml配置项等，采用assembly插件可以让输出的结构清晰而标准化。 要使用该插件，就在项目pom文件中加入以下内容。 org.apache.maven.plugins maven-assembly-plugin ${maven-assembly-plugin.version} make-assembly package single src/main/assembly/assembly.xml jar-with-dependencies --> assembly插件的打包方式是通过descriptor（描述符）来定义的。 Maven预先定义好的描述符有bin，src，project，jar-with-dependencies等。比较常用的是jar-with-dependencies，它是将所有外部依赖JAR都加入生成的JAR包中，比较傻瓜化。 但要真正达到自定义打包的效果，就需要自己写描述符文件，格式为XML。下面是我们的项目中常用的一种配置。 assembly tar.gz true src/main/bin *.sh bin 0755 src/main/conf conf src/main/sql *.sql sql target/classes/ *.properties *.xml *.txt conf target/${project.artifactId}-${project.version}.jar . false runtime lib id与formats formats是assembly插件支持的打包文件格式，有zip、tar、tar.gz、tar.bz2、jar、war。可以同时定义多个format。 id则是添加到打包文件名的标识符，用来做后缀。 也就是说，如果按上面的配置，生成的文件就是${artifactId}-${version}-assembly.tar.gz。 fileSets/fileSet 用来设置一组文件在打包时的属性。 directory：源目录的路径。 includes/excludes：设定包含或排除哪些文件，支持通配符。 fileMode：指定该目录下的文件属性，采用Unix八进制描述法，默认值是0644。 outputDirectory：生成目录的路径。 files/file 与fileSets大致相同，不过是指定单个文件，并且还可以通过destName属性来设置与源文件不同的名称。 dependencySets/dependencySet 用来设置工程依赖文件在打包时的属性。也与fileSets大致相同，不过还有两个特殊的配置： unpack：布尔值，false表示将依赖以原来的JAR形式打包，true则表示将依赖解成*.class文件的目录结构打包。 scope：表示符合哪个作用范围的依赖会被打包进去。compile与provided都不用管，一般是写runtime。 按照以上配置打包好后，将.tar.gz文件上传到服务器，解压之后就会得到bin、conf、lib等规范化的目录结构，十分方便。 参考：https://www.jianshu.com/p/e581fff1cf87 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/maven/三manifest和maven.html":{"url":"notes/20.10/maven/三manifest和maven.html","title":"三manifest和maven.md","keywords":"","body":" jar文件 常见的 jar工具用法 META-INF maven和MANIFEST.MF [TOC] jar文件 提到 JAR，最先可能想到的就是依赖，比如 fastjson.jar ，它可以作为依赖在项目中来引用，但是不能通过 java -jar 来执行，这种就是非可执行的 JAR。另外一种，比如我们项目打包之后生成的 JAR （当然也可能是 war），我们可以通过 java -jar 来运行程序，我们把它称之为可执行的 JAR。 JAR 作用大体可以分为以下几种： 用于发布和使用类库 作为应用程序和扩展的构建单元 作为组件、applet 或者插件程序的部署单位 用于打包与组件相关联的辅助资源 JAR 文件格式提供了许多优势和功能，其中很多是传统的压缩格式如 ZIP 或者 TAR 所没有提供的。它们包括： 安全性：可以对 JAR 文件内容加上数字化签名。这样，能够识别签名的工具就可以有选择地为您授予软件安全特权，这是其他文件做不到的，它还可以检测代码是否被篡改过。 减少下载时间：如果一个 applet 捆绑到一个 JAR 文件中，那么浏览器就可以在一个 HTTP 事务中下载这个 applet 的类文件和相关的资源，而不是对每一个文件打开一个新连接。 压缩：JAR 格式允许您压缩文件以提高存储效率。 传输平台扩展。Java 扩展框架 (Java Extensions Framework) 提供了向 Java 核心平台添加功能的方法，这些扩展是用 JAR 文件打包的 (Java 3D 和 JavaMail 就是由 Sun 开发的扩展例子 )。 包密封：存储在 JAR 文件中的包可以选择进行 密封，以增强版本一致性和安全性。密封一个包意味着包中的所有类都必须在同一 JAR 文件中找到。 包版本控制：一个 JAR 文件可以包含有关它所包含的文件的数据，如厂商和版本信息。 可移植性：处理 JAR 文件的机制是 Java 平台核心 API 的标准部分。 常见的 jar工具用法 功能 命令 用一个单独的文件创建一个 JAR 文件 jar cf jar-file input-file... 用一个目录创建一个 JAR 文件 jar cf jar-file dir-name 创建一个未压缩的 JAR 文件 jar cf0 jar-file dir-name 更新一个 JAR 文件 jar uf jar-file input-file... 查看一个 JAR 文件的内容 jar tf jar-file 提取一个 JAR 文件的内容 jar xf jar-file 从一个 JAR 文件中提取特定的文件 jar xf jar-file archived-file... 运行一个打包为可执行 JAR 文件的应用程序 java -jar app.jar META-INF 大多数 JAR 文件包含一个 META-INF 目录，它用于存储包和扩展的配置数据，如安全性和版本信息。Java 2 平台（标准版【J2SE】）识别并解释 META-INF 目录中的下述文件和目录，以便配置应用程序、扩展和类装载器： MANIFEST.MF：这个 manifest 文件定义了与扩展和包相关的数据。 通过 MAVEN 插件打包进来的文件比如： maven services ： 存储所有服务提供程序配置文件 其他的还有一些不常看到的： INDEX.LIST ：这个文件由 jar工具的新选项 -i生成，它包含在应用程序或者扩展中定义的包的位置信息。它是 JarIndex 实现的一部分，并由类装载器用于加速类装载过程。 .SF：这是 JAR 文件的签名文件 .DSA：与签名文件相关联的签名程序块文件，它存储了用于签名 JAR 文件的公共签名。 LICENSE.txt ：证书信息 NOTICE.txt ： 公告信息 maven和MANIFEST.MF 可以通过在pom文件里增加配置来自动生成MANIFEST.MF ${project.name} ${project.version} ${project.name} ${project.version} dsvshx.agent.AgentTest 这样生成的内容如下： new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/maven/二通过maven来启动main方法.html":{"url":"notes/20.10/maven/二通过maven来启动main方法.html","title":"二通过maven来启动main方法.md","keywords":"","body":" 通过maven命令来运行Java程序main方法 一、从命令行运行 二、 在pom.xml中指定某个阶段执行 三、 在pom.xml中指定某个配置来执行 [TOC] 通过maven命令来运行Java程序main方法 一、从命令行运行 运行前先编译代码，exec：java不会自动编译代码，你需要手动执行mvn compile来完成编译。 mvn compile 编译完成后，执行exec运行main方法。 不需要传递参数： mvn exec:java -Dexec.mainClass=\"com.vineetmanohar.module.Main\" 需要传递参数： mvn exec:java -Dexec.mainClass=\"com.vineetmanohar.module.Main\" -Dexec.args=\"arg0 arg1 arg2\" 指定对classpath的运行时依赖： mvn exec:java -Dexec.mainClass=\"com.vineetmanohar.module.Main\" -Dexec.classpathScope=runtime 二、 在pom.xml中指定某个阶段执行 org.codehaus.mojo exec-maven-plugin 1.1.1 test java com.vineetmanohar.module.CodeGenerator arg0 arg1 将CodeGenerator.main()方法的执行绑定到maven的 test 阶段，通过下面的命令可以执行main方法： mvn test 三、 在pom.xml中指定某个配置来执行 code-generator org.codehaus.mojo exec-maven-plugin 1.1.1 test java com.vineetmanohar.module.CodeGenerator arg0 arg1 将2中的配置用标签包裹后就能通过指定该配置文件来执行main方法，如下： mvn test -Pcode-generator 注：通过以下命令可以获取mvn exec的其他配置参数说明。 mvn exec:help -Ddetail=true -Dgoal=java 参考：https://blog.csdn.net/qbg19881206/article/details/19850857 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/maven/五maven构建的生命周期和常用命令.html":{"url":"notes/20.10/maven/五maven构建的生命周期和常用命令.html","title":"五maven构建的生命周期和常用命令.md","keywords":"","body":" maven 命令的格式 开发中常用命令 maven 命令的格式 mvn [plugin-name]:[goal-name]，可以接受的参数如下。 -D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试； -P 指定 Profile 配置，可以用于区分环境； -e 显示maven运行出错的信息； -o 离线执行命令,即不去远程仓库更新包； -X 显示maven允许的debug信息； -U 强制去远程更新snapshot的插件或依赖，默认每天只更新一次。 开发中常用命令 mvn compile 编译源代码 mvn test-compile 编译测试代码 mvn test 运行测试 mvn -Dtest package 打包但不测试。完整命令为：mvn -D maven.test.skip=true package mvn verify 验证软件包是否有效 mvn install 在本地Repository中安装jar mvn clean 清除产生的项目 mvn dependency:sources 下载源码 mvn validate 检查项目是否正确，需要的信息是否完善 mvn deploy 将最终的构件上传到远程存储库 mvn package 打包，根据pom.xml打成war或jar。也会先执行validate、compile以及test。 如果pom.xml中设置 war，则此命令相当于mvn war:war 如果pom.xml中设置 jar，则此命令相当于mvn jar:jarnew Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/maven/四dependencyManagement和dependencies.html":{"url":"notes/20.10/maven/四dependencyManagement和dependencies.html","title":"四dependencyManagement和dependencies.md","keywords":"","body":" 一、dependencyManagement应用场景 二、dependencies应用场景 三、dependencyManagement与dependencies区别 [TOC] 一、dependencyManagement应用场景 为了项目的正确运行，必须让所有的子模块使用依赖项的统一版本，必须确保应用的各个项目的依赖项和版本一致，才能保证测试的和发布的是相同的结果。在我们项目顶层的pom文件中，我们会看到dependencyManagement元素。通过它元素来管理jar包的版本，让子项目中引用一个依赖而不用显示的列出版本号。Maven会沿着父子层次向上走，直到找到一个拥有dependencyManagement元素的项目，然后它就会使用在这个dependencyManagement元素中指定的版本号。 父pom中dependencyManagement如下： module1 3.1.1.RELEASE org.springframework spring-web ${spring-version} 子模块module1中dependency声明如下所示： org.springframework spring-web 这样做的好处：统一管理项目的版本号，确保应用的各个项目的依赖和版本一致，才能保证测试的和发布的是相同的成果，因此，在顶层pom中定义共同的依赖关系。同时可以避免在每个使用的子项目中都声明一个版本号，这样想升级或者切换到另一个版本时，只需要在父类容器里更新，不需要任何一个子项目的修改；如果某个子项目需要另外一个版本号时，只需要在dependencies中声明一个版本号即可。子类就会使用子类声明的版本号，不继承于父类版本号。 二、dependencies应用场景 相对于dependencyManagement，如果在module1的pom文件中中通过dependencies引入jar，将默认被所有的子模块继承。 三、dependencyManagement与dependencies区别 dependencyManagement里只是声明依赖，并不实现引入，因此子项目需要显式的声明需要用的依赖。如果不在子项目中声明依赖，是不会从父项目中继承下来的；只有在子项目中写了该依赖项，并且没有指定具体版本，才会从父项目中继承该项，并且version和scope都读取自父pom;另外如果子项目中指定了版本号，那么会使用子项目中指定的jar版本。 dependencies即使在子模块中不写该依赖项，那么子模块仍然会从父项目中继承该依赖项（全部继承）。 在实际的项目开发中，推荐在父pom中使用dependencyManagement对项目中使用到的依赖包进行统一的管理。 参考：https://www.jianshu.com/p/c8666474cf9a new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/vscode插件/":{"url":"notes/20.10/vscode插件/","title":"vscode插件","keywords":"","body":" vscode插件.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10/vscode插件/vscode插件.html":{"url":"notes/20.10/vscode插件/vscode插件.html","title":"vscode插件.md","keywords":"","body":" 如何写一个vscode插件 编写 package.json extenion.js 注册命令 编写具体的功能实现。 上线 本地打包 发布到应用市场 注册账号 创建发布账号 发布 [TOC] 如何写一个vscode插件 先说说为什么会萌生了这个开发vscode插件的想法。我在写markdown的时候需要插入图片。本地写的话只能是本地的URI。如果放到别的平台上对于图片的处理是比较麻烦的。目前的解决方案是存到七牛云或者使用pic等等。但是比较不靠谱而且还要配置比较麻烦。所以我的这个插件就是把图片上传到码云的仓库，返回一个URL直接插入到markdown中。 首先要感谢大神的一系列博客https://www.cnblogs.com/liuxianan/p/vscode-plugin-overview.html。写一个简单的vscode插件看这系列文章就够了。我在这里只是简单记录一下我的开发过程。 vscode支持通过脚手架来初始化一个vscode插件目录。首先安装脚手架。 npm install -g yo generator-code 然后进入你的目运行 yo code。 编写 vscode支持TypeScript和JavaScript。我用的是JS。进入目录之后大部分的改动都在extension.js和package.json两个文件。 我下面直接把代码贴过来再加一些注释。 vscode的主要配置如下，main表明了入口文件。这里是extention.js。 package.json contributes：这里定义了如何来触发自己的插件。我定义的是command。也就是通过Ctrl+shift+p然后输入命令。这些命令需要在activationEvents里面注册一下。 configuration：这里定义了一些配置，一些个性化的信息不适合写死在代码里。 输入命令对应的代码会写在extension.js里面。 // package.json \"activationEvents\": [ \"onCommand:extention.upload\", \"onCommand:extention.upload_remote\", \"onCommand:extention.upload_local\", \"*\" ], \"main\": \"./extension.js\", \"contributes\": { \"commands\": [ { \"command\": \"extention.upload\", \"title\": \"upload\" }, { \"command\": \"extention.upload_remote\", \"title\": \"uploadRemote\" }, { \"command\": \"extention.upload_local\", \"title\": \"uploadLocal\" } ], \"configuration\": { \"type\": \"object\", \"title\": \"mdPic配置\", \"properties\": { \"pic.git\": { \"type\": \"string\", \"default\": \"null\", \"description\": \"git仓库\" }, \"pic.access_token\": { \"type\": \"string\", \"default\": \"null\", \"description\": \"access_token\" } } } }, extenion.js 注册命令 首先vscode有一个声明周期函数。插件激活之后会自动进入activate函数。在这个函数里面我们需要把配置的commands注册一下。 sub.push(vscode.commands.registerCommand('extention.upload_remote', disposeRemotePic));这行代码标识如果输入upload_remote命令，它对应的回调函数是disposeRemotePic。vscode为我们提供了很多API，比如vscode.window.showInformationMessage(\"active!\");就是弹出一个显示active的窗口。 // extension.js /** * @param {vscode.ExtensionContext} context */ function activate(context) { console.log('\"md-pic\" is now active!'); const dispos = vscode.commands.registerCommand(\"extention.upload\", function () { vscode.window.showInformationMessage(\"active!\"); }); context.subscriptions.push(dispos); let sub = context.subscriptions; sub.push(vscode.commands.registerCommand('extention.upload_remote', disposeRemotePic)); sub.push(vscode.commands.registerCommand('extention.upload_local', disposeLocalPic)); } 编写具体的功能实现。 这段代码实现了获取当前行的图片链接，并且下载该图片并转成base64格式编码。下载图片是用的axios。后面上传图片也是是用了这个模块。 function disposeRemotePic() { let editor = vscode.window.activeTextEditor; let document = editor.document; console.log(editor); console.log(document); const line = editor.selection.active.line; let url = document.lineAt(line); console.log(url.text); const text = '上传第' + line + '行链接图片：' + url.text + ' 至GitHub, 请输入图片名称'; vscode.window.showInputBox( { password: false, // 输入内容是否是密码 ignoreFocusOut: true, // 默认false，设置为true时鼠标点击别的地方输入框不会消失 placeHolder: 'name', // 在输入框内的提示信息 prompt: text, // 在输入框下方的提示信息 }).then(res => { const pic_name = res + \".png\"; const pic_url = url.text; // upload(res + \".png\", url.text); console.log('name: ' + pic_name + ', url: ' + pic_url); axios.get(encodeURI(pic_url), { responseType: 'arraybuffer' }) .then(res => uploadGitee(pic_name, Buffer.from(res.data).toString('base64'))) .catch(function (error) { console.log(error); vscode.window.showInformationMessage(\"download image failed, please try again!\"); }); }); } 这段代码是选择一个本地文件并把这个文件转成base64编码。 function disposeLocalPic() { vscode.window.showOpenDialog( { // 可选对象 canSelectFiles: true, // 是否可选文件 canSelectFolders: false, // 是否可选文件夹 canSelectMany: true, // 是否可以选择多个 defaultUri: vscode.Uri.file(\"./\"), // 默认打开本地路径 openLabel: '上传' }).then(function (msg) { const path = msg[0].path; console.log(path); // var data = fs.readFileSync(path.substring(1)); var data = fs.readFileSync(path); const base64Data = Buffer.from(data).toString('base64'); const paths = path.split(\"/\"); const pic_name = paths[paths.length - 1]; uploadGitee(pic_name, base64Data); }); } 这段代码是吧文件上传到gitee然后返回一个URL。并且调用API插入到文本编辑框里。 function uploadGitee(pic_name, base64_data) { const url = vscode.workspace.getConfiguration().get('pic.git'); const auth = vscode.workspace.getConfiguration().get('pic.access_token'); const headers = { 'Content-Type': 'application/json', 'charset': 'UTF-8' }; const jdata = JSON.stringify({ \"access_token\": auth, \"message\": pic_name, \"content\": base64_data }); console.log(headers) console.log(jdata); axios.post(encodeURI(url + pic_name), jdata, { headers: headers } ).then(res => { console.log(res); if (res.status = 200) { const git_url = res.data[\"content\"][\"download_url\"] console.log(git_url); vscode.window.activeTextEditor.edit(editBuilder => { const md_img = \"![\" + pic_name + \"](\" + git_url + \")\"; const end = new vscode.Position(vscode.window.activeTextEditor.selection.active.line + 1, 0); editBuilder.replace(new vscode.Range(new vscode.Position(vscode.window.activeTextEditor.selection.active.line, 0), end), md_img); }); } else { console.error(\"upload url failed!\") vscode.window.showInformationMessage(\"upload url failed, please try again!\"); } }).catch(function (error) { console.log(error); vscode.window.showInformationMessage(\"upload url failed, please try again!\"); }); } 整体的功能比较简单。vscode提供的API相当丰富。这个只是一个比较简单的尝试。 上线 方法一：直接把文件夹发给别人，让别人找到vscode的插件存放目录并放进去，然后重启vscode，一般不推荐； 方法二：打包成vsix插件，然后发送给别人安装，如果你的插件涉及机密不方便发布到应用市场，可以尝试采用这种方式； 方法三：注册开发者账号，发布到官网应用市场，这个发布和npm一样是不需要审核的。 本地打包 无论是本地打包还是发布到应用市场都需要借助vsce这个工具。 安装：npm i vsce -g 打包成vsix文件：vsce package 生成好的vsix文件不能直接拖入安装，只能从扩展的右上角选择Install from VSIX安装。 发布到应用市场 注册账号 访问 https://login.live.com/ 登录你的Microsoft账号，然后访问： https://aka.ms/SignupAzureDevOps， 进入组织的主页后，点击右上角的Security。点击创建新的个人访问令牌，这里特别要注意Organization要选择all accessible organizations，Scopes要选择Full access，否则后面发布会失败。 创建发布账号 获得个人访问令牌后，使用vsce以下命令创建新的发布者：vsce create-publisher your-publisher-name 发布 vsce publish // 发布 vsce publish patch // 增量发布 vsce unpublish (publisher name).(extension name) // 取消发布new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/":{"url":"notes/20.10之前归档/","title":"20.10之前归档","keywords":"","body":" HashMap.md JVM.md Java服务异常分析的几个思路.md Redis设计与实现.md Spring知识点.md crontab定时任务.md idea远程部署docker.md linux系统命令行快捷键.md redis知识点和面试问题.md redis线程模型.md tcp建立和释放连接过程三次握手四次挥手.md 使用typora自动上传图片到github仓库.md 写Redis时的并发异常和分布式锁.md 分布式系统.md 单例模式整理以及相关的知识点.md 如何制作一个自己的图床.md 常用的消息中间件.md 并发编程常见面试题.md 搜索引擎书.md 操作系统知识点和面试总结.md 数据库常考点.md 数据库索引.md 新买的服务器要做哪些配置.md 新建springboot项目.md 系统架构设计.md 经验教训.md 计算机网络常见面试题.md 设计模式常考点.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/HashMap.html":{"url":"notes/20.10之前归档/HashMap.html","title":"HashMap.md","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/JVM.html":{"url":"notes/20.10之前归档/JVM.html","title":"JVM.md","keywords":"","body":" jvm jvm内存模型 堆 虚拟机栈 方法区 程序计数器 JVM垃圾回收算法 标记-清除 复制算法 标记-整理 分代收集 JVM垃圾收集器有哪些？以及优劣势比较？ 串行收集器 并行收集器 CMS收集器 G1收集器 在JVM中，如何判断一个对象是否死亡？ 引用计数法 可达性分析算法 谈谈JVM中，对类加载器的认识 堆和栈♥ ♥ [TOC] jvm jvm内存模型 堆 存放对象实例，java代码中所有的new操作，几乎所有的对象实例都在这里分配内存 堆得内存由-Xms指定，默认是物理内存的1/64；最大的内存由-Xmx指定，默认是物理内存的1/4。 默认空余的堆内存小于40%时，就会增大，直到-Xmx设置的内存。具体的比例可以由-XX:MinHeapFreeRatio指定 空余的内存大于70%时，就会减少内存，直到-Xms设置的大小。具体由-XX:MaxHeapFreeRatio指定。 虚拟机栈 虚拟机栈是用于描述java方法执行的内存模型 ：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。 虚拟机栈是线程隔离的。 本地方法栈服务的对象是JVM执行的native方法，而虚拟机栈服务的是JVM执行的java方法。如何去服务native方法？native方法使用什么语言实现？怎么组织像栈帧这种为了服务方法的数据结构？虚拟机规范并未给出强制规定，因此不同的虚拟机实可以进行自由实现，我们常用的HotSpot虚拟机选择合并了虚拟机栈和本地方法栈。 方法区 存储已被虚拟机加载的类元数据信息(元空间) 有时候也成为永久代，在该区内很少发生垃圾回收，但是并不代表不发生GC，在这里进行的GC主要是对方法区里的常量池和对类型的卸载 方法区主要用来存储已被虚拟机加载的类的信息、常量、静态变量和即时编译器编译后的代码等数据。 该区域是被线程共享的。 方法区里有一个运行时常量池，用于存放静态编译产生的字面量和符号引用。该常量池具有动态性，也就是说常量并不一定是编译时确定，运行时生成的常量也会存在这个常量池中。 程序计数器 当前线程所执行的字节码的行号指示器 JVM垃圾回收算法 JVM GC只回收堆区和方法区的对象。 标记-清除 标记哪些要被回收的对象，然后统一回收。这种方法很简单，但是会有两个主要问题：1.效率不高，标记和清除的效率都很低；2.会产生大量不连续的内存碎片，导致以后程序在分配较大的对象时，由于没有充足的连续内存而提前触发一次GC动作。 复制算法 为了解决效率问题，复制算法将可用内存按容量划分为相等的两部分，然后每次只使用其中的一块，当一块内存用完时，就将还存活的对象复制到第二块内存上，然后一次性清楚完第一块内存，再将第二块上的对象复制到第一块。 但是这种方式，内存的代价太高，每次基本上都要浪费一般的内存。 于是将该算法进行了改进，内存区域不再是按照1：1去划分，而是将内存划分为8:1:1三部分，较大那份内存叫Eden（伊甸园）区，其余是两块较小的内存区叫Survior区。 每次都会优先使用Eden区，若Eden区满，就将对象复制到第二块内存区上，然后清除Eden区，如果此时存活的对象太多，以至于Survivor不够时，会将这些对象通过分配担保机制复制到老年代中。(java堆又分为新生代和老年代) 标记-整理 主要是为了解决标记-清除，产生大量内存碎片的问题；当对象存活率较高时，也解决了复制算法的效率问题。它的不同之处就是在清除对象的时候现将可回收对象移动到一端，然后清除掉端边界以外的对象，这样就不会产生内存碎片了。 分代收集 现在的虚拟机垃圾收集大多采用这种方式，它根据对象的生存周期，将堆分为新生代和老年代。在新生代中，由于对象生存期短，每次回收都会有大量对象死去，那么这时就采用复制算法。老年代里的对象存活率较高，没有额外的空间进行分配担保，所以可以使用标记-整理 或者 标记-清除。 JVM垃圾收集器有哪些？以及优劣势比较？ 收集器 特点 串行收集器 暂停所有应用的线程来工作，单线程 并行收集器 默认的垃圾收集器。暂停所有应用，多线程。 CMS收集器 多线程扫描，标记需要回收的实例，清除。 G1收集器 用于大堆区域。对内存分割，并发回收。 串行收集器 只使用一个线程去回收。新生代、老年代使用串行回收；新生代复制算法、老年代标记-压缩；垃圾收集的过程中会Stop The World（服务暂停） 并行收集器 Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。 CMS收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括： 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） G1收集器 G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。与CMS收集器相比G1收集器有以下特点： 空间整合，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。 可预测停顿，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 在JVM中，如何判断一个对象是否死亡？ 引用计数法 引用计数法是最简单最古老的算法，JVM为每个对象分配一个计数器，当对象被引用时，计数器就加1，当对象没有被引用或者离开作用域，计数器就减1。当计数器的值为0时，就代表该对象已经死亡 可达性分析算法 用GCROOTs 作为对象的起点开始往下搜索，能搜索到这个对象，就表示对象是可达的，不能搜素到表示对象是不可达的： 可作为GCRoots的对象包括下面几种： 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中引用的对象 谈谈JVM中，对类加载器的认识 类加载器是JVM的组成部分之一。将字节码文件加载进JVM。 类加载分为四部分： BootStrapClassLoader，即跟类加载器，加载java运行时所需的类，如String，Integer等存在${java_home}/jre/lib/rt.jar包类的所有类。 ExtensionClassLoader,扩展类加载器，加载一些扩展类，即${java_home}/jre/lib/ext/*.jar包 AppClassLoader，系统加载类，加载自定义的类，级classpath下的所有类 ClassLoader 抽象类加载器：用户自定义的类加载器，用户定义的类加载器都要继承次ClassLoader Jvm默认采用的是双亲委派类加载机制， 某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。 堆和栈♥ ♥ 栈内存：栈内存首先是一片内存空间，存储都是局部变量，凡是定义在方法中的都是局部变量，是先加载函数才能进行局部变量的定义，所以方法先进栈，然后在定义变量，变量有自己的作用域，一旦离开作用域，变量就会被释放。栈内存的更新速度很快，因为局部变量的生命周期都很短。 堆内存：存储的是数组和对象（其实数据就是对象），凡是new建立的都是在堆中，堆中存放的都是实体对象，实体用于封装数据，而且是封装多个（实体的多个属性），如果一个数据消失，这个实体也没有消失，还可以用，所以对是不会随时释放的，但是栈不一样，栈里存放的都是单个变量，变量被释放了，就没有了。堆里的实体虽然不会被释放，但是会被GC不定时的回收。 比如主函数里的语句 int [] arr=new int [3];在内存中是怎么被定义的： 主函数先进栈，在栈中定义一个变量arr，接下来为arr赋值，但是右边不是一个具体的值，是一个实体。实体创建在堆里，在堆里首先通过new关键字开辟一个空间，内存在存储数据的时候都是通过地址来体现的，地址是一块连续的二进制，然后给这个实体分配一个内存地址。 数组都是有一个索引，数组这个实体在堆内存中产生之后每一个空间都会进行默认的初始化（这是堆内存的特点，未初始化的数据是不能用的，但在堆里是可以用的，因为初始化过了，但是在栈里没有），不同的类型初始化的值不一样。 就是栈中定义变量，堆中创建实体，初始化实体，返回一个地址。 那么栈和堆是怎么联系起来的呢？ 我们刚刚说过给对分配了一个地址，把堆的地址赋值给arr，arr就通过地址指向了数组。arr想操纵数组就通过地址，而不是直接把实体赋给它。这种我们不在叫他基本数据类型，而叫引用数据类型，称为arr引用了堆内存当中的实体。 如果是int[] arr = null;则arr不坐任何指向，null的作用就是取消引用数据类型的指向。 当一个实体，没有引用数据类型指向的时候，它在堆内存中不会被释放，而被当做一个垃圾，在不定时的时间内自动回收，因为Java有一个自动回收机制，（而c++没有，需要程序员手动回收，如果不回收就越堆越多，直到撑满内存溢出，所以Java在内存管理上优于c++）。自动回收机制（程序）自动监测堆里是否有垃圾，如果有，就会自动的做垃圾回收的动作，但是什么时候收不一定。 所以堆和栈的区别很明显： 栈内存存储的是局部变量二堆内存存储的是实体； 占内存的更新速度要快于堆内存，因为局部变量的生命周期很短； 栈内存存放的变量生命周期一旦结束就会被释放，而堆内存是等着GC回收。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/Java服务异常分析的几个思路.html":{"url":"notes/20.10之前归档/Java服务异常分析的几个思路.html","title":"Java服务异常分析的几个思路.md","keywords":"","body":" Java服务异常分析的几个思路 火焰图 async-profiler简介 下载压缩包 wget https://github.com/jvm-profiling-tools/async-profiler/releases/download/v1.6/async-profiler-1.6-linux-x64.tar.gz 解压缩 tar -zxvf async-profiler-1.6-linux-x64.tar.gz 使用流程 分析CPU 分析内存分配 分析锁 分析线程状态 其他常用指令与功能 Java服务异常分析的几个思路 Java服务异常分析的几个思路 首先使用top命令查看CPU使用情况。 jps // 拿到Java进程的$pid top -Hp $pid // 对单独的进程，显示线程资源消耗情况。 top（cpu）、free（内存）、df（磁盘）、dstat（网络流量）、pstack、vmstat、strace（底层系统调用） https://cloud.tencent.com/developer/article/1600345 top命令显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 -b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i 设置间隔时间 -u 指定用户名 -p 指定进程 -n 循环显示的次数 找到具体的线程，分析这个线程在干嘛 https://www.xncoding.com/2018/06/25/java/jstack.html jps（进程）、jmap（内存）、jstack（线程）、jinfo（参数）等。 jps：查询当前机器所有JAVA进程信息 jmap：输出某个 Java 进程内存情况（如产生那些对象及数量等） jstack：打印某个 Java 线程的线程栈信息 jinfo：用于查看 jvm 的配置参数 jstack $pid // 获取线程堆栈信息 cpu火焰图 火焰图 async-profiler简介 基于采样的轻量级诊断工具，支持cpu、lock、mem、thread、cachemiss等分析 可以分析jvm/native/kelnel调用栈 可以轻松生成火焰图 项目地址：https://github.com/jvm-profiling-tools/async-profiler 下载压缩包 wget https://github.com/jvm-profiling-tools/async-profiler/releases/download/v1.6/async-profiler-1.6-linux-x64.tar.gz 解压缩 tar -zxvf async-profiler-1.6-linux-x64.tar.gz 使用流程 解压后我们会得到一个profiler.sh脚本，主要功能皆通过该脚本完成 分析CPU 获取分析的进程号：jps -v 执行脚本 ./profiler.sh -e cpu -d 60 -f cpu.svg pid sz cpu.svg 到本地并用chrome打开火焰图即可 分析内存分配 获取分析的进程号：jps -v 执行脚本 ./profiler.sh -e alloc -d 60 -f mem_alloc.svg pid sz mem_alloc.svg 到本地并用chrome打开火焰图即可 分析锁 获取分析的进程号：jps -v 执行脚本 ./profiler.sh -e lock -d 60 -f lock.svg pid sz lock.svg 到本地并用chrome打开火焰图即可 分析线程状态 获取分析的进程号：jps -v 执行脚本 ./profiler.sh -e wall -t -i 5ms -f thread.svg pid sz thread.svg 到本地并用chrome打开火焰图即可 其他常用指令与功能 ./profiler.sh list pid 查看支持的事件 分析cachemiss：./profiler.sh -d 30 -e cache-misses pid 相关脚本参数详情可参见github，有详细说明 火焰图分析指南 http://www.brendangregg.com/flamegraphs.htmlnew Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/Redis设计与实现.html":{"url":"notes/20.10之前归档/Redis设计与实现.html","title":"Redis设计与实现.md","keywords":"","body":" new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/Spring知识点.html":{"url":"notes/20.10之前归档/Spring知识点.html","title":"Spring知识点.md","keywords":"","body":" 简单类型 boolean byte char short Int long float double void 二进制位数 1 8 16 16 32 64 32 64 -- 封装器类 Boolean Byte Character Short Integer Long Float Double Void new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/crontab定时任务.html":{"url":"notes/20.10之前归档/crontab定时任务.html","title":"crontab定时任务.md","keywords":"","body":"最近工作中遇到一个需求，需要每天十点钟执行一个任务，其实用Java也可以解决，但是Linux有一个内置命令可以轻松地设置定时任务。 crontable 用crontab -e进入当前用户的工作表编辑，是常见的vim界面。每行是一个任务。 crontab的命令构成为 时间+动作，其时间有分、时、日、月、周五种，操作符有 Seconds Minutes Hours DayofMonth Month DayofWeek 时间元素 可出现的字符 有效数值范围 Seconds , - * / 0-59 Minutes , - * / 0-59 Hours , - * / 0-23 DayofMonth , - * / ? L W 0-31 Month , - * / 1-12 DayofWeek , - * / ? L # 1-7或SUN-SAT 字符 作用 举例 , 列出枚举值 在Minutes域使用5,10，表示在5分和10分各触发一次 - 表示触发范围 在Minutes域使用5-10，表示从5分到10分钟每分钟触发一次 * 匹配任意值 在Minutes域使用*, 表示每分钟都会触发一次 / 起始时间开始触发，每隔固定时间触发一次 在Minutes域使用5/10,表示5分时触发一次，每10分钟再触发一次 ? 在DayofMonth和DayofWeek中，用于匹配任意值 在DayofMonth域使用?,表示每天都触发一次 # 在DayofMonth中，确定第几个星期几 1#3表示第三个星期日 L 表示最后 在DayofWeek中使用5L,表示在最后一个星期四触发 W 表示有效工作日(周一到周五) 在DayofMonth使用5W，如果5日是星期六，则将在最近的工作日4日触发一次 每1分钟执行一次myCommand * * * * * myCommand 或者每天十点执行一次自己写的脚本00 10 * * * source /home/web_server/.bash_profile && cd /home/tools/work.sh cron表达式可以在需要的时候使用在线生成网站，地址：https://cron.qqe2.com/new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/idea远程部署docker.html":{"url":"notes/20.10之前归档/idea远程部署docker.html","title":"idea远程部署docker.md","keywords":"","body":"https://blog.csdn.net/simle168/article/details/99671659new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/linux系统命令行快捷键.html":{"url":"notes/20.10之前归档/linux系统命令行快捷键.html","title":"linux系统命令行快捷键.md","keywords":"","body":"Linux 命令行编辑快捷键 命令行快捷键： 常用： Ctrl A ： 移动光标到命令行首 Ctrl B : 光标后退 Ctrl C : 中断正在当前正在执行的程序 Ctrl D : 删除当前光标所在字符 Ctrl E : 移动光标到命令行尾 Ctrl F : 光标前进 Ctrl H : 删除光标的前一个字符 Ctrl K ：删除光标之后所有字符 Ctrl L ：清屏 Ctrl M ：等效于回车 Ctrl N : 下一条命令 Ctrl P : 上一条命令，可以一直按表示一直往前翻 Ctrl Q : 解锁（S)屏幕输出 Ctrl R : 历史命令，输入出现过的字符串：按字符串寻找历史命令（重度推荐） Ctrl S : 锁定屏幕输出，tail -F的时候有用。 Ctrl T : 交换光标所在字符和前一个字符 Ctrl U : 清空当前键入的命令 Ctrl W : 删除光标前的单词(Word, 不包含空格的字符串) Ctrl X Ctrl E : 调出系统默认编辑器编辑当前输入的命令，退出编辑器时，命令执行 Ctrl+X : 光标所在位置和行首位置切换 Ctrl Y : 粘贴Ctrl W或Ctrl K删除的内容 Ctrl Z : 把当前进程放到后台（之后可用''fg''命令回到前台） Ctrl PageUp : 屏幕输出向上翻页 Ctrl PageDown : 屏幕输出向下翻页 Ctrl \\ : 删除光标前的所有空白字符 Ctrl ] : 从当前光标往后搜索字符串，用于快速移动到该字符串 Ctrl - : 撤销操作 Ctrl Alt ] : 从当前光标往前搜索字符串，用于快速移动到该字符串 Alt B : 光标后退一格单词 Alt D : 删除当前单词 Alt F : 光标前进一个单词 Alt . : 粘贴上一条命令的最后一个参数（很有用） Alt [0-9] Alt . 粘贴上一条命令的第[0-9]个参数 Alt [0-9] Alt . Alt. 粘贴上上一条命令的第[0-9]个参数 Tab : 自动补齐（重度推荐） Shift Insert : 粘贴（相当于Windows的Ctrl V） 在命令行窗口选中即复制 在命令行窗口中键即粘贴，可用Shift Insert代替new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/redis知识点和面试问题.html":{"url":"notes/20.10之前归档/redis知识点和面试问题.html","title":"redis知识点和面试问题.md","keywords":"","body":" 使用redis有哪些好处？ redis相比memcached有哪些优势？ redis最适合的场景 如果有大量的key需要设置同一时间过期，一般需要注意什么？ redis持久化机制 Redis的同步机制了解么？ Redis 集群方案与实现 [TOC] 使用redis有哪些好处？ 速度快，数据都在内存中。 支持丰富的数据类型，支持String，list，set，sorted set，hash。 支持事务，操作都是原子性，要么全部执行，要么全部不执行。 丰富的特性：可用于缓存，消息，过期自动删除等。 redis相比memcached有哪些优势？ memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 redis的速度比memcached快很多 redis可以持久化其数据 redis最适合的场景 Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别。 session cache，可以会话缓存，而且提供持久化。分布式系统就可以使用这种方式。 全页缓存（FPC），就相当于缓存网页，以更快的速度加载曾经浏览过的网页。 消息队列。队列 Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 排行榜/计数器 Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。（这个用处非常常见） 发布/订阅模式。 如果有大量的key需要设置同一时间过期，一般需要注意什么？ 如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。 redis持久化机制 bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。 Redis的同步机制了解么？ Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 Redis 集群方案与实现 Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。 Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/redis线程模型.html":{"url":"notes/20.10之前归档/redis线程模型.html","title":"redis线程模型.md","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/tcp建立和释放连接过程三次握手四次挥手.html":{"url":"notes/20.10之前归档/tcp建立和释放连接过程三次握手四次挥手.html","title":"tcp建立和释放连接过程三次握手四次挥手.md","keywords":"","body":" 基础知识 三次握手 四次挥手 wireshark 常见面试题 ﻿# TCP建立和释放连接过程三次握手四次挥手 基础知识 上图是tcp的报文格式。 序列号seq：占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号seq就是这个报文段中的第一个字节的数据编号。 确认号ack：占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。 确认ACK：占1位，仅当ACK=1时，确认号字段才有效。ACK=0时，确认号无效 同步SYN：连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。 终止FIN：用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放运输连接。 | 字段 | 含义 | | ---- | :----------------------------------------------------------- | | URG | 紧急指针是否有效。为1，表示需要优先处理。 | | ACK | 确认号是否有效，一般置为1。 | | PSH | 提示接收端应用程序立即从TCP缓冲区把数据读走。 | | RST | 对方要求重新建立连接，复位。 | | SYN | 请求建立连接，并在其序列号的字段进行序列号的初始值设定。建立连接，设置为1。 | | FIN | 希望断开连接。 | 三次握手 第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。 四次挥手 第一次挥手：客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 第二次挥手：服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。 数据传送：客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 第三次挥手：服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 第四次挥手：客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。 结束连接：服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 wireshark 在学习套tcp的过程中，最好结合实际，印象更深刻，推荐使用wireshark进行抓包分析，看着抓的包在对照知识点就非常清晰了。 常见面试题 【问题一】为什么连接的时候是三次握手，关闭的时候却是四次握手？ 答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，\"你发的FIN报文我收到了\"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？ 答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。 【问题3】为什么不能用两次握手进行连接？ 答：3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。现在把三次握手改成仅需要两次握手，死锁是可能发生的。作为例子，考虑计算机S和C之间的通信，假定C给S发送一个连接请求分组，S收到了这个分组，并发 送了确认应答分组。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据分组。可是，C在S的应答分组在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求分组。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据分 组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。 另一种情况，C第一次发送请求没有收到S的返回，结果又发送了一次连接成功了并断开连接。如果这个时候S收到了延迟的第一次的请求，会再次建立连接，这个时候C就不会理会了。这个时候S就会一直等待主机A发送请求，浪费资源。 【问题4】如果已经建立了连接，但是客户端突然出现故障了怎么办？ 答：TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/使用typora自动上传图片到github仓库.html":{"url":"notes/20.10之前归档/使用typora自动上传图片到github仓库.html","title":"使用typora自动上传图片到github仓库.md","keywords":"","body":"gitee上传文件api github上传文件api 这个网址)讲了怎么申请token和使用这个api。 结合typora可以非常方便的利用GitHub搭建一个私人图床。 之前有很多教程是讲的怎么上传到七牛云阿里云等，但是还是不如这个方便而且也非常稳定。 所有xxx的地方都需要替换成你的 import argparse import base64 import random import string import sys import requests import json from urllib.parse import unquote url = 'https://api.github.com/repos/xxx_username_xxx/xxx_仓库名——xxx/contents/img/blog/' headers = {'content-type': 'application/json', 'Authorization': 'Bearer xxx_your_token_xxx'} data = { \"message\": \"\", \"committer\": { \"name\": \"xxx\", \"email\": \"xxx\" }, \"content\": \"\" } image_name = '' if len(sys.argv) == 1: sys.argv.append('--help') parser = argparse.ArgumentParser() parser.add_argument('-s', '--source', type=str, nargs='+', help=\"必须传入文件名参数\", required=True) args = parser.parse_args() image_list = args.source def get_data(img): with open(img, \"rb\") as f: file = f.read() encode_f = base64.b64encode(file) data['content'] = str(encode_f, encoding=\"utf-8\") data['message'] = image_name return data if __name__ == '__main__': for img in image_list: image_name = img.split(\"/\")[-1] if len(image_name) > 50: image_name = ''.join(random.sample(string.ascii_letters + string.digits, 20)) \\ + '.' + image_name.split(\".\")[-1] data = get_data(img) req = requests.put(url=url + image_name, data=json.dumps(data), headers=headers) print(unquote(req.json()['content']['download_url'], 'utf-8')) 自定义命令填入 python3 xxx/upload.py -s -s后面typora会帮你自动填入本地图片路径，使用时直接拖拽图片到typora就自动上传了。 asdf asdf autoindex on; location /video/ { alias /Volumes/新加卷/video/; } new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/写Redis时的并发异常和分布式锁.html":{"url":"notes/20.10之前归档/写Redis时的并发异常和分布式锁.html","title":"写Redis时的并发异常和分布式锁.md","keywords":"","body":"最近公司里有一个并发业务。多个线程消费一个kafka数据流，这个kafka数据流里数据的某个字段有重复。需要根据这个字段来做下去重。 一开始的方案是利用Redis来实现，先查Redis如果没有的话则setex。后来发现这个并不能保证并发安全性，后来的结果还是有重复的数据。 经过分析，发现是有的重复数据相隔极短。比如说A1和A2两条数据。如果A1 get不到，则说明没有，这个时候去写redis。但是还没写进去呢。A2也去get，如果A1还没写进去的话，A2就get不到。这个时候就出现了并发不安全了。 解决方案就是用redis另一个函数。类似于分布式锁的方式。 set(key, value, \"NX\", \"EX\", expireSeconds); // SET IF NOT EXIST，而且还是原子的 // 操作成功，返回“OK”，否则返回null 如果此时返回ok，就说明这个数据不重复，如果返回null，就说明数据不重复。 看jedis的set函数 /** * Set the string value as value of the key. The string can't be longer than 1073741824 bytes (1 * GB). * @param key * @param value * @param nxxx NX|XX, NX -- Only set the key if it does not already exist. XX -- Only set the key * if it already exist. * @param expx EX|PX, expire time units: EX = seconds; PX = milliseconds * @param time expire time in the units of expx * @return Status code reply */ public String set(final String key, final String value, final String nxxx, final String expx, final long time) { checkIsInMultiOrPipeline(); client.set(key, value, nxxx, expx, time); return client.getStatusCodeReply(); } 对应的Redis命令如下 SET resource_name my_random_value NX PX 30000 该命令仅在密钥不存在（NX选项）且到期时间为30000毫秒（PX选项）时才设置密钥。密钥设置为“我的随机值”。该值在所有客户端和所有锁定请求中必须唯一。 基本上，使用随机值是为了以安全的方式释放锁，并且脚本会告诉Redis：仅当密钥存在且存储在密钥上的值恰好是我期望的值时，才删除该密钥。这是通过以下Lua脚本完成的： if redis.call(\"get\",KEYS[1]) == ARGV[1] then return redis.call(\"del\",KEYS[1]) else return 0 end 为了避免删除另一个客户端创建的锁，这一点很重要。例如，一个客户端可能获取了该锁，在某些操作中被阻塞的时间超过了该锁的有效时间（密钥将过期的时间），然后又删除了某个其他客户端已经获取的锁。仅使用DEL是不安全的，因为一个客户端可能会删除另一个客户端的锁。使用上述脚本时，每个锁都由一个随机字符串“签名”，因此仅当该锁仍是客户端尝试将其删除时设置的锁时，该锁才会被删除。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/分布式系统.html":{"url":"notes/20.10之前归档/分布式系统.html","title":"分布式系统.md","keywords":"","body":" 分布式系统理论 cap 理论 分布式系统理论 cap 理论 CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这三个基本需求，最多只能同时满足其中的2个。 原则 描述 一致性 asdf adfa [x] asdf new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/单例模式整理以及相关的知识点.html":{"url":"notes/20.10之前归档/单例模式整理以及相关的知识点.html","title":"单例模式整理以及相关的知识点.md","keywords":"","body":" 懒汉式 1. 单线程 2. 直接使用synchronized但是效率低 3. 双重检验 4. 加volatile 5. 静态内部类方法 饿汉式 1. 饿汉式 2. 枚举方法 [TOC] 单例模式里面其实也是包含很多知识点的，整理一下有助于知识的融会贯通。 单例模式的解决的痛点就是节约资源，节省时间从两个方面看: 1.由于频繁使用的对象，可以省略创建对象所花费的时间，这对于那些重量级的对象而言，是很重要的. 2.因为不需要频繁创建对象，我们的GC压力也减轻了，而在GC中会有STW(stop the world)，从这一方面也节约了GC的时间 单例模式的缺点：简单的单例模式设计开发都比较简单，但是复杂的单例模式需要考虑线程安全等并发问题，引入了部分复杂度。 线程安全 并发性能好 可以延迟加载 序列化/反序列化安全 能抵御反射攻击 饿汉式 Y Y 懒汉不加锁 Y Y 懒汉加锁的 Y Y DCL Y Y Y 静态内部类 Y Y Y 枚举 Y Y Y Y 懒汉式 懒汉式就是他很懒，只有在用的时候才进行实例化。 1. 单线程 public class Singleton { private static Singleton singleton; // 私有的构造方法，不能在外部类实例化 private Singleton() { } public static Singleton getInstance() { if (singleton == null) { singleton = new Singleton(); } return singleton; } } 但是上面这个方法在多线程的情况下就不行了。如果多个线程同时运行到判空的地方。而且单例的确没有被创建。那么两个线程都会创建一个单例。那此时就不是单例了。 2. 直接使用synchronized但是效率低 public class Singleton { private static Singleton singleton; // 私有的构造方法，不能在外部类实例化 private Singleton() { } public synchronized static Singleton getInstance() { if (singleton == null) { singleton = new Singleton(); } return singleton; } } 这样确实可以保证线程安全，但是加锁释放锁是比较耗费性能的。所以这个方法不推荐。 3. 双重检验 public class Singleton { private static Singleton singleton; // 私有的构造方法，不能在外部类实例化 private Singleton() { } public static Singleton getInstance() { // 线程并发问题只有在初始化单例的时候会出现，所以如果实例存在那么就不用加锁了。 if (singleton == null) { synchronized (Singleton.class) { // 实例不存在的时候，先获取锁，但是此时有可能其他线程已经实例化过了。所以再判空。 if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 4. 加volatile public class Singleton { // 这个volatile很关键，下面细讲 private volatile static Singleton singleton; // 私有的构造方法，不能在外部类实例化 private Singleton() { } public static Singleton getInstance() { // 线程并发问题只有在初始化单例的时候会出现，所以如果实例存在那么就不用加锁了。 if (singleton == null) { synchronized (Singleton.class) { // 实例不存在的时候，先获取锁，但是此时有可能其他线程已经实例化过了。所以再判空。 if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 为什么需要volatile呢？ 我们都知道volatile有内存可见性和防止指令重排序的功能。 首先创建对象分为三个步骤： 分配内存空间 初始化对象 将内存空间的地址赋值给对象的引用。 但是JVM可能会对代码进行重排序，所以真正的执行顺序可能是1->3->2。 那么当第一个线程抢到锁执行初始化对象的时候，发生了重排序，这个时候对象还没初始化，但是对象的引用已经不为空了。 当第二个线程遇到第一个判空时，就会直接返回对象，但是第一个线程此时还没执行完初始化对象，就会造成第二个线程拿到的是一个空对象。造成空指针问题。 5. 静态内部类方法 public class Singleton { // 私有的构造方法，不能在外部类实例化 private Singleton() { } public static Singleton getInstance() { return StaticSingletonHolder.singelton; } // 一个私有的静态内部类，用于初始化一个静态final实例 private static class StaticSingletonHolder { private static final Singleton singleton = new Singleton(); } } 加载一个类时，其中内部类不会同时被加载。一个类被加载，仅仅当某个静态成员被调用时发生。由于在调用 StaticSingleton.getInstance() 的时候，才会对单例进行初始化，而且通过反射，是不能从外部类获取内部类的属性的；由于静态内部类的特性，只有在其被第一次引用的时候才会被加载，所以可以保证其线程安全性。 优势：兼顾了懒汉模式的内存优化（使用时才初始化）以及饿汉模式的安全性（不会被反射入侵）。 劣势：需要两个类去做到这一点，虽然不会创建静态内部类的对象，但是其 Class 对象还是会被创建，而且是属于永久代的对象。 饿汉式 1. 饿汉式 public class Singleton { // 这个volatile很关键，下面细讲 private static final Singleton singleton = new Singleton(); // 私有的构造方法，不能在外部类实例化 private Singleton() { } public static Singleton getInstance() { return singleton; } } 在类初始化时，已经自行实例化。 instance什么时候被初始化？ Singleton类被加载的时候就会被初始化，java虚拟机规范虽然没有强制性约束在什么时候开始类加载过程，但是对于类的初始化，虚拟机规范则严格规定了有且只有四种情况必须立即对类进行初始化，遇到new、getStatic、putStatic或invokeStatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。 生成这4条指令最常见的java代码场景是： 1）使用new关键字实例化对象 2）读取一个类的静态字段（被final修饰、已在编译期把结果放在常量池的静态字段除外） 3）设置一个类的静态字段（被final修饰、已在编译期把结果放在常量池的静态字段除外） 4）调用一个类的静态方法 class的生命周期? class的生命周期一般来说会经历加载、连接、初始化、使用、和卸载五个阶段 class的加载机制 这里可以聊下classloader的双亲委派模型。 2. 枚举方法 枚举默认就是线程安全的，所以不需要担心DCL。但能防止反序列化导致重新创建新的对象。即使使用反射机制也无法实例化一个枚举量。 public class Singleton { enum Single { SINGLE; private Single() { } } } new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/如何制作一个自己的图床.html":{"url":"notes/20.10之前归档/如何制作一个自己的图床.html","title":"如何制作一个自己的图床.md","keywords":"","body":"大致分为三部分 服务器 后台 前台new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/常用的消息中间件.html":{"url":"notes/20.10之前归档/常用的消息中间件.html","title":"常用的消息中间件.md","keywords":"","body":" 使用了消息队列有什么缺点？ 常见的消息队列比较（如何选型）？ 如何保证消息队列高可用？ 如何保证消息不被重复消费（如何保证消息队列的幂等性？） 如何保证消费的可靠性传输？ 为什么使用消息中间件？ 解耦 耦合性太强的话可以将消息写入消息队列，需要消息的系统自己从消息队列中订阅。 异步 将消息写入消息队列，非必要的业务逻辑可以以异步的方式运行，加快主体业务的速度。 削峰 并发量大的时候，所以的请求都直接对数据库，造成数据库异常，这个时候可以先把请求放入消息队列中，慢慢读取。 使用了消息队列有什么缺点？ 系统可用性降低 如果消息队列挂掉了，系统肯定就不行了。 系统复杂性增加 加入消息队列需要考虑一些新的东西，比如一致性问题，如何保证消息不被重复消费，如何保证消息可靠性传输等。 常见的消息队列比较（如何选型）？ 特性 ActiveMQ RabbitMQ RocketMQ kafka ZeroMQ 开发语言 java erlang java scala c 单机吞吐量 万级 万级 10万级 10万级 最高 时效性 ms级 us级 ms级 ms级以内 可用性 高(主从架构) 高(主从架构) 非常高(分布式架构) 非常高(分布式架构) 功能特性 成熟的产品，在很多公司得到应用；有较多的文档；各种协议支持较好 基于erlang开发，所以并发能力很强，性能极其好，延时很低;管理界面较丰富 MQ功能比较完备，扩展性佳 只支持主要的MQ功能，像一些消息查询，消息回溯等功能没有提供，毕竟是为大数据准备的，在大数据领域应用广。 内存中使用，不支持数据持久化，金融场景比较多见。 主要有两点： 中小型软件公司，建议选rabbitMQ，e语言天生具备高并发的特性，管理界面用起来十分方便。但是e语言的个性化定制不容易。不选rocketmq和kafka的原因是，数据量没那么大，kafka功能不完备，rocketmq是阿里的，也是不容易进行rocketmq的定制性开发。 大型软件公司，可以在rocketMQ和kafka之间二选一。有足够的资金搭建分布式环境，也具备足够大的数据量。如果有日志采集功能，首选kafka。 如何保证消息队列高可用？ 以RocketMQ为例：他的集群就有多master模式、多master多slave异步复制模式、多master多slave同步双写模式。 感觉这里无非就是多台机器，和zookeeper什么类似。 如何保证消息不被重复消费（如何保证消息队列的幂等性？） 正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发出的确认消息形式不同，例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offet的概念，简单说一下，就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。 如果因为网络传输等故障，确认消息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他消费者。 如何解决？这个问题针对业务场景来答，分以下三种情况： 比如，你拿到这个消息做数据库的insert操作，那就容易了，给这个消息做一个唯一的主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。 再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。 如果上面两种情况还不行，上大招。准备一个第三方介质，来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将以K-V形式写入redis.那消费者开始消费前，先去redis中查询有没有消费记录即可。 如何保证消费的可靠性传输？ 我们在使用消息队列的过程中，应该做到消息不能多消费，也不能少消费。如果无法做到可靠性传输，可能给公司带来千万级别的财产损失。可靠性传输可以从这三个角度来分析。 生产者弄丢数据 消息队列弄丢数据 消费者弄丢数据 生产者丢数据 从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。 transaction机制就是说，发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而会造成吞吐量下降。 消息队列丢数据 处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。 消费者丢数据 消费者丢数据一般是因为采用了自动确认消息模式。这种模式下，消费者会自动确认收到信息。这时rabbitMQ会立即将消息删除，这种情况下，如果消费者出现异常而未能处理消息，就会丢失该消息。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/并发编程常见面试题.html":{"url":"notes/20.10之前归档/并发编程常见面试题.html","title":"并发编程常见面试题.md","keywords":"","body":" 什么是可重入锁？ 当一个线程进入某个对象的一个synchronized的实例方法后，其它线程是否可进入此对象的其它方法？ 乐观锁和悲观锁的理解以及如何实现？ java并发编程 什么是可重入锁？ 线程可以进入任何一个它已经拥有的锁所同步着的代码块。 synchronized和ReentrantLock都是可重入的锁。 当一个线程进入某个对象的一个synchronized的实例方法后，其它线程是否可进入此对象的其它方法？ 如果其他方法没有synchronized的话，其他线程是可以进入的。 所以要开放一个线程安全的对象时，得保证每个方法都是线程安全的。 乐观锁和悲观锁的理解以及如何实现？ 悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/搜索引擎书.html":{"url":"notes/20.10之前归档/搜索引擎书.html","title":"搜索引擎书.md","keywords":"","body":" 前言 倒排索引 搜索引擎 前言 最近在看《自制搜索引擎》这本书，自制xxx系列丛书有很多，之前看过自制操作系统这本书，但是后来感觉有点难懂，确实看不下去了。但是自制系列丛书对于理解比较生涩的原理还是非常有帮助，如果你还在学生时代又对这些底层的原理感兴趣不妨多看看。 接触《自制搜索引擎》这本书纯属意外，开始是因为我在快手实习期间用到了倒排索引这个数据结构，后来了解到搜索引擎的数据就是通过倒排索引来保存的，所以一下子就对搜索引擎的底层原理来了兴趣。通过豆瓣了解到这本书，索性买来看看。 首先说这本书值得一买，里面有原理也有实例，整体上通俗易懂，比较容易理解，只要会一些c语言还有了解一些基本的计算机知识就可以看看。 倒排索引 搜索引擎最基本的是要有数据，数据哪里来，通过爬虫获取，爬虫也是非常有意思的，感兴趣的话可以学学Python爬虫，这本书里面没有这部分，书里面讲的主要是讲的如何构建索引。那数据有了，存哪里，怎么存呢，如何保证数据能够被高效的查找，这是一个问题。拿一篇文章举例，我们一般的想法就是爬虫爬取了一篇文章，直接存到数据库就好了。但是这样会造成一个问题就是在搜索的时候需要从头到尾的查找一遍，时间上会非常慢。这种存储的方式就叫做正排索引，就是把文章标题或者文章ID作为键，文章内容作为值得存储，我们如果知道了标题或者ID可以很快的查找到文章的信息。但是如果想查找某一个关键字就需要遍历所有文章，时间复杂度很大。所以就有了倒排索引，倒排索引就是把某个关键字作为键，而文章ID作为值。举例来说，某个关键字：百度，然后数据库就把百度作为键，值就是出现这个关键字的文章的列表。如果某个人想搜索百度，就可以快速的把出现百度的文章找出来，然后根据一系列的排序算法将文章或网页展示出来。倒排索引的具体实例可以看这篇文章。倒排索引 搜索引擎 一个简单的搜索引擎其实是由几个模块构成的。主要的模块有索引构建器，索引管理器，文章管理器，索引检索器等部分构成。 最主要的还是要构建倒排索引。对于某个文档，要先进行分词，分词又有好多种方法，可以两个三个字等也可以以词语分词。然后根据这些词语构建整个的倒排索引。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/操作系统知识点和面试总结.html":{"url":"notes/20.10之前归档/操作系统知识点和面试总结.html","title":"操作系统知识点和面试总结.md","keywords":"","body":" 问题总结 一、进程和线程的关系以及区别 二、进程间通信有哪些方式？它们的区别？ 几种通信方式的比较 三、线程间的通信机制 比较 四、Windows下的内存是如何管理的 五、中断和轮询的特点 六、什么是临界区、如何解决冲突？ 七、 分段和分页的区别？ 分段机制 分页机制 分段和分页的区别 页面置换算法 八、什么是死锁？产生条件？如何避免死锁 九、进程间同步与互斥的区别，线程同步的方式？ 十、进程的调度算法有哪些？ 操作系统常见的知识点和面试总结 问题总结 进程和线程的关系以及区别 进程间通信有哪些方式？它们的区别？ 线程间的通信机制 Windows下的内存是如何管理的 中断和轮询的特点 什么是临界区、如何解决冲突？ 分段和分页的区别？ 什么是死锁？产生条件？如何避免死锁 进程间同步与互斥的区别，线程同步的方式？ 进程的调度算法有哪些？ 一、进程和线程的关系以及区别 定义： 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位. 　　线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源. 关系 　　一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行. 　　相对进程而言，线程是一个更加接近于执行体的概念，它可以与同进程中的其他线程共享数据，但拥有自己的栈空间，拥有独立的执行序列。 区别 优缺点 线程开销小，但不利于资源的管理和保护；进程与之相反。 协程 协程是单线程下实现多任务，它通过 yield 关键字来实现，能有效地减少多线程之间切换的开销。它是一种比线程更加轻量级的存在。正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。 协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行），性能得到了很大的提升，不会像线程切换那样消耗资源。 异步代码，可能不那么容易理解和调度。 协程共享堆，不共享栈。 协程之间通信：channel。要用通信来共享内存，不要用共享内存来通信。 二、进程间通信有哪些方式？它们的区别？ 管道（pipe）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在有血缘关系的进程间使用，进程的血缘关系通常是指父子进程关系。 命名管道（named pipe）：也是半双工的通信方式，但是它允许无亲缘关系关系进程间通信。 套接字（socket）：套接口也是进程间的通信机制，与其他通信机制不同的是它可用于不同机器间的进程通信。 信号（signal）：是一种比较复杂的通信方式，用于通知接收进程某一事件已经发生。 信号量（semophere）：信号量是一个计数器，可用来控制多个进程对共享资源的访问。它通常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 消息队列（message queue）:消息队列是由消息组成的链表，存放在内核中，并由消息队列标识符标识。消息队列克服了信号传递消息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。 共享内存（shared memory）:就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，共享内存是最快的IPC方式，它是针对其他进程间的通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量等配合使用，来实现进程间的同步和通信。 几种通信方式的比较 管道：速度慢、容量有限 消息队列：容量收到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题。 信号量：不能传递复杂信息，只能用来同步。 共享内存：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全。 三、线程间的通信机制 锁机制：互斥锁、条件变量、读写锁 互斥锁：提供了以排他方式防止数据结构被并发修改的方法。 读写锁：允许多个线程同时读共享数据，而对写操作是互斥的。 条件变量：可以以原子的方式进行阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。 信号量机制：包括无名信号量和命名线程信号量 信号机制：类似进程间的信号处理 比较 线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。 四、Windows下的内存是如何管理的 3种： 虚拟内存： 最适合用来管理大型对象或者结构数组 内存映射文件： 最适合用来管理大型数据流（通常来自文件）以及在单个计算机上运行多个进程之间共享数据 内存堆栈： 最适合用来管理大量的小对象 五、中断和轮询的特点 对I/O设备的程序轮询的方式，是早期的计算机系统对I/O设备的一种管理方式。它定时对各种设备轮流询问一遍有无处理要求。轮流询问之后，有要求的就加以处理。在处理I/O设备的要求之后，处理机返回继续工作。尽管轮询需要时间，但轮询要比I/O设备的速度要快得多，所以一般不会发生不能及时处理的问题。当然，再快的处理机，能处理的输入输出设备的数量也是有一定限度的。而且，程序轮询毕竟占据了CPU相当一部分处理时间，因此程序轮询是一种效率较低的方式，现代计算机系统中已很少应用。 　　轮询效率低，等待时间很长，CPU利用率不高；中断容易遗漏一些问题，CPU利用率高。 六、什么是临界区、如何解决冲突？ 每个进程中访问临界资源的那段程序称为临界区，每次只准许一个进程进入临界区，进入后不允许其他进程进入。如果有若干个进程要求进入空闲的临界区，一次仅允许一个进程进入。任何时候，处于临界区的进程不可多于一个。如已有进程进入自己的临界区，则其他试图进入临界区的进程必须等待。进入临界区的进程要在有限时间内退出，以便其他进程能及时进入自己的临界区。如果不能进入自己的临界区，就应该让出CPU，避免进程出现忙等等现象。 七、 分段和分页的区别？ 分段机制 分段机制就是把虚拟地址空间中的虚拟内存组织成一些长度可变的称为段的内存块单元。 每个段由三个参数定义：段基地址、段限长和段属性。 段的基地址、段限长以及段的保护属性存储在一个称为段描述符的结构项中。 段可以用来存放程序的代码、数据和堆栈，或者用来存放系统数据结构。 系统中所有使用的段都包含在处理器线性地址空间中。 逻辑地址包括一个段选择符或一个偏移量，段选择符是一个段的唯一标识，提供了段描述符表，段描述符表指明短的大小、访问权限和段的特权级、段类型以及段的第一个字节在线性地址空间中的位置（称为段的基地址）。逻辑地址的偏移量部分到段的基地址上就可以定位段中某个字节的位置。因此基地址加上偏移量就形成了处理器线性地址空间中的地址。 分页机制 分页机制在段机制之后进行的，它进一步将线性地址转换为物理地址。 分页机制支持虚拟存储技术，在使用虚拟存储的环境中，大容量的线性地址空间需要使用小块的物理内存（RAM或ROM）以及某些外部存储空间来模拟。当使用分页时，每个段被划分成页面（通常每页为4K大小），页面会被存储于物理内存中或硬盘中。操作系统通过维护一个页目录和一些页表来留意这些页面。当程序（或任务）试图访问线性地址空间中的一个地址位置时，处理器就会使用页目录和页表把线性地址转换成一个物理地址，然后在该内存位置上执行所要求的操作。 分段和分页的区别 1、分页机制会使用大小固定的内存块，而分段管理则使用了大小可变的块来管理内存。 2、分页使用固定大小的块更为适合管理物理内存，分段机制使用大小可变的块更适合处理复杂系统的逻辑分区。 3、段表存储在线性地址空间，而页表则保存在物理地址空间。 页面置换算法 若其所要访问的页面不在内存而需要把它们调入内存，但是内存已无空闲空间时，系统必须从内存中调出一个页面到磁盘对换区中，并且将程序所需要的页面调入内存中。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。 最佳（Optimal） 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。 先进先出（FIFO） 所选择换出的页面是最先进入的页面。 最近最久未使用（LRU, Least Recently Used） 时钟（Clock） Clock 页面置换算法需要用到一个访问位，当一个页面被访问时，将访问为置为 1。 首先，将内存中的所有页面链接成一个循环队列，当缺页中断发生时，检查当前指针所指向页面的访问位，如果访问位为 0，就将该页面换出；否则将该页的访问位设置为 0，给该页面第二次的机会，移动指针继续检查。 八、什么是死锁？产生条件？如何避免死锁 死锁的概念：在2个或多个并发进程中，如果每个进程持有某有资源而又都等待别的进程释放它或他们现在保持的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗地讲，就是2个或多个进程被无限期地阻塞、相互等待的一种状态。 死锁产生的原因：系统资源不足，进程推进顺序非法 产生死锁的必要条件： 互斥条件：一个资源每次只能被一个进程使用 不可剥夺条件：进程已获得资源，在未使用完之前，不能被其他进程强行剥夺，只能主动释放 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。 循环等待条件：即进程集合{p0,p1,p2,p3…..pn};p0正在等待p1占用的资源，p1正在等待p2占用的资源，pn正在等待p0占用的资源。 　只要上述一个条件不成立，就不会发生死锁。 死锁的解除和预防：理解了死锁的原因，以及产生死锁的四个必要条件，就可以最大可能地避免和预防和解锁死锁。所以在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确定资源的合理分配算法，避免进程永久占据系统资源。对资源的分配要给予合理规划 死锁的处理策略：鸵鸟策略、预防策略、避免策略、检测与解除死锁 九、进程间同步与互斥的区别，线程同步的方式？ 互斥：指某一个资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的 同步：是指在互斥的基础上（大多数情况下），通过其它机制实现访问者对资源的有序访问。大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源。 同步：体现的是一种协作性。互斥：体现的是排它性。 进程同步的主要任务：是对多个相关进程在执行次序上进行协调，以使并发执行的诸进程之间能有效地共享资源和相互合作。从而使程序的执行具有可再现性。 线程同步的方式： 　　临界区、互斥量、信号量、事件 　　临界区：通过对多线程的串行化来访问公共资源或者一段代码，速度快，适合控制数据访问。 　　互斥量：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以可以保证公共资源不会同时被多个线程访问。 　　信号量：它允许多个线程同一时刻访问同一资源，但是需要限制同一时刻访问此资源的最大线程数目。信号量对象与其他前面几种方法不同，信号允许多个线程同时使用共享资源。 　　事件（信号）：通过通知操作的方式来保持多线程的同步，还可以方便实现多线程的优先级比较操作。 　　 十、进程的调度算法有哪些？ 先来先服务（FCFS）:此算法的原则是按照作业到达后备作业队列（或进程进入就绪队列）的先后次序选择作业（或进程） 短作业优先（SJF:Shortest Process First）：这种算法主要用于作业调度，它从作业后备序列中挑选所需运行时间最短的作业进入主存运行。 时间片轮转调度算法：当某个进程执行的时间片用完时，调度程序便终止该进程的执行，并将它送到就绪队列的末尾，等待分配下一时间片再执行。然后把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证队列中的所有进程，在已给定的时间内，均能获得一时间片处理机执行时间。 高响应比优先：按照高响应比（已等待时间+要求运行时间）/要求运行时间 优先的原则，在每次选择作业投入运行时，先计算此时后备作业队列中每个作业的响应比RP。选择最大的作业投入运行。 优先权调度算法：按照进程的优先权大小来调度。使高优先权进程得到优先处理的调度策略称为优先权调度算法。注意：优先数越多，优先权越小。 多级队列调度算法：多队列调度是根据作业的性质和类型的不同，将就绪队列再分为若干个队列，所有的作业（进程）按其性质排入相应的队列中，而不同的就绪队列采用不同的调度算法。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/数据库常考点.html":{"url":"notes/20.10之前归档/数据库常考点.html","title":"数据库常考点.md","keywords":"","body":" MySQL锁机制 为什么要加锁？ 数据库事务 transanction MySQL锁机制 为什么要加锁？ 当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。 数据库里的锁分为行、表、页锁。 数据库事务 transanction 数据库事务 transanction 正确执行的四个基本要素。ACID,原子性(Atomicity)、一致性(Correspondence)、隔离性(Isolation)、持久性(Durability)。 （1）原子性：要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 （2）一致性：在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。 （3）隔离性：隔离状态执行事务，使它们好像是系统在给定时间内执行的唯一操作。如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请求，使得在同一时间仅有一个请求用于同一数据。 （4）持久性：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。 springboot声明式事务@Transactional new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/数据库索引.html":{"url":"notes/20.10之前归档/数据库索引.html","title":"数据库索引.md","keywords":"","body":" 索引---------------------------------- 聚簇索引 聚簇索引优点 聚簇索引缺点 非聚簇索引 二级索引（辅助索引） 覆盖索引 Hash索引 自适应hash索引 全文检索 锁--------------------------------------- 事务------------------------------------- 四大事务 事务隔离级别 [toc] 索引---------------------------------- 聚簇索引 索引和数据存储在一块（ 都存储在同一个B*tree 中）。 一般主键索引都是聚餐索引 InnoDB引擎的主键索引为聚簇索引，MyISAM是非聚簇索引 聚簇索引优点 因为聚簇索引页是通过双向链表链接，页按照主键的顺序排序，聚簇索引能针对范围和主键排序进行查找。 聚簇索引更快，非聚簇索引定位到主键后还要多一次目标记录寻址，多一次I/O。 聚簇索引缺点 插入速度严重依赖与顺序。索引对于InnoDB来说。我们一般都会定义一个自增的Id为主键。 更新主键代价高。 二级索引访问需要两次查找。第一次查找主键。第二次找到行。 二级索引存储主键，而不是行指针（非聚簇索引存储指针或者地址），这是为了减少当出现行移动或数据页分裂时候的二级索引维护工作。 插入新值要慢很多。 非聚簇索引 索引数据和存储数据是分离的。 二级索引（辅助索引） 二级索引存储的是记录的主键，而不是数据存储的地址。 以InnoDB为例，主键是聚集索引。 .png) 唯一索引、普通索引、前缀索引等都是二级索引（辅助索引） 一个表中的所有索引除了聚集索引，其他的都是二级索引（secondary index） 通过辅助索引查找数据时，首先遍历辅助索引，找到指向主键索引的主键，在通过主键索引找到一个完整的行记录。 覆盖索引 举个例子，某个数据库建立了联合索引： ALTER TABLE student ADD INDEX idx_name_age(name, age); 如果要执行以下SQL： SELECT age FROM student WHERE name = '小李'； 流程为： 在name,age联合索引树上找到名称为小李的节点 此时节点索引里包含信息age 直接返回 12 此时没有走主索引，所以叫做索引覆盖。 Hash索引 Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升 hash索引只有精确匹配索引所有列的查询才有效。 因为索引自身只需要存储对应该hash值，所以索引结构十分紧凑，速度快的同时也有很多限制。 只包含Hash值和行指针，不存储字段，不能是有索引中的值才避免读取行。 无法用于排序。 (a,b)上简历hash索引，如果只查a，则无法使用该索引。 只支持等值比较，不支持范围查询。 hash冲突。 自适应hash索引 维护索引叶页面中所有记录的索引键值(或键值前缀)到索引叶页面位置的Hash映射关系, 能够根据索引键值(前缀)快速定位到叶页面满足条件记录的Offset，减少了B+树Search Path的代价，将B+树从Root页面至Leaf页面的路径定位，优化为Hash Index的快速查询。 经常访问的二级索引数据会自动被生成到hash索引里面去(最近连续被访问三次的数据)，自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。 全文检索 第一行中B+树索引是可以支持的，但是第二行就必须进行全文索引。 select * from blog where content like 'xxx%'; select * from blog where content like '%xxx%'; InnoDB使用倒排索引来实现全文检索，这也是搜索引擎的核心技术。 锁--------------------------------------- 锁的类型： 共享锁，允许事务读一行数据。 排它锁，允许事务删除或者更新一行数据。 事务------------------------------------- 四大事务 数据库事务的四大特性： 原子性：事务包含的所有数据库操作要么全部成功，要不全部失败回滚 一致性：一个事务执行之前和执行之后都必须处于一致性状态。拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 隔离性：一个事务未提交的业务结果是否对于其它事务可见。级别一般有：read_uncommit，read_commit，read_repeatable，Serializable 串行化访问。 持久性：一个事务一旦被提交了，那么对数据库中数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 事务隔离级别 读未提交（READ UNCOMMITTED）：一个事务还没提交时，它做的变更就能被别的事务看到。 读提交（READ COMMITTED）：一个事务提交之后，它做的变更才会被其他事务看到。 可重复读（REPEATABLE READ）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化（SERIALIZABLE)：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”，当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 隔离级别解决的问题： 脏读（dirty read）：如果一个事务A读到了另一个未提交事务B修改过的数据，这个时候B可能回滚，然后A读到的就是脏数据。 不可重复读（non-repeatable read）（针对update，读取内容）：如果一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值。 幻读（phantom read）（针对insert，delete，数据总量）：事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，成为幻读。 不可重复读和幻读到底有什么区别呢？ (1) 不可重复读是读取了其他事务更改的数据，针对update操作 解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许其他事务更改刚才的数据。 (2) 幻读是读取了其他事务新增的数据，针对insert和delete操作 解决：使用表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，这个时候才允许其他事务新增数据。 这时候再理解事务隔离级别就简单多了呢。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/新买的服务器要做哪些配置.html":{"url":"notes/20.10之前归档/新买的服务器要做哪些配置.html","title":"新买的服务器要做哪些配置.md","keywords":"","body":" 阿里云购买和连接 安装MySQL并配置 安装redis并配置 安装docker DOCKER 配置阿里云镜像加速器 搭建图床 荔枝图床 Chevereto图床 最近买了台阿里云学生机想做点东西，暂定做一个博客。想从头记录一下做这个博客需要的知识和技能。 阿里云购买和连接 我买的是阿里云学生机，比较便宜，9.5一个月。贴一下配置： 用xshell远程连接。记得设置防火墙可访问的端口。 安装MySQL并配置 sudo apt-get install mysql-server sudo apt-get install mysql-client sudo apt-get install libmysqlclient-dev 查看安装成功否sudo netstat -tap | grep mysql 接下来就可以打开数据库了 mysql -uroot -p 现在设置mysql允许远程访问，首先编辑文件/etc/mysql/mysql.conf.d/mysqld.cnf： sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf 注释掉bind-address = 127.0.0.1 保存退出，然后进入mysql服务，执行授权命令： grant all on . to root@'%' identified by '你的密码' with grant option; flush privileges; 然后执行quit命令退出mysql服务，执行如下命令重启mysql： service mysql restart 这样，我们的数据库就可以被远程连接了。 安装redis并配置 sudo apt update sudo apt install redis-server redis命令行：redis-cli 修改redis配置 远程访问： sudo vim /etc/redis/redic.conf # bind 127.0.0.1 protected-mode no #将yes修改成no 重启一下服务： sudo service redis-server restart 远程连接用 RedisDesktop Manager 可视化客户端 安装docker sudo apt-get update sudo apt-get install -y docker.io 允许开机启动： systemctl enable docker 查看是否安装成功： docker version DOCKER 配置阿里云镜像加速器 因为买的学生机所以只有5M带宽，最好配置一下阿里云镜像加速，走的是阿里云内网会快很多。 打开阿里云控制台。 打开容器镜像服务->镜像加速器->复制加速器地址 修改配置文件 vim /etc/docker/daemon.json 加入 { \"registry-mirrors\": [\"https://你的值.mirror.aliyuncs.com\"] } 最后 systemctl daemon-reload systemctl restart docker 搭建图床 荔枝图床 我用的是荔枝图床。还有国内的一个https://sm.ms/也不错，不过我还是喜欢自己建一个。 安装docker，已经说过了。 把镜像拉下来：docker image pull kdelfour/lychee-docker 启动这个镜像。完整命令：docker run -it -d -p 9001:80 kdelfour/lychee-docker（访问 9001 端口，映射到 docker 容器里边的 80 端口）。 命令 docker container ls 是查看正在运行的容器。可以看到第一次用这个命令的时候，没有容器在跑；启动之后就有了。 访问http://你的地址:9001。按照提示信息填写就可以了。 最后附上卸载方式： 先停止运行的容器：docker container stop [container-id] 然后删除容器：docker container rm [container-id] 最后删除镜像：docker image rmi [image-id] 获取对应的 id 可以通过命令：docker container ls 和 docker image ls。 Chevereto图床 后来发现荔枝图床的功能太少了，我又找了这个，功能非常多，安装也很方便，同样是使用docker安装。 中文文档地址：https://ch.cndrew.cn/cn/Setup/Install/ 我同样是用docker安装的。安完docker之后在安装docker-compose apt install docker-compose mkdir cheverto/ cd cheverto vim docker-compose.yaml 在docker-compose.yaml 增加如下内容 version: '3' services: db: image: mariadb volumes: - database:/var/lib/mysql:rw restart: always networks: - private environment: MYSQL_ROOT_PASSWORD: chevereto_root MYSQL_DATABASE: chevereto MYSQL_USER: chevereto MYSQL_PASSWORD: chevereto chevereto: depends_on: - db image: nmtan/chevereto restart: always networks: - private environment: CHEVERETO_DB_HOST: db CHEVERETO_DB_USERNAME: chevereto CHEVERETO_DB_PASSWORD: chevereto CHEVERETO_DB_NAME: chevereto CHEVERETO_DB_PREFIX: chv_ volumes: - chevereto_images:/var/www/html/images:rw ports: - 8080:80 networks: private: volumes: database: chevereto_images: 之后我只把端口改了改，其他的随意。 docker-compose up 或者 nohup docker-compose up &> run.log &disown 然后打开http://你的地址:你的端口 就可以了。 下面是截图 上传图片之后会有各种链接，使用方便： api上传：GET http://mysite.com/api/1/upload/?key=12345&source=http://somewebsite/someimage.jpg&format=json 文档地址：https://ch.cndrew.cn/cn/API/API%20V1/ PS1='${debian_chroot:+($debian_chroot)}[\\033[01;32;40m]\\u[\\033[00;00;40m]@[\\033[01;32;40m]\\h[\\033[00;32;40m]:[\\033[00;00;40m]\\w [\\033[01;33;40m]$ [\\033[01;36;40m]'new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/新建springboot项目.html":{"url":"notes/20.10之前归档/新建springboot项目.html","title":"新建springboot项目.md","keywords":"","body":" springboot热部署 真正的热部署 swagger 阿里云OSS 自己作图床。 springboot热部署 热部署依赖：https://blog.csdn.net/liu_shi_jun/article/details/79985575 org.springframework.boot spring-boot-devtools org.springframework.boot spring-boot-maven-plugin true debug: true spring: devtools: restart: enabled: true #设置开启热部署 freemarker: cache: false #页面不加载缓存，修改即时生效 但我觉得用处不太大，不知道什么时候他会更新，大多数不需要的时候刷新还会报错。 真正的热部署 因为要编辑前端用到thymleaf， 每次都要重启项目非常麻烦。开启idea的热部署会非常方便。更改html文件reload一下，大概两三秒就可以了。更改java代码还是会重启但是比自己重启会快一些。 在设置Compiler里勾选Build project automatically。->之后按住Ctrl+shift+alt+/进入Redistry，勾选compiler.automake.allow.when.app.running。就可以了，然后在工具栏run->里Reload changed class可以手动热部署。 swagger 参考https://www.jianshu.com/p/05be40b9a7a3 io.springfox springfox-swagger2 2.9.2 io.springfox springfox-swagger-ui 2.9.2 package xyz.dsvshx.blog.config; import io.swagger.annotations.Api; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 public class Swagger2Configuration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.withClassAnnotation(Api.class))//这是注意的代码 .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"Blog接口文档\") .description(\"Blog相关接口的文档\") .termsOfServiceUrl(\"http://www.dsvshx.xyz\") .version(\"1.0\") .build(); } } 注意的这行代码：apis(RequestHandlerSelectors.withClassAnnotation(Api.class)),这个代码说明的我们扫描的哪些接口，我这行意思是扫描带@Api注解的接口类，这里selector有5个方法来应对扫描需求，其中basePackage()方法是按照接口类所在的包的位置(在我的代码中这里就应该填“ cn.zh.demo.controller”）,需多的人说这个配置类应该与Application类在同一级目录，但是我实际测试是不需要的，放在自己想要的放的位置即可。 @Api： 描述 Controller @ApiIgnore： 忽略该 Controller，指不对当前类做扫描 @ApiOperation： 描述 Controller类中的 method接口 @ApiParam： 单个参数描述，与 @ApiImplicitParam不同的是，他是写在参数左侧的。如（ @ApiParam(name=\"username\",value=\"用户名\")Stringusername） @ApiModel： 描述 POJO对象 @ApiProperty： 描述 POJO对象中的属性值 @ApiImplicitParam： 描述单个入参信息 @ApiImplicitParams： 描述多个入参信息 @ApiResponse： 描述单个出参信息 @ApiResponses： 描述多个出参信息 @ApiError： 接口错误所返回的信息 @Api(value = \"AdminUserController \") @RestController @RequestMapping(\"/admin/user\") public class AdminUserController extends BaseController { /** * 用户登录 */ @ApiOperation(value = \"登录\") @ApiImplicitParams({@ApiImplicitParam(name = \"userName\", value = \"用户名\", required = true, dataType = \"String\"), @ApiImplicitParam(name = \"password\", value = \"密码\", required = true, dataType = \"String\")}) @PostMapping(\"/login\") @SystemControllerLog(description = \"/admin/user/login\") public ResultVO login(String userName, String password){} https://blog.csdn.net/xtj332/article/details/80595768 配置了fastjson出现了访问不到的情况，上面是解决方案。 阿里云OSS 自己作图床。 一、原理分析 浏览器提供了 copy 命令 ，可以复制选中的内容 document.execCommand(\"copy\") 如果是输入框，可以通过 select() 方法，选中输入框的文本，然后调用 copy 命令，将文本复制到剪切板 但是 select() 方法只对 和 有效，对于 就不好使 最后我的解决方案是，在页面中添加一个 ，然后把它隐藏掉 点击按钮的时候，先把 的 value 改为 的 innerText，然后复制 中的内容 二、代码实现 https://www.cnblogs.com/wisewrong/p/7473978.html HTML 部分 .wrapper {position: relative;} #input {position: absolute;top: 0;left: 0;opacity: 0;z-index: -10;} 我把你当兄弟你却想着复制我？ 这是幕后黑手 copy ;) JS 部分 function copyText() { var text = document.getElementById(\"text\").innerText; var input = document.getElementById(\"input\"); input.value = text; // 修改文本框的内容 input.select(); // 选中文本 document.execCommand(\"copy\"); // 执行浏览器复制命令 alert(\"复制成功\"); } 我觉得可以自己做一个图床啊，实现原理很简单就是后台就一两个接口，前端就是显示图片加上链接，可以有一个复制功能。这就很简单了。有时间可以试一试。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/系统架构设计.html":{"url":"notes/20.10之前归档/系统架构设计.html","title":"系统架构设计.md","keywords":"","body":" https://www.jianshu.com/p/9389301b0bc8 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/经验教训.html":{"url":"notes/20.10之前归档/经验教训.html","title":"经验教训.md","keywords":"","body":"1.一定要是最新版本的，网上搜的好多依赖不是最新版本所以会报各种莫名其妙的错。所以不妨在maven仓库上搜最新版本的依赖。一般搜 名字+maven就会出现。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/计算机网络常见面试题.html":{"url":"notes/20.10之前归档/计算机网络常见面试题.html","title":"计算机网络常见面试题.md","keywords":"","body":" OSI，TCP/IP，五层协议的体系结构，以及各层协议 1. 物理层 2. 数据链路层 3. 网络层 4. 传输层 5. 会话层 6. 表示层 7. 应用层 应用层和传输层的关系 tcp和udp的区别 TCP中的流量控制和拥塞控制--tcp如何保证传输的可靠性 DNS域名系统，简单描述其工作原理。 在浏览器输入 URL 回车之后发生了什么？ 1）URL解析 2）DNS查询 3）TCP连接 4）服务器处理请求 5）浏览器接受响应 6）渲染页面 Socket 1.什么是Socket？比较好的一个网站 HTTP与HTTPS区别 http长连接与短连接 session和cookies的区别 Token 计算机网络常见面试题 OSI，TCP/IP，五层协议的体系结构，以及各层协议 1. 物理层 激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性。该层为上层协议提供了一个传输数据的可靠的物理媒体。简单的说，物理层确保原始的数据可在各种物理媒体上传输。物理层记住两个重要的设备名称，中继器（Repeater，也叫放大器）和集线器。 2. 数据链路层 数据链路层在物理层提供的服务的基础上向网络层提供服务，其最基本的服务是将源自网络层来的数据可靠地传输到相邻节点的目标机网络层。所以这一层需要： 如何将数据组合成数据块，在数据链路层中称这种数据块为帧（frame），帧是数据链路层的传送单位；如何控制帧在物理信道上的传输，包括如何处理传输差错，如何调节发送速率以使与接收方相匹配；以及在两个网络实体之间提供数据链路通路的建立、维持和释放的管理。 数据链路层在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等 。主要的协议是以太网协议，设备主要是网桥和交换机。 3. 网络层 网络层的目的是实现两个主机系统之间的数据透明传送，具体功能包括寻址和路由选择、连接的建立、保持和终止等。它提供的服务使传输层不需要了解网络中的数据传输和交换技术。如果您想用尽量少的词来记住网络层，那就是“路径选择、路由及逻辑寻址”。 最重要的协议，也是TCP/IP的核心协议——IP协议。IP协议非常简单，仅仅提供不可靠、无连接的传送服务。IP协议的主要功能有：无连接数据报传输、数据报路由选择和差错控制。与IP协议配套使用实现其功能的还有地址解析协议ARP、逆地址解析协议RARP、因特网报文协议ICMP、因特网组管理协议IGMP。 网络层基本数据单位为ip数据报。重要的设备有路由器。 4. 传输层 传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。 传输层的任务是根据通信子网的特性，最佳的利用网络资源，为两个端系统的会话层之间，提供建立、维护和取消传输连接的功能，负责端到端的可靠数据传输。在这一层，信息传送的协议数据单元称为段或报文。作用：为应用进程之间提供端到端的逻辑通信。 网络层只是根据网络地址将源结点发出的数据包传送到目的结点，而传输层则负责将数据可靠地传送到相应的端口。 包含的主要协议：TCP协议（Transmission Control Protocol，传输控制协议）、UDP协议（User Datagram Protocol，用户数据报协议）。重要的设备有网关。 5. 会话层 会话层管理主机之间的会话进程，即负责建立、管理、终止进程之间的会话。会话层还利用在数据中插入校验点来实现数据的同步。 6. 表示层 表示层对上层数据或信息进行变换以保证一个主机应用层信息可以被另一个主机的应用程序理解。表示层的数据转换包括数据的加密、压缩、格式转换等。 7. 应用层 为用户的应用程序提供网络服务的接口。将用户的操作通过应用程序转换成为服务，并匹配一个相应的服务协议发送给传输层。基本单位为报文。 注：我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议。 层 协议 设备 物理层 RJ45、CLOCK、IEEE802.3 中继器，集线器，网关 数据链路 PPP、FR、HDLC、VLAN、MAC 网桥，交换机 网络层 IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP 路由器 传输层 TCP、UDP、SPX 会话层 NFS、SQL、NETBIOS、RPC 表示层 JPEG、MPEG、ASCII 应用层 FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS 应用层和传输层的关系 传输层协议添加端口就可以标识应用层协议。应用层协议代表着服务器上的服务，服务器上的服务如果对客户端提供服务，必须在TCP或UDP端口侦听客户端的请求。 传输层的协议TCP或UDP加上端口就可以标识一个应用层协议，TCP/IP协议中的端口范围是从0～65535。 IP 地址与网络服务的关系是一对多的关系。实际上是通过\"IP地址+端口号\"来区分不同的服务的。 tcp和udp的区别 TCP面向连接，UDP面向非连接即发送数据前不需要建立链接 TCP提供可靠的服务（数据传输），UDP无法保证 TCP面向字节流，UDP面向报文 TCP数据传输慢，UDP数据传输快 TCP提供一种面向连接的、可靠的字节流服务 在一个TCP连接中，仅有两方进行彼此通信，因此广播和多播不能用于TCP TCP使用校验和，确认和重传机制来保证可靠传输 TCP使用累积确认 TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制 TCP中的流量控制和拥塞控制--tcp如何保证传输的可靠性 流量控制主要针对的是端到端传输中控制流量大小并保证传输可靠性（未收到ack就不滑动）。流量控制往往是指点对点通信量的控制，所要做的是抑制发送端发送数据的速率，要让接收方来得及接收。 利用滑动窗口可以非常方便的实现流量控制。 拥塞控制主要是一个全局性过程，涉及到所有主机，路由器，以及与降低网络传输性能有关的所有因素。防止过多的数据注入到网络中。如果有发生丢包则通过拥塞控制减小窗口，确定出合适(慢启动 拥塞避免 快重传 快恢复)的拥塞窗口（增性加乘性减）。 DNS域名系统，简单描述其工作原理。 在浏览器输入 URL 回车之后发生了什么？ URL 解析 DNS 查询 TCP 连接 处理请求 接受响应 渲染页面 1）URL解析 首先判断你输入的是一个合法的 URL 还是一个待搜索的关键词，并且根据你输入的内容进行自动完成、字符编码等操作。 2）DNS查询 浏览器会先检查是否在缓存中，没有则调用系统库函数进行查询。 操作系统也有自己的 DNS缓存，但在这之前，会向检查域名是否存在本地的 Hosts 文件里，没有则向 DNS 服务器发送查询请求。 路由器也有自己的缓存。 ISP DNS 就是在客户端电脑上设置的首选 DNS 服务器，它们在大多数情况下都会有缓存。 3）TCP连接 1. 应用层：发送 HTTP 请求 在前面的步骤我们已经得到服务器的 IP 地址，浏览器会开始构造一个 HTTP 报文，其中包括： 请求报头（Request Header）：请求方法、目标地址、遵循的协议等等 请求主体（其他参数） 其中需要注意的点： 浏览器只能发送 GET、POST 方法，而打开网页使用的是 GET 方法，ajax可以发送别的请求。 2. 传输层：TCP传输报文 传输层会发起一条到达服务器的 TCP 连接，为了方便传输，会对数据进行分割（以报文段为单位），并标记编号，方便服务器接受时能够准确地还原报文信息。在建立连接前，会先进行 TCP 三次握手。结束之后是四次挥手。 HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层（网络层）的IP地址查找目的端。 3. 网络层：IP协议查询Mac地址 将数据段打包，并加入源及目标的IP地址，并且负责寻找传输路线。 判断目标地址是否与当前地址处于同一网络中，是的话直接根据 Mac 地址发送，否则使用路由表查找下一跳地址，以及使用 ARP 协议查询它的 Mac 地址。 4. 链路层：以太网协议 以太网协议 根据以太网协议将数据分为以“帧”为单位的数据包，每一帧分为两个部分： 标头：数据包的发送者、接受者、数据类型 数据：数据包具体内容 Mac 地址 以太网规定了连入网络的所有设备都必须具备“网卡”接口，数据包都是从一块网卡传递到另一块网卡，网卡的地址就是 Mac 地址。每一个 Mac 地址都是独一无二的，具备了一对一的能力。 广播 发送数据的方法很原始，直接把数据通过 ARP 协议，向本网络的所有机器发送，接收方根据标头信息与自身 Mac 地址比较，一致就接受，否则丢弃。 4）服务器处理请求 HTTPD 最常见的 HTTPD 有 Linux 上常用的 Apache 和 Nginx，以及 Windows 上的 IIS。 处理请求 接受 TCP 报文后，会对连接进行处理，对HTTP协议进行解析 5）浏览器接受响应 浏览器接收到来自服务器的响应资源后，会对资源进行分析。 首先查看 Response header，根据不同状态码做不同的事（比如上面提到的重定向）。 如果响应资源进行了压缩（比如 gzip），还需要进行解压。 然后，对响应资源做缓存。 6）渲染页面 不同的浏览器内核，渲染过程也不完全相同，但大致流程都差不多。 Socket 1.什么是Socket？比较好的一个网站 上面我们已经知道网络中的进程是通过socket来通信的，那什么是socket呢？socket起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，都可以用“打开open –> 读写write/read –> 关闭close”模式来操作。我的理解就是Socket就是该模式的一个实现，socket即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭）。 三次握手发生在socket的那几个函数中呢？ HTTP与HTTPS区别 https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。 http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 http长连接与短连接 在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。本质还是tcp和长连接和短连接。 session和cookies的区别 http是无状态的协议，所以服务器就给每个用户颁发一个通行证，每次请求就带上自己的通行证。cookie数据存放在客户的浏览器上，session数据放在服务器上。 cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,考虑到安全应当使用session。 session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能,考虑到减轻服务器性能方面，应当使用COOKIE，session是基于Cookie技术实现，重启浏览器后再次访问原有的连接依然会创建一个新的session，因为Cookie在关闭浏览器后就会消失，但是原来服务器的Session还在，只有等到了销毁的时间会自动销毁。Session是保存在服务器端上会存在一段时间才会消失，如果session过多会增加服务器的压力 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。 所以个人建议： 将登陆信息等重要信息存放为SESSION 其他信息如果需要保留，可以放在COOKIE中 spring-session 用到了redis，session存储到redis里面，可以共享session。在服务器集群的场景下可以使用。 Token 一般在前后端分离的时候会用到。Token 是在服务端产生的。如果前端使用用户名/密码向服务端请求认证，服务端认证成功，那么在服务端会返回 Token 给前端。前端可以在每次请求的时候带上 Token 证明自己的合法地位。如果这个 Token 在服务端持久化（比如存入数据库），那它就是一个永久的身份令牌。Token可以减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.10之前归档/设计模式常考点.html":{"url":"notes/20.10之前归档/设计模式常考点.html","title":"设计模式常考点.md","keywords":"","body":" dingleton（单例模式） factory（简单工厂模式） Proxy（代理模式） Adapter（适配器模式）别名包装器(Wrapper) Strategy（策略模式） Template（模板模式） 举例说明你什么时候会用抽象类，什么时候更愿意使用接口？ 设计模式非常多而且有些不容易理解，需要结合实践来进行学习，这一部分是需要长期的积累的，光背概念是很难学会设计模式的。如果面试的话，还是结合理解，用几句话描述一下就可以。 dingleton（单例模式） 一句话总结：一个类在Java虚拟机中只有一个对象，并提供一个全局访问点。 解决问题：对象的唯一性，性能问题。 项目里怎么用：数据库连接对象，属性配置文件的读取对象。 模式结构：饿汉式和懒汉式（考虑性能用懒汉式，方法里面进行初始化，如果对象为null则初始化，饿汉式是在成员变量初始化）。构造器私有化，对外提供方法加同步关键字。 factory（简单工厂模式） 一句话总结：用一个方法来代替new关键字 解决问题：对象产生过多，或者经常有子类替换生成。 项目里怎么用：对于经常生成的对象，或者父子类替换的对象。 模式结构：写一个对外声明的方法，方法里面使用new关键字代替。 框架：spring的核心就是工厂模式。 public class UserFactory { public static User createUser(int i){ //如果输入的是1，就创建它的子类，否则就创建父类 if(i==1){ return new Alices(); } return new User(); } } Proxy（代理模式） 一句话总结：为其它对象提供一个代理，以控制对当前对象的访问。 解决问题：不能直接访问该对象，或者太大的资源耗费。 项目里面怎么用：权限，或者大对象的访问权限。 模式结构：代理类河北代理类实现同一个接口，用户访问的时候先访问代理对象，然后让代理对象去访问被代理对象（代理类里面持有一个被代理类的对象，方法都是一样的）。 框架里面的使用：spring里面的AOP。 Adapter（适配器模式）别名包装器(Wrapper) 一句话总结：将两个原来不兼容的类兼容起来一起工作。 例子：变压器、充电器。 解决问题：已经存在相同功能的代码，单室接口不兼容，不能直接调用。 项目里面怎么用：在使用旧的api的时候，没有源码，和新的不能兼容。 模式结构：分为类适配器和对象适配，一般常用的是对象适配器，组合优于继承。适配者类实现目标抽象类继承被适配类并调用被适配类的方法。或者把被适配类作为一个成员属性，而不是继承。 框架里面使用：单元测试里的assertEquels。 适配器模式 Strategy（策略模式） 一句话总结： 定义一系列算法并可以相互替换。 解决什么问题：做一件事情有很多方法。 项目里怎么用：购物车里面的付款方式。 模式结构：声明一个顶级接口，定义一个策略方法，具体的实例都要实现这个接口。（这不就是多态吗） 框架里面使用：hibernate的主键生成策略。 Template（模板模式） 一句话总结：父类定义流程，子类实现流程。 生活中的例子：iphone生产有多个国家，但流程只有一个。 解决什么问题：业务有多种，但都有规定的流程。 项目里面怎么用：一般基类的实现都是模板模式，BaseDAO 模式结构：定义一个抽象父类定义流程，或者常用方法和常量，子类继承父类，实现具体的细节方法。 框架：hibernate里面的方言，是跨数据库的基础。 JDK里面：IO流里面的inputStream，Writer等。 举例说明你什么时候会用抽象类，什么时候更愿意使用接口？ 抽象类是一种模板，而接口是一种规范 java只能继承一个类，但可以实现多个接口。 接口是用来代表形容词或行为，例如Runnable、Clonable、Serializable等。因此，如果您使用一个抽象类来实现Runnable和Clonacle，你就不可以使你的类同时实现这两个功能，而如果接口的话就没问题。 抽象类是比接口稍快，所以很在乎时间的应用尽量使用抽象类。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/":{"url":"notes/20.11/","title":"20.11","keywords":"","body":" HTTPS cheat_sh.md docker.md java.io.Closeable接口.md java测试.md lambda和stream.md nginx.md spring启动流程（敖丙公众号）.md 分布式 手写一个AQS.md 计算机启动过程.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/HTTPS/":{"url":"notes/20.11/HTTPS/","title":"HTTPS","keywords":"","body":" https原理.md 如何让自己的网站支持https.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/HTTPS/https原理.html":{"url":"notes/20.11/HTTPS/https原理.html","title":"https原理.md","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/HTTPS/如何让自己的网站支持https.html":{"url":"notes/20.11/HTTPS/如何让自己的网站支持https.html","title":"如何让自己的网站支持https.md","keywords":"","body":" 如何让你的网站支持https? 申请证书 配置NGINX [TOC] 如何让你的网站支持https? 申请证书 SSL 证书通常需要购买，也有免费的，通过第三方 SSL 证书机构颁发。你也可以在云服务商上购买，但是一般免费的 ssl 证书只能支持单个域名。 我用的是阿里云的SSL证书，可以申请免费的。地址如下： https://common-buy.aliyun.com/?spm=5176.2020520154.0.0.1f8956a7lXJtr0&commodityCode=cas 下载证书，我选的是NGINX版本。 下载下来是两个文件，一个是.pem文件，一个是.key文件。把这两个文件上传到服务器，我是放在nginx/ssl目录下。接下来就配置nginx就可以了。 配置NGINX 直接把我的复制过来： user www-data; worker_processes auto; pid /run/nginx.pid; events { worker_connections 768; # multi_accept on; } http { server { listen 80; listen 443 ssl; server_name www.example.com; ssl_certificate /etc/nginx/ssl/xxx.pem; # 你的pem和key文件的路径 ssl_certificate_key /etc/nginx/ssl/xxx.key; location / { root /etc/nginx/html; index index.html; } } sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; include /etc/nginx/mime.types; default_type application/octet-stream; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; gzip on; gzip_disable \"msie6\"; include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } 现在重启NGINX访问网站就可以使用https了，访问http也会自动跳转到https。 参考： https://juejin.im/post/6844904063688179720new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/cheat_sh.html":{"url":"notes/20.11/cheat_sh.html","title":"cheat_sh.md","keywords":"","body":"curl cht.sh/[command] new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/docker.html":{"url":"notes/20.11/docker.html","title":"docker.md","keywords":"","body":" docker常用命令 Docker简介 安装 常用命令 搜索镜像 下载镜像 查看镜像版本 列出镜像 删除镜像 打包镜像 Docker容器常用命令 新建并启动容器 列出容器 停止容器 强制停止容器 启动容器 进入容器 删除容器 查看容器的日志 修改容器的启动方式 同步宿主机时间到容器 指定容器时区 查看容器资源占用状况 查看容器磁盘使用情况 执行容器内部命令 指定账号进入容器内部 查看所有网络 创建外部网络 指定容器网络 修改镜像的存放位置 [TOC] docker常用命令 Docker简介 Docker是一个开源的应用容器引擎，让开发者可以打包应用及依赖包到一个可移植的镜像中，然后发布到任何流行的Linux或Windows机器上。使用Docker可以更方便地打包、测试以及部署应用程序。 安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors（配置国内镜像加速） 常用命令 搜索镜像 docker search java 下载镜像 docker pull java:8 查看镜像版本 由于docker search命令只能查找出是否有该镜像，不能找到该镜像支持的版本，所以我们需要通过Docker Hub来搜索支持的版本。 进入Docker Hub的官网，地址：https://hub.docker.com，然后搜索需要的镜像，查看版本。 下载镜像： docker pull nginx:1.17.0 列出镜像 docker images 删除镜像 指定名称删除镜像： docker rmi java:8 指定名称删除镜像（强制）： docker rmi -f java:8 删除所有没有引用的镜像： docker rmi `docker images | grep none | awk '{print $3}'` 强制删除所有镜像： docker rmi -f $(docker images) 打包镜像 # -t 表示指定镜像仓库名称/镜像名称:镜像标签 .表示使用当前目录下的Dockerfile文件 docker build -t mall/mall-admin:1.0-SNAPSHOT . Docker容器常用命令 新建并启动容器 docker run -p 80:80 --name nginx \\ -e TZ=\"Asia/Shanghai\" \\ -v /mydata/nginx/html:/usr/share/nginx/html \\ -d nginx:1.17.0 -p：将宿主机和容器端口进行映射，格式为：宿主机端口:容器端口； --name：指定容器名称，之后可以通过容器名称来操作容器； -e：设置容器的环境变量，这里设置的是时区； -v：将宿主机上的文件挂载到宿主机上，格式为：宿主机文件目录:容器文件目录； -d：表示容器以后台方式运行。 [OPTIONS] 参数说明： --add-host list 添加自定义主机到ip映射(书写格式为：主机:ip) -a, --attach list 附加到STDIN、STDOUT或STDERR上 --blkio-weight uint16 Block IO (相对权重)，取值10到1000之间，0为禁用(默认0) --blkio-weight-device list Block IO weight (相对于设备的权重) (默认为数组的形式) --cap-add list 添加Linux功能 --cap-drop list 删除Linux功能 --cgroup-parent string 容器的可选父级对照组项 --cidfile string 将容器ID写入文件 --cpu-period int 限制CPU CFS(完全公平调度程序)周期 --cpu-quota int 限制CPU CFS(完全公平的调度程序)上限 --cpu-rt-period int 限制CPU运行时周期(以微秒为单位) --cpu-rt-runtime int 限制CPU实时运行时间(以微秒为单位) -c, --cpu-shares int CPU 共享 (相对权重的设定) --cpus decimal 设定cpu的数量 --cpuset-cpus string 允许执行的cpu (0-3,0,1) --cpuset-mems string 允许执行的MEMs (0-3,0,1) -d, --detach 在后台运行容器并打印容器ID --detach-keys string 覆盖分离容器的键序列 --device list 向容器添加主机设备 --device-cgroup-rule list 向 cgroup 允许的设备列表中添加一个或多个规则 --device-read-bps list 限定设备的读取速率（单位: byte/s）（默认为 []） --device-read-iops list 限定设备的读取速率（单位：IO/s）（默认为 []） --device-write-bps list 限定设备的写入速率（单位: byte/s）（默认为 []） --device-write-iops list 限定设备的写入速率（单位：IO/s）（默认为 []） --disable-content-trust 跳过镜像验证(默认为 true) --dns list 设置自定义DNS服务器 --dns-option list 设置DNS选项 --dns-search list 设置自定义的DNS搜索域 --entrypoint string 覆盖镜像的默认入口点 -e, --env list 设置环境变量 --env-file list 读取环境变量内容 --expose list 公开一个端口或多个端口 --group-add list 添加其他要加入的组 --health-cmd string 命令运行以检查健康 --health-interval duration 运行检查之间的时间(ms\\ s\\ m\\ h)(默认为 0s) --health-retries int 连续的失败需要报告不健康 --health-start-period duration 启动健康重试倒计时前容器初始化的启动周期(ms\\ s\\ m\\ h)(默认为 0s) --health-timeout duration 健康检查运行情况的最大时间值 格式为：(ms\\ s\\ m\\ h) (默认 0s) --help 打印出使用情况 -h, --hostname string 定义容器主机名 --init 在容器中运行初始化，以转发信号并获取进程 -i, --interactive 即使没有连接，也保持STDIN开放 --ip string 设定容器的 IPv4 地址 (例如，192.168.155.139) --ip6 string 设定IPv6地址(例如，2001:db8::33) --ipc string 使用IPC模式 --isolation string 容器隔离技术 --kernel-memory bytes 内核内存限制 -l, --label list 在容器上设置元数据 --label-file list 在以行分隔的标签文件中读取 --link list 向另一个容器添加链接 --link-local-ip list 容器 IPv4/IPv6 链接本地地址 --log-driver string 设定容器的日志驱动 --log-opt list 设定日志驱动器选项 --mac-address string 配置容器MAC地址(例如，92:d0:c6:0a:29:33) -m, --memory bytes 设定内存限额 --memory-reservation bytes 内存软限制 --memory-swap bytes 交换限制等于内存加上交换:'-1'，以启用无限交换 --memory-swappiness int 优化容器内存交换 (0 到 100) (默认为 -1) --mount mount 将文件系统挂载附加到容器 --name string 为容器指定一个名称 --network string 将容器连接到网络 --network-alias list 为容器连接的网络添加别名 --no-healthcheck 禁止任何容器指定 HEALTHCHECK --oom-kill-disable 禁止OOM事件被杀死 --oom-score-adj int 优化主机的OOM事件 ，参数范围 (-1000 到 1000) --pid string 设定PID命名 --pids-limit int 优化容器pid限制(如果设置-1则为无限制) --privileged 赋予容器扩展的权限 -p, --publish list 将容器的端口发布到主机 -P, --publish-all 将所有公开的端口发布到随机端口 --read-only 将容器的根文件系统挂载为只读（后面会详细讲到） --restart string 配置容器的重启策略，当容器退出时重新启动(默认为“no”) --rm 当容器退出时自动移除这个容器 --runtime string 使用容器的运行时 --security-opt list 指定docker启动的安全项 --shm-size bytes /dev/shm 的大小（这个可以使其容量进行动态的扩展） --sig-proxy 设置代理接收京城信号 (默认为 true) --stop-signal string 停止容器的信号 (默认为 \"SIGTERM\") --stop-timeout int 设置超时停止容器(以秒为单位) --storage-opt list 设定容器的存储驱动程序选项 --sysctl map 指定系统控制项 (默认为 map[] 的格式) --tmpfs list 挂载tmpfs目录 -t, --tty 为当前容器分配一个客户端 --ulimit ulimit 启动需要限制的项(默认为数组的形式) -u, --user string 用户名或UID(格式为: uid>[: gid>]) --userns string 使用用户名称空间 --uts string 使用UTS名称空间 -v, --volume list 绑定安装卷（关于容器卷，在Docker容器数据卷中会具体的讲解） --volume-driver string 容器的可选卷驱动程序 --volumes-from list 指定容器装载卷 -w, --workdir string 容器内的工作目录 列出容器 列出运行中的容器： docker ps 列出所有容器： docker ps -a 停止容器 注意：$ContainerName表示容器名称，$ContainerId表示容器ID，可以使用容器名称的命令，基本也支持使用容器ID，比如下面的停止容器命令。 docker stop $ContainerName(or $ContainerId) 例如： docker stop nginx #或者 docker stop c5f5d5125587 强制停止容器 docker kill $ContainerName 启动容器 docker start $ContainerName 进入容器 https://blog.csdn.net/skh2015java/article/details/80229930 删除容器 删除指定容器： docker rm $ContainerName 按名称通配符删除容器，比如删除以名称mall-开头的容器： docker rm `docker ps -a | grep mall-* | awk '{print $1}'` 强制删除所有容器； docker rm -f $(docker ps -a -q) 查看容器的日志 查看容器产生的全部日志： docker logs $ContainerName 动态查看容器产生的日志： docker logs -f $ContainerName 修改容器的启动方式 # 将容器启动方式改为always docker container update --restart=always $ContainerName 同步宿主机时间到容器 docker cp /etc/localtime $ContainerName:/etc/ 指定容器时区 docker run -p 80:80 --name nginx \\ -e TZ=\"Asia/Shanghai\" \\ -d nginx:1.17.0 查看容器资源占用状况 查看指定容器资源占用状况，比如cpu、内存、网络、io状态： docker stats $ContainerName 查看所有容器资源占用情况： docker stats -a 查看容器磁盘使用情况 docker system df 执行容器内部命令 docker exec -it $ContainerName /bin/bash 指定账号进入容器内部 # 使用root账号进入容器内部 docker exec -it --user root $ContainerName /bin/bash 查看所有网络 docker network ls [root@local-linux ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 59b309a5c12f bridge bridge local ef34fe69992b host host local a65be030c632 none 创建外部网络 docker network create -d bridge my-bridge-network 指定容器网络 docker run -p 80:80 --name nginx \\ --network my-bridge-network \\ -d nginx:1.17.0 修改镜像的存放位置 查看Docker镜像的存放位置： docker info | grep \"Docker Root Dir\" 关闭Docker服务： systemctl stop docker 先将原镜像目录移动到目标目录： mv /var/lib/docker /mydata/docker 建立软连接： ln -s /mydata/docker /var/lib/dockernew Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/java.io.Closeable接口.html":{"url":"notes/20.11/java.io.Closeable接口.html","title":"java.io.Closeable接口.md","keywords":"","body":" java.io.Closeable java.lang.AutoCloseable try-with-resources 说到java.io.Closeable接口就避不开java.lang.AutoCloseable接口，因为在java版本7.0时引入了java.lang.AutoCloseable接口，同时java.io.Closeable接口便继承自java.lang.AutoCloseable接口了。 java.io.Closeable 先说一下Closeable接口，这个接口从java 5.0版本开始引入，其中中仅声明了一个方法close，用于关闭一个资源。一直一来我都很困惑，就算不实现这个接口，我给我的类实现一个close方法（或者别的方法）来完成“关闭”的功能不也是一样的么。直到我看到下面的两段代码。 //第一段代码 static void copy(String src, String dest)throws IOException { InputStream in = null; OutputStream out = null; try { in = new FileInputStream(src); out = new FileOutputStream(dest); byte[] buf = new byte[1024]; int n; while ((n = in.read(buf)) >= 0) { out.write(buf, 0, n); } } finally { if (in != null) in.close(); if (out != null) out.close(); } } 上面这段代码的问题在于，finally语句中的close方法也可能会抛出IOException异常。如果这正好发现在in.close被调用之时，那么这个异常就会阻止out.close被调用，从而使输出流保持在打开状态。所以这个程序使得finally可能被意外结束。解决方式是将每一个close都包装在一个try语句块中。从java 5.0版本开始，可以利用Closeable接口。 //第二段代码 // 对第一段代码中的finally语句改造如下 finally { closeIgnoringIOException(in); closeIgnoringIOException(out); } private static void closeIgnoringIOException(Closeable c) { if (c != null) { try { c.close(); } catch (IOException ex) { } } } 基于以上两段代码我知道了java.io.Closeable接口的用处。 java.lang.AutoCloseable 在java 7.0j时引入了java.lang.AutoCloseable，并且java.io.Closeable接口继承自 java.lang.AutoCloseable。很多资源类都直接或间接的实现了此接口。其实这个接口与try-with-resources语法是密切相关的。 从AutoCloseable的注释可知它的出现是为了更好的管理资源，准确说是资源的释放，当一个资源类实现了该接口close方法，在使用try-with-resources语法创建的资源抛出异常后，JVM会自动调用close 方法进行资源释放，当没有抛出异常正常退出try-block时候也会调用close方法。 //第三段代码 static void copy(String src, String dest)throws IOException { try (InputStream in=new FileInputStream(src);OutputStream out=new FileOutputStream(dest)){ byte[] buf = new byte[1024]; int n; while ((n = in.read(buf)) >= 0) { out.write(buf, 0, n); } }catch(Exception e) { System.out.println(\"catch block:\"+e.getLocalizedMessage()); }finally{ System.out.println(\"finally block\"); } } 因为InputStream和OutputStream都实现了java.io.Closeable接口（间接实现了java.lang.AutoCloseable接口）所以上面的【第三段代码】与【第二段代码的】一样“安全”。 try-with-resources try-with-resources 是在java 7.0 版本时引入的新语法特性。使用它配合java.lang.AutoCloseable接口可以更好的对资源进行释放，减少繁琐的异常处理。 使用try-with-resources结构无论是否抛出异常在try-block执行完毕后都会调用资源的close方法； 使用try-with-resources结构创建多个资源，try-block执行完毕后调用的close方法的顺序与创建资源顺序相反； 使用try-with-resources结构，try-block块抛出异常后先执行所有资源（try的（）中声明的）的close方法然后在执行catch里面的代码然后才是finally； 只用在try的()中声明的资源的close方法才会被调用，并且当对象销毁的时候close不会被再次调用； 使用try-with-resources结构无须显式调用资源释放，编程效率高，代码更简洁。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/java测试.html":{"url":"notes/20.11/java测试.html","title":"java测试.md","keywords":"","body":" Junit spring的测试 mock [TOC] 测试其实是衡量一个程序员编程素养的一个比较重要的维度。做测试其实是对自己写过代码的一个再思考的过程，而不仅仅是发现程序中的bug。之前工作中很少写测试，虽然短期看代码产出量变多了但是长久来看的话其实是一个非常不好的习惯，中间还是吃过几次亏的。 Junit Junit是idea自带的测试框架，可以用快捷键shift+command+T快速的创建测试类。需要添加一下pom依赖： org.junit.jupiter junit-jupiter ${latest-version} test 在方法中加入@Test方注解可以开始测试。 JUnit5 提供了4个生命周期注解 @BeforeAll @AfterAll @BeforeEach @AfterEach @BeforeAll：在所有的 @Test @RepeatedTest @ParameterizedTest @TestFactory 之前执行 @BeforeEach：在每个测试用例前执行 @AfterAll @AfterEach：与before类似，在测试用例之后执行 @RepeatedTest() 执行多次测试 @ParameterizedTest参数化测试 @ParameterizedTest @ValueSource(strings = { \"racecar\", \"radar\", \"able was I ere I saw elba\" }) void palindromes(String candidate) { log.error(candidate); } @CsvSource csv源支持 @ParameterizedTest @CsvSource({ \"apple, 1\", \"banana, 2\", \"'lemon, lime', 0xF1\" }) void testWithCsvSource(String fruit, int rank) { log.error(fruit + rank); } 它也支持从文件导入，例如@CsvFileSource(resources = \"/two-column.csv\", numLinesToSkip = 1) spring的测试 @SpringTest @MockBean @SpyBean 等等 mock Mockito org.mockito mockito-all 1.10.19 test https://juejin.im/post/6844903631137800206 参考文章：https://dnocm.com/articles/cherry/junit-5-info/(非常详细)new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/lambda和stream.html":{"url":"notes/20.11/lambda和stream.html","title":"lambda和stream.md","keywords":"","body":" lambda表达式 Lambda and Anonymous Classes(I) 自定义函数接口 [TOC] lambda表达式 Java Lambda表达式的一个重要用法是简化某些匿名内部类（Anonymous Classes）的写法。实际上Lambda表达式并不仅仅是匿名内部类的语法糖，JVM内部是通过invokedynamic指令来实现Lambda表达式的。 Lambda and Anonymous Classes(I) 本节将介绍如何使用Lambda表达式简化匿名内部类的书写，但Lambda表达式并不能取代所有的匿名内部类，只能用来取代函数接口（Functional Interface）的简写。 自定义函数接口 自定义函数接口很容易，只需要编写一个只有一个抽象方法的接口即可。 // 自定义函数接口 @FunctionalInterface public interface ConsumerInterface{ void accept(T t); } 上面代码中的@FunctionalInterface是可选的，但加上该标注编译器会帮你检查接口是否符合函数接口规范。就像加入@Override标注会检查是否重载了函数一样。 有了上述接口定义，就可以写出类似如下的代码： ConsumerInterface consumer = str -> System.out.println(str); 进一步的，还可以这样使用： class MyStream{ private List list; ... public void myForEach(ConsumerInterface consumer){// 1 for(T t : list){ consumer.accept(t); } } } MyStream stream = new MyStream(); stream.(str -> System.out.println(str));// 使用自定义函数接口书写Lambda表达式 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/nginx.html":{"url":"notes/20.11/nginx.html","title":"nginx.md","keywords":"","body":" nginx 安装和卸载nginx的方法: nginx命令 nginx 安装和卸载nginx的方法: #apt安装nginx方法 sudo apt-add-repository ppa:nginx/development sudo apt-get update sudo apt-get install nginx #apt卸载nginx方法 #卸载方法1. # 删除nginx，保留配置文件 sudo apt-get remove nginx #删除配置文件 rm -rf /etc/nginx #罗列出与nginx相关的软件并删除 dpkg --get-selections|grep nginx sudo apt-get --purge remove nginx sudo apt-get --purge remove nginx-common sudo apt-get --purge remove nginx-core #卸载方法2. #删除nginx连带配置文件 sudo apt-get purge nginx # Removes everything.包括配置文件 #卸载不再需要的nginx依赖程序 sudo apt-get autoremove #全局查找与nginx相关的文件 sudo find / -name nginx* #比较靠谱的解决办法是：root权限下载命令行敲入如下命令： rm -rf /etc/nginx/ rm -rf /usr/sbin/nginx rm /usr/share/man/man1/nginx.1.gz apt-get remove nginx* nginx命令 ```shell nginx #打开 nginx nginx -t #测试配置文件是否有语法错误 nginx -s reopen #重启Nginx nginx -s reload #重新加载Nginx配置文件，然后以优雅的方式重启Nginx nginx -s stop #强制停止Nginx服务 nginx -s quit #优雅地停止Nginx服务（即处理完所有请求后再停止服务） nginx [-?hvVtq] [-s signal] [-c filename] [-p prefix] [-g directives] -?,-h : 打开帮助信息 -v : 显示版本信息并退出 -V : 显示版本和配置选项信息，然后退出 -t : 检测配置文件是否有语法错误，然后退出 -q : 在检测配置文件期间屏蔽非错误信息 -s signal : 给一个 nginx 主进程发送信号：stop（强制停止）, quit（优雅退出）, reopen（重启）, reload（重新加载配置文件） -p prefix : 设置前缀路径（默认是：/usr/share/nginx/） -c filename : 设置配置文件（默认是：/etc/nginx/nginx.conf） -g directives : 设置配置文件外的全局指令 ```new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/spring启动流程（敖丙公众号）.html":{"url":"notes/20.11/spring启动流程（敖丙公众号）.html","title":"spring启动流程（敖丙公众号）.md","keywords":"","body":"https://mp.weixin.qq.com/s/ut3mRwhfqXNjrBtTmI0oWg > miner.start(2) INFO [05-16|00:07:25] Updated mining threads threads=0 INFO [05-16|00:07:25] Starting mining operation null INFO [05-16|00:07:25] Commit new mining work number=1 txs=0 uncles=0 elapsed=38.053ms INFO [05-16|00:07:28] Generating DAG ``in` `progress epoch=0 percentage=0 elapsed=1.715 INFO [05-16|00:07:30] Generating DAG ``in` `progress epoch=0 percentage=1 elapsed=3.448s INFO [05-16|00:07:31] Generating DAG ``in` `progress epoch=0 percentage=2 elapsed=5.059s INFO [05-16|00:07:33] Generating DAG ``in` `progress epoch=0 percentage=3 elapsed=6.799s INFO [05-16|00:07:35] Generating DAG ``in` `progress epoch=0 percentage=4 elapsed=8.373s INFO [05-16|00:24:54] Successfully sealed new block number=36 ``hash``=95fdfd…1411ee INFO [05-16|00:24:54] 🔗 block reached canonical chain number=31 ``hash``=438022…f6592e INFO [05-16|00:24:54] 🔨 mined potential block number=36 ``hash``=95fdfd…1411ee INFO [05-16|00:24:54] Commit new mining work number=37 txs=0 uncles=0 elapsed=122.202µs new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/分布式/":{"url":"notes/20.11/分布式/","title":"分布式","keywords":"","body":" zookeeper 分布式的一些原理.md 微信公众号文章高并发系统设计.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/分布式/zookeeper/":{"url":"notes/20.11/分布式/zookeeper/","title":"zookeeper","keywords":"","body":" Zookeeper.md zookeeper学习一.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/分布式/zookeeper/Zookeeper.html":{"url":"notes/20.11/分布式/zookeeper/Zookeeper.html","title":"Zookeeper.md","keywords":"","body":" Zookeeper 简介/快速入门 应用场景 Zookeeper的设计目标 数据模型 结点状态stat的属性 单机安装 常用shell命令 操作结点 zookeeper的Acl权限控制 案例/远程登录 acl 超级管理员 zookeeper的 JavaAPI 连接到Zookeeper 新增节点 修改节点 删除节点 查看节点 查看子节点 检查节点是否存在 事件监听机制 watcher架构 watcher特性 Watcher通知状态(KeeperState) Watcher事件类型(EventType) 捕获相应的事件 客户端与服务器端的连接状态 watcher检查节点 分布式唯一id案例 分布式锁 集群搭建 一致性协议——zab协议 leader选举 observer角色及其配置 API连接集群 curator介绍 基础用法 创建 修改 删除 读取节点 读取子节点 watcher 事务 分布式锁 四字监控命令/配置属性 conf cons crst dump envi ruok stat srst wchs wchc wchp mntr ZooInspector图形化工具 [TOC] Zookeeper 2020-4-28 ——https://www.bilibili.com/video/BV1M741137qY?p=74 https://zookeeper.apache.org/ 简介/快速入门 ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them, which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed. ZooKeeper是一个集中的服务，用于维护配置信息、命名、提供分布式同步和提供组服务。所有这些类型的服务都以某种形式被分布式应用程序使用。每次它们被实现时，都会有大量的工作来修复不可避免的错误和竞争条件。由于实现这些服务的困难，应用程序最初通常会略过这些服务，这使得它们在出现更改时变得脆弱，并且难以管理。即使正确地执行了这些服务，在部署应用程序时，这些服务的不同实现也会导致管理复杂性 zookeeper由雅虎研究院开发,是Google Chubby的开源实现,后来托管到 Apache,于2010年11月正式成为apache的顶级项目 大数据生态系统里由很多组件的命名都是某些动物或者昆虫，比如hadoop大象，hive就是蜂巢，zookeeper即管理员，顾名思义就算管理大数据生态系统各组件的管理员，如下所示： 应用场景 zookeepepr是一个经典的分布式数据一致性解决方案，致力于为分布式应用提供一个高性能、高可用,且具有严格顺序访问控制能力的分布式协调存储服务。 维护配置信息 分布式锁服务 集群管理 生成分布式唯一ID 维护配置信息 java编程经常会遇到配置项，比如数据库的url、 schema、user和 password等。通常这些配置项我们会放置在配置文件中，再将配置文件放置在服务器上当需要更改配置项时，需要去服务器上修改对应的配置文件。 但是随着分布式系统的兴起,由于许多服务都需要使用到该配置文件,因此有必须保证该配置服务的高可用性(highavailability)和各台服务器上配置数据的一致性。 通常会将配置文件部署在一个集群上，然而一个集群动辄上千台服务器，此时如果再一台台服务器逐个修改配置文件那将是非常繁琐且危险的的操作，因此就需要一种服务，能够高效快速且可靠地完成配置项的更改等操作，并能够保证各配置项在每台服务器上的数据一致性。 zookeeper就可以提供这样一种服务，其使用Zab这种一致性协议来保证一致性。现在有很多开源项目使用zookeeper来维护配置，如在 hbase中，客户端就是连接一个 zookeeper，获得必要的 hbase集群的配置信息，然后才可以进一步操作。还有在开源的消息队列 kafka中，也便用zookeeper来维护 brokers的信息。在 alibaba开源的soa框架dubbo中也广泛的使用zookeeper管理一些配置来实现服务治理。 分布式锁服务 一个集群是一个分布式系统，由多台服务器组成。为了提高并发度和可靠性，多台服务器上运行着同一种服务。当多个服务在运行时就需要协调各服务的进度，有时候需要保证当某个服务在进行某个操作时，其他的服务都不能进行该操作，即对该操作进行加锁，如果当前机器挂掉后，释放锁并 fail over到其他的机器继续执行该服务 集群管理 一个集群有时会因为各种软硬件故障或者网络故障，出现棊些服务器挂掉而被移除集群，而某些服务器加入到集群中的情况，zookeeper会将这些服务器加入/移出的情况通知给集群中的其他正常工作的服务器，以及时调整存储和计算等任务的分配和执行等。此外zookeeper还会对故障的服务器做出诊断并尝试修复。 生产分布式唯一ID 在过去的单库单表型系统中，通常可以使用数据库字段自带的auto_ increment属性来自动为每条记录生成一个唯一的ID。但是分库分表后，就无法在依靠数据库的auto_ Increment属性来唯一标识一条记录了。此时我们就可以用zookeeper在分布式环境下生成全局唯一ID。 做法如下:每次要生成一个新id时，创建一个持久顺序节点，创建操作返回的节点序号，即为新id，然后把比自己节点小的删除即可 Zookeeper的设计目标 zooKeeper致力于为分布式应用提供一个高性能、高可用，且具有严格顺序访问控制能力的分布式协调服务 高性能 zookeeper将全量数据存储在内存中，并直接服务于客户端的所有非事务请求，尤其用于以读为主的应用场景 高可用 zookeeper一般以集群的方式对外提供服务，一般3~5台机器就可以组成一个可用的 Zookeeper集群了，每台机器都会在内存中维护当前的服务器状态，井且每台机器之间都相互保持着通信。只要集群中超过一半的机器都能够正常工作，那么整个集群就能够正常对外服务 严格顺序访问 对于来自客户端的每个更新请求，Zookeeper都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序 数据模型 zookeeper的数据结点可以视为树状结构(或目录)，树中的各个结点被称为znode(即zookeeper node)，一个znode可以由多个子结点。zookeeper结点在结构上表现为树状； 使用路径path来定位某个znode，比如/ns-1/itcast/mysqml/schemal1/table1，此处ns-1，itcast、mysql、schemal1、table1分别是根结点、2级结点、3级结点以及4级结点；其中ns-1是itcast的父结点，itcast是ns-1的子结点，itcast是mysql的父结点....以此类推 znode，间距文件和目录两种特点，即像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分 那么如何描述一个znode呢？一个znode大体上分为3个部分： 结点的数据：即znode data(结点path，结点data)的关系就像是Java map中的 key value关系 结点的子结点children 结点的状态stat：用来描述当前结点的创建、修改记录，包括cZxid、ctime等 结点状态stat的属性 在zookeeper shell中使用 get命令查看指定路径结点的data、stat信息 属性说明： 结点的各个属性如下。其中重要的概念是Zxid(Zookeeper Transaction ID)，Zookeeper结点的每一次更改都具有唯一的Zxid，如果Zxid-1 小于Zxid-2 ，则Zxid-1 的更改发生在 Zxid-2更改之前 https://zookeeper.apache.org/doc/r3.4.14/zookeeperProgrammers.html#sc_zkDataModel_znodes cZxid数据结点创建时的事务ID——针对于zookeeper数据结点的管理：我们对结点数据的一些写操作都会导致zookeeper自动地为我们去开启一个事务，并且自动地去为每一个事务维护一个事务ID ctime数据结点创建时的时间 mZxid数据结点最后一次更新时的事务ID mtime数据结点最后一次更新时的时间 pZxid数据节点最后一次修改此znode子节点更改的zxid cversion子结点的更改次数 dataVersion结点数据的更改次数 aclVersion结点的ACL更改次数——类似linux的权限列表，维护的是当前结点的权限列表被修改的次数 ephemeralOwner如果结点是临时结点，则表示创建该结点的会话的SessionID；如果是持久结点，该属性值为0 dataLength数据内容的长度 numChildren数据结点当前的子结点个数 结点类型 zookeeper中的结点有两种，分别为临时结点和永久结点。结点的类型在创建时被确定，并且不能改变 临时节点： 该节点的生命周期依赖于创建它们的会话。一旦会话( Session）结束，临时节点将被自动删除，当然可以也可以手动删除。虽然每个临时的 Znode都会绑定到一个客户端会话，但他们对所有的客户端还是可见的。另外，Zookeeper的临时节点不允许拥有子节点 持久化结点： 该结点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，它们才能被删除 单机安装 测试系统环境centos7.3 zookeeper:zookeeper-3.4.10.tar.gz jdk:jdk-8u131-linux-x64.tar.gz http://archive.apache.org/dist/zookeeper/ 在centos中使用 root用户创建 zookeeper用户，用户名:zookeeper密码:zookeeper useradd zookeeper passwd zookeeper su zookeeper zookeeper底层依赖于jdk，zookeeper用户登录后，根目录下先进行jdk 的安装，jdk使用 jdk-8u131-linux-x64.tar.gz tar -zxf tar.gz 配置jdk 环境变量 vi /etc/profile JAVA_HOME=/home/zookeeper/jdk1.8.0_131 export JAVA_HOME PATH=$JAVA_HOME/bin:$PATH export PATH souce /etc/profile 检测jdk安装 java -version // 如果反馈了Java信息，则成功 zookeeper 上传解压 wget http://mirrors.hust.edu.cn/apache/zookeeper/stable/apache-zookeeper-3.5.8-bin.tar.gz tar -zxf tar.gz 为zookeeper准备配置文件 # 进入conf目录 cd /home/zookeeper/zookeeper-3.4.10/conf # 复制配置文件 cp zoo_sampe.cfg zoo.cfg # zookeeper 根目录下创建data目录 mkdir data # vi 配置文件中的dataDir # 此路径用于存储zookeeper中数据的内存快照、及事务日志文件，虽然zookeeper是使用内存的，但是需要持久化一些数据来保证数据的安全，和redis一样 dataDir=/home/zookeeper/zookeeper-3.4.10/data 启动zookeeper # 进入zookeeper的bin目录 cd /home/zookeeper/zookeeper-3.4.10/bin # 启动zookeeper ./zkServer.sh start # 启动: zkServer.sh start # 停止: zkServer.sh stop # 查看状态：zkServer.sh status # 进入zookeeper 内部 ./zkCli.sh 常用shell命令 zookeeper——getting started——https://zookeeper.apache.org/doc/r3.4.14/zookeeperStarted.html#sc_FileManagement 操作结点 查询 get /hadoop 查看结点的数据和属性 stat /hadoop 查看结点的属性 创建 创建结点并写入数据： create [-s] [-e] path data # 其中 -s 为有序结点，-e 临时结点（默认是持久结点） create /hadoop \"123456\" # 此时，如果quit退出后再./ZkCient.sh 登入 # 再用输入 get /hadoop 获取，结点依然存在(永久结点) create -s /a \"a\" # 创建一个持久化有序结点，创建的时候可以观察到返回的数据带上了一个id create -s /b \"b\" # 返回的值，id递增了 create -s -e /aa \"aa\" # 依然还会返回自增的id，quit后再进来，继续创建，id依然是往后推的 create /aa/xx # 继续创建结点，可以看到pZxid变化了 更新 更新结点的命令是set，可以直接进行修改，如下： set path [version] set /hadoop \"345\" # 修改结点值 set /hadoop \"hadoop-x\" 1 # 也可以基于版本号进行更改，类似于乐观锁，当传入版本号(dataVersion) # 和当前结点的数据版本号不一致时，zookeeper会拒绝本次修改 删除 删除结点的语法如下： delete path [version] 和 set 方法相似，也可以传入版本号 delete /hadoop # 删除结点 delete /hadoop 1 # 乐观锁机制，与set 方法一致 要想删除某个结点及其所有后代结点，可以使用递归删除，命令为 rmr path 查看结点列表 ls /hadoop # 可以查看结点的列表 ls2 /hadoop # 可以查看结点的列表以及目标结点的信息 ls / # 根节点 监听器get path [watch] | stat path [watch] 使用get path [watch] 注册的监听器能够在结点内容发生改变的时候，向客户端发出通知。需要注意的是zookeeper的触发器是一次性的(One-time trigger)，即触发一次后就会立即失效 get /hadoop watch # get 的时候添加监听器，当值改变的时候，监听器返回消息 set /hadoop 45678 # 测试 ls\\ls2 path [watch] 使用 ls path [watch] 或 ls2 path [watch]注册的监听器能够监听该结点下所有子节点的增加和删除操作 ls /hadoop watch # 添加监听器 set /hadoop/node \"node\" zookeeper的Acl权限控制 https://zookeeper.apache.org/doc/r3.4.14/zookeeperProgrammers.html#sc_ZooKeeperAccessControl zookeeper类似文件系统，client可以创建结点、更新结点、删除结点，那么如何做到结点的权限控制呢？ zookeeper的 access control list 访问控制列表可以做到这一点 acl权限控制，使用scheme：id：permission来标识，主要涵盖3个方面： https://zookeeper.apache.org/doc/r3.4.14/zookeeperProgrammers.html#sc_BuiltinACLSchemes 权限模式(scheme)：授权的策略 授权对象(id)：授权的对象 权限(permission)：授予的权限 其特性如下： zookeeper的权限控制是基于每个znode结点的，需要对每个结点设置权限 每个znode支持多种权限控制方案和多个权限 子结点不会继承父结点的权限，客户端无权访问某结点，但可能可以访问它的子结点： 例如setAcl /test2 ip:192.168.133.133:crwda // 将结点权限设置为Ip：192.168.133.133 的客户端可以对节点进行 增删改查和管理权限 权限模式 采用何种方式授权 | 方案 | 描述 | | ------ | ------------------------------------------------------- | | world | 只有一个用户：anyone，代表登录zookeeper所有人(默认) | | ip | 对客户端使用IP地址认证 | | auth | 使用已添加认证的用户认证 | | digest | 使用\"用户名：密码\"方式认证 | 授权对象 给谁授予权限 授权对象ID是指，权限赋予的实体，例如：IP地址或用户 授权的权限 授予什么权限 create、delete、read、writer、admin也就是 增、删、查、改、管理权限，这5种权限简写为 c d r w a，注意： 这五种权限中，有的权限并不是对结点自身操作的例如：delete是指对子结点的删除权限 可以试图删除父结点，但是子结点必须删除干净，所以delete的权限也是很有用的 | 权限 | ACL简写 | 描述 | | ------ | ------- | ---------------------------------- | | create | c | 可以创建子结点 | | delete | d | 可以删除子结点(仅下一级结点) | | read | r | 可以读取结点数据以及显示子结点列表 | | write | w | 可以设置结点数据 | | admin | a | 可以设置结点访问控制权限列表 | 授权的相关命令 | 命令 | 使用方式 | 描述 | | ------- | -------- | ------------ | | getAcl | getAcl | 读取ACL权限 | | setAcl | setAcl | 设置ACL权限 | | addauth | addauth | 添加认证用户 | 案例/远程登录 ./zkServer.sh -server 192.168.133.133 可以远程登录 world权限模式 getAcl /node // 读取权限信息 setAcl /node world:anyone:drwa // 设置权限(禁用创建子结点的权限) ip模式 ./zkServer.sh -server 192.168.133.133 可以远程登录 setAcl /hadoop ip:192.168.133.133:drwa 如果在两台不同的虚拟机中，另一台用远程连接的模式，进行上面这条命令，那么只会有一台被授权 需要两台虚拟机一起授权的话需要用逗号将授权列表隔开：setAcl /hadoop ip:192.168.133.133:cdrwa,ip:192.168.133.132:cdrwa auth认证用户模式 addauth digest : setAcl auth:: create /hadoop \"hadoop\" # 初始化测试用的结点 addauth digest itcast:123456 # 添加认证用户 setAcl /hadoop auth:itcast:cdrwa # 设置认证用户 quit # 退出后再./zkCli.sh 进入 get /hadoop # 这个时候就没有权限了，需要再次认证 addauth digest itcast:123456 # 认证，密码错了的话 zookeeper 不会报错，但是不能认证 get /hadoop Digest授权模式 setAcl digest::: 这里的密码是经过SHA1以及BASE64处理的密文，在shell 中可以通过以下命令计算： echo -n : | openssl dgst -binary -sha1 | openssl base64 # 计算密码 echo -n itcast:12345 | openssl dgst -binary -sha1 | openssl base64 # 获取密码，设置权限列表 setAcl /hadoop digest:itcast:qUFSHxJjItUW/93UHFXFVGlvryY=:cdrwa # 现在想要get /hadoop 需要登录了 addauth digest itcast:12345 get /hadoop 多种授权模式 仅需逗号隔开 setAcl /hadoop ip:192.168.133.132:cdrwa,auth:hadoop:cdrwa,digest:itcast:673OfZhUE8JEFMcu0l64qI8e5ek=:cdrwa acl 超级管理员 zookeeper的权限管理模式有一种叫做super，该模式提供一个超管，可以方便的访问任何权限的节点 假设这个超管是supper:admin，需要为超管生产密码的密文 echo -n super:admin | openssl dgst -binary -sha1 | openssl base64 那么打开zookeeper目录下/bin/zkServer.sh服务器脚本文件，找到如下一行： /nohup # 快速查找，可以看到如下 nohup \"$JAVA\" \"-Dzookeeper.log.dir=${ZOO_LOG_DIR}\" \"-Dzookeeper.root.logger=${ZOO_LOG4J_PROP}\" 这个就算脚本中启动zookeeper的命令，默认只有以上两个配置项，我们需要添加一个超管的配置项 \"-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs=\" 修改后命令变成如下 nohup \"$JAVA\" \"-Dzookeeper.log.dir=${ZOO_LOG_DIR}\" \"-Dzookeeper.root.logger=${ZOO_LOG4J_PROP}\" \"-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs=\" # 重起后，现在随便对任意节点添加权限限制 setAcl /hadoop ip:192.168.1.1:cdrwa # 这个ip并非本机 # 现在当前用户没有权限了 getAcl /hadoop # 登录超管 addauth digest super:admin # 强行操作节点 get /hadoop zookeeper的 JavaAPI com.101tec zkclient zookeeper org.apache.zookeeper log4j log4j slf4j-log4j12 org.slf4j slf4j-api org.slf4j 0.9 zookeeper log4j log4j slf4j-log4j12 org.slf4j org.apache.zookeeper 3.4.10 zonde是 zookeeper集合的核心组件，zookeeper API 提供了一小组使用 zookeeper集群来操作znode的所有细节 客户端应该遵循以下步骤，与zookeeper服务器进行清晰和干净的交互 连接到zookeeper服务器。zookeeper服务器为客户端分配会话ID 定期向服务器发送心跳。否则，zookeeper服务器将过期会话ID，客户端需要重新连接 只要会话Id处于活动状态，就可以获取/设置znode 所有任务完成后，断开与zookeeper服务器连接，如果客户端长时间不活动，则zookeeper服务器将自动断开客户端 连接到Zookeeper 这部分，官网的解释十分稀少https://zookeeper.apache.org/doc/r3.4.14/zookeeperStarted.html#sc_ConnectingToZooKeeper [zkshell: 0] help ZooKeeper host:port cmd args get path [watch] ls path [watch] set path data [version] delquota [-n|-b] path quit printwatches on|off create path data acl stat path [watch] listquota path history setAcl path acl getAcl path sync path redo cmdno addauth scheme auth delete path [version] deleteall path setquota -n|-b val path Zookeeper(String connectionString, int sessionTimeout, watcher watcher) connectionString - zookeeper主机 sessionTimeout- 会话超时 watcher - 实现\"监听器\" 对象。zookeeper集合通过监视器对象返回连接状态 public static void main(String[] args) throws IOException, InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(1); ZooKeeper zookeeper = new ZooKeeper(\"192.168.133.133:2181\", 5000, (WatchedEvent x) -> { if (x.getState() == Watcher.Event.KeeperState.SyncConnected) { System.out.println(\"连接成功\"); countDownLatch.countDown(); } }); countDownLatch.await(); System.out.println(zookeeper.getSessionId()); zookeeper.close(); } 新增节点 // 同步 create(String path, byte[] data, List acl, CreateMode createMode) // 异步 create(String path, byte[] data, List acl, CreateMode createMode, AsynCallback.StringCallback callBack, Object ctx) | 参数 | 解释 | | ------------ | ------------------------------------------------------------ | | path | znode路径 | | data | 数据 | | acl | 要创建的节点的访问控制列表。zookeeper API提供了一个静态接口 ZooDefs.Ids 来获取一些基本的acl列表。例如，ZooDefs.Ids.OPEN_ACL_UNSAFE返回打开znode的acl列表 | | createMode | 节点的类型，这是一个枚举 | | callBack | 异步回调接口 | | ctx | 传递上下文参数 | 示例： // 枚举的方式 public static void createTest1() throws Exception{ String str = \"node\"; String s = zookeeper.create(\"/node\", str.getBytes(), ZooDefs.Ids.READ_ACL_UNSAFE, CreateMode.PERSISTENT); System.out.println(s); } // 自定义的方式 public static void createTest2() throws Exception{ ArrayList acls = new ArrayList<>(); Id id = new Id(\"ip\",\"192.168.133.133\"); acls.add(new ACL(ZooDefs.Perms.ALL,id)); zookeeper.create(\"/create/node4\",\"node4\".getBytes(),acls,CreateMode.PERSISTENT); } // auth public static void createTest3() throws Exception{ zookeeper.addAuthInfo(\"digest\",\"itcast:12345\".getBytes()); zookeeper.create(\"/node5\",\"node5\".getBytes(), ZooDefs.Ids.CREATOR_ALL_ACL,CreateMode.PERSISTENT); } // 自定义的方式 public static void createTest3() throws Exception{ // zookeeper.addAuthInfo(\"digest\",\"itcast:12345\".getBytes()); // zookeeper.create(\"/node5\",\"node5\".getBytes(), // ZooDefs.Ids.CREATOR_ALL_ACL,CreateMode.PERSISTENT); zookeeper.addAuthInfo(\"digest\",\"itcast:12345\".getBytes()); List acls = new ArrayList<>(); Id id = new Id(\"auth\",\"itcast\"); acls.add(new ACL(ZooDefs.Perms.READ,id)); zookeeper.create(\"/create/node6\",\"node6\".getBytes(), acls,CreateMode.PERSISTENT); } // digest public static void createTest3() throws Exception{ List acls = new ArrayList<>(); Id id = new Id(\"digest\",\"itcast:qUFSHxJjItUW/93UHFXFVGlvryY=\"); acls.add(new ACL(ZooDefs.Perms.READ,id)); zookeeper.create(\"/create/node7\",\"node7\".getBytes(), acls,CreateMode.PERSISTENT); } // 异步 public static void createTest4() throws Exception{ zookeeper.create(\"/node12\", \"node12\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT, new AsyncCallback.StringCallback(){ /** * @param rc 状态，0 则为成功，以下的所有示例都是如此 * @param path 路径 * @param ctx 上下文参数 * @param name 路径 */ public void processResult(int rc, String path, Object ctx, String name){ System.out.println(rc + \" \" + path + \" \" + name + \" \" + ctx); } }, \"I am context\"); TimeUnit.SECONDS.sleep(1); System.out.println(\"结束\"); } 修改节点 同样也有两种修改方式(异步和同步) // 同步 setData(String path, byte[] data, int version) // 异步 setData(String path, byte[] data, int version, StatCallback callBack, Object ctx) | 参数 | 解释 | | ---------- | ------------------------------------------------------------ | | path | 节点路径 | | data | 数据 | | version | 数据的版本号， -1代表不使用版本号，乐观锁机制 | | callBack | 异步回调 AsyncCallback.StatCallback，和之前的回调方法参数不同，这个可以获取节点状态 | | ctx | 传递上下文参数 | public static void setData1() throws Exception{ // arg1:节点的路径 // arg2:修改的数据 // arg3:数据的版本号 -1 代表版本号不参与更新 Stat stat = zookeeper.setData(\"/hadoop\",\"hadoop-1\".getBytes(),-1); } public static void setData2() throws Exception{ zookeeper.setData(\"/hadoop\", \"hadoop-1\".getBytes(), 3 ,new AsyncCallback.StatCallback(){ @Override public void processResult(int rc, String path, Object ctx, Stat stat) { // 讲道理，要判空 System.out.println(rc + \" \" + path + \" \" + stat.getVersion() + \" \" + ctx); } }, \"I am context\"); } 删除节点 异步、同步 // 同步 delete(String path, int version) // 异步 delete(String path, int version, AsyncCallback.VoidCallback callBack, Object ctx) | 参数 | 解释 | | ---------- | ----------------------------------------------- | | path | 节点路径 | | version | 版本 | | callBack | 数据的版本号， -1代表不使用版本号，乐观锁机制 | | ctx | 传递上下文参数 | public static void deleteData1() throws Exception { zookeeper.delete(\"/hadoop\", 1); } public static void deleteData2() throws Exception { zookeeper.delete(\"/hadoop\", 1, new AsyncCallback.VoidCallback() { @Override public void processResult(int rc, String path, Object ctx) { System.out.println(rc + \" \" + path + \" \" + ctx); } }, \"I am context\"); TimeUnit.SECONDS.sleep(1); } 查看节点 同步、异步 // 同步 getData(String path, boolean watch, Stat stat) getData(String path, Watcher watcher, Stat stat) // 异步 getData(String path, boolean watch, DataCallback callBack, Object ctx) getData(String path, Watcher watcher, DataCallback callBack, Object ctx) | 参数 | 解释 | | ---------- | -------------------------------- | | path | 节点路径 | | boolean | 是否使用连接对象中注册的监听器 | | stat | 元数据 | | callBack | 异步回调接口，可以获得状态和数据 | | ctx | 传递上下文参数 | public static void getData1() throws Exception { Stat stat = new Stat(); byte[] data = zookeeper.getData(\"/hadoop\", false, stat); System.out.println(new String(data)); // 判空 System.out.println(stat.getCtime()); } public static void getData2() throws Exception { zookeeper.getData(\"/hadoop\", false, new AsyncCallback.DataCallback() { @Override public void processResult(int rc, String path, Object ctx, byte[] bytes, Stat stat) { // 判空 System.out.println(rc + \" \" + path + \" \" + ctx + \" \" + new String(bytes) + \" \" + stat.getCzxid()); } }, \"I am context\"); TimeUnit.SECONDS.sleep(3); } 查看子节点 同步、异步 // 同步 getChildren(String path, boolean watch) getChildren(String path, Watcher watcher) getChildren(String path, boolean watch, Stat stat) getChildren(String path, Watcher watcher, Stat stat) // 异步 getChildren(String path, boolean watch, ChildrenCallback callBack, Object ctx) getChildren(String path, Watcher watcher, ChildrenCallback callBack, Object ctx) getChildren(String path, Watcher watcher, Children2Callback callBack, Object ctx) getChildren(String path, boolean watch, Children2Callback callBack, Object ctx) | 参数 | 解释 | | ---------- | -------------------------- | | path | 节点路径 | | boolean | | | callBack | 异步回调，可以获取节点列表 | | ctx | 传递上下文参数 | public static void getChildren_1() throws Exception{ List hadoop = zookeeper.getChildren(\"/hadoop\", false); hadoop.forEach(System.out::println); } public static void getChildren_2() throws Exception { zookeeper.getChildren(\"/hadoop\", false, new AsyncCallback.ChildrenCallback() { @Override public void processResult(int rc, String path, Object ctx, List list) { list.forEach(System.out::println); System.out.println(rc + \" \" + path + \" \" + ctx); } }, \"I am children\"); TimeUnit.SECONDS.sleep(3); } 检查节点是否存在 同步、异步 // 同步 exists(String path, boolean watch) exists(String path, Watcher watcher) // 异步 exists(String path, boolean watch, StatCallback cb, Object ctx) exists(String path, Watcher watcher, StatCallback cb, Object ctx) | 参数 | 解释 | | ---------- | -------------------------- | | path | 节点路径 | | boolean | | | callBack | 异步回调，可以获取节点列表 | | ctx | 传递上下文参数 | public static void exists1() throws Exception{ Stat exists = zookeeper.exists(\"/hadoopx\", false); // 判空 System.out.println(exists.getVersion() + \"成功\"); } public static void exists2() throws Exception{ zookeeper.exists(\"/hadoopx\", false, new AsyncCallback.StatCallback() { @Override public void processResult(int rc, String path, Object ctx, Stat stat) { // 判空 System.out.println(rc + \" \" + path + \" \" + ctx +\" \" + stat.getVersion()); } }, \"I am children\"); TimeUnit.SECONDS.sleep(1); } 事件监听机制 watcher概念 https://zookeeper.apache.org/doc/r3.4.14/zookeeperProgrammers.html#sc_WatchRememberThese zookeeper提供了数据的发布/订阅功能，多个订阅者可同时监听某一特定主题对象，当该主题对象的自身状态发生变化时例如节点内容改变、节点下的子节点列表改变等，会实时、主动通知所有订阅者 zookeeper采用了 Watcher机制实现数据的发布订阅功能。该机制在被订阅对象发生变化时会异步通知客户端，因此客户端不必在 Watcher注册后轮询阻塞，从而减轻了客户端压力 watcher机制事件上与观察者模式类似，也可看作是一种观察者模式在分布式场景下的实现方式 watcher架构 watcher实现由三个部分组成 zookeeper服务端 zookeeper客户端 客户端的ZKWatchManager对象 客户端首先将 Watcher注册到服务端，同时将 Watcher对象保存到客户端的watch管理器中。当Zookeeper服务端监听的数据状态发生变化时，服务端会主动通知客户端，接着客户端的 Watch管理器会触发相关 Watcher来回调相应处理逻辑，从而完成整体的数据 发布/订阅流程 watcher特性 | 特性 | 说明 | | -------------- | ------------------------------------------------------------ | | 一次性 | watcher是一次性的，一旦被触发就会移除，再次使用时需要重新注册 | | 客户端顺序回调 | watcher回调是顺序串行执行的，只有回调后客户端才能看到最新的数据状态。一个watcher回调逻辑不应该太多，以免影响别的watcher执行 | | 轻量级 | WatchEvent是最小的通信单位，结构上只包含通知状态、事件类型和节点路径，并不会告诉数据节点变化前后的具体内容 | | 时效性 | watcher只有在当前session彻底失效时才会无效，若在session有效期内快速重连成功，则watcher依然存在，仍可接收到通知； | watcher接口设计 Watcher是一个接口，任何实现了Watcher接口的类就算一个新的Watcher。Watcher内部包含了两个枚举类：KeeperState、EventType Watcher通知状态(KeeperState) KeeperState是客户端与服务端连接状态发生变化时对应的通知类型。路径为org.apache.zookeeper.Watcher.EventKeeperState，是一个枚举类，其枚举属性如下： | 枚举属性 | 说明 | | --------------- | ------------------------ | | SyncConnected | 客户端与服务器正常连接时 | | Disconnected | 客户端与服务器断开连接时 | | Expired | 会话session失效时 | | AuthFailed | 身份认证失败时 | Watcher事件类型(EventType) EventType是数据节点znode发生变化时对应的通知类型。EventType变化时KeeperState永远处于SyncConnected通知状态下；当keeperState发生变化时，EventType永远为None。其路径为org.apache.zookeeper.Watcher.Event.EventType，是一个枚举类，枚举属性如下： | 枚举属性 | 说明 | | --------------------- | ----------------------------------------------------------- | | None | 无 | | NodeCreated | Watcher监听的数据节点被创建时 | | NodeDeleted | Watcher监听的数据节点被删除时 | | NodeDataChanged | Watcher监听的数据节点内容发生更改时(无论数据是否真的变化) | | NodeChildrenChanged | Watcher监听的数据节点的子节点列表发生变更时 | 注意：客户端接收到的相关事件通知中只包含状态以及类型等信息，不包含节点变化前后的具体内容，变化前的数据需业务自身存储，变化后的数据需要调用get等方法重新获取 捕获相应的事件 上面讲到zookeeper客户端连接的状态和zookeeper对znode节点监听的事件类型，下面我们来讲解如何建立zookeeper的watcher监听。在zookeeper中采用zk.getChildren(path,watch)、zk.exists(path,watch)、zk.getData(path,watcher,stat)这样的方式来为某个znode注册监听 。 下表以node-x节点为例，说明调用的注册方法和可用监听事件间的关系： 注册方式 created childrenChanged Changed Deleted zk.exists(\"/node-x\",watcher) 可监控 可监控 可监控 zk.getData(\"/node-x\",watcher) 可监控 可监控 zk.getChildren(\"/node-x\",watcher) 可监控 可监控 注册watcher的方法 客户端与服务器端的连接状态 KeeperState：通知状态 SyncConnected：客户端与服务器正常连接时 Disconnected：客户端与服务器断开连接时 Expired：会话session失效时 AuthFailed：身份认证失败时 事件类型为：None 案例 public class ZkConnectionWatcher implements Watcher { @Override public void process(WatchedEvent watchedEvent) { Event.KeeperState state = watchedEvent.getState(); if(state == Event.KeeperState.SyncConnected){ // 正常 System.out.println(\"正常连接\"); }else if (state == Event.KeeperState.Disconnected){ // 可以用Windows断开虚拟机网卡的方式模拟 // 当会话断开会出现，断开连接不代表不能重连，在会话超时时间内重连可以恢复正常 System.out.println(\"断开连接\"); }else if (state == Event.KeeperState.Expired){ // 没有在会话超时时间内重新连接，而是当会话超时被移除的时候重连会走进这里 System.out.println(\"连接过期\"); }else if (state == Event.KeeperState.AuthFailed){ // 在操作的时候权限不够会出现 System.out.println(\"授权失败\"); } countDownLatch.countDown(); } private static final String IP = \"192.168.133.133:2181\" ; private static CountDownLatch countDownLatch = new CountDownLatch(1); public static void main(String[] args) throws Exception { // 5000为会话超时时间 ZooKeeper zooKeeper = new ZooKeeper(IP, 5000, new ZkConnectionWatcher()); countDownLatch.await(); // 模拟授权失败 zooKeeper.addAuthInfo(\"digest1\",\"itcast1:123451\".getBytes()); byte[] data = zooKeeper.getData(\"/hadoop\", false, null); System.out.println(new String(data)); TimeUnit.SECONDS.sleep(50); } } watcher检查节点 exists exists(String path, boolean b) exists(String path, Watcher w) NodeCreated：节点创建 NodeDeleted：节点删除 NodeDataChanged：节点内容 案例 public class EventTypeTest { private static final String IP = \"192.168.133.133:2181\"; private static CountDownLatch countDownLatch = new CountDownLatch(1); private static ZooKeeper zooKeeper; // 采用zookeeper连接创建时的监听器 public static void exists1() throws Exception{ zooKeeper.exists(\"/watcher1\",true); } // 自定义监听器 public static void exists2() throws Exception{ zooKeeper.exists(\"/watcher1\",(WatchedEvent w) -> { System.out.println(\"自定义\" + w.getType()); }); } // 演示使用多次的监听器 public static void exists3() throws Exception{ zooKeeper.exists(\"/watcher1\", new Watcher() { @Override public void process(WatchedEvent watchedEvent) { try { System.out.println(\"自定义的\" + watchedEvent.getType()); } finally { try { zooKeeper.exists(\"/watcher1\",this); } catch (Exception e) { e.printStackTrace(); } } } }); } // 演示一节点注册多个监听器 public static void exists4() throws Exception{ zooKeeper.exists(\"/watcher1\",(WatchedEvent w) -> { System.out.println(\"自定义1\" + w.getType()); }); zooKeeper.exists(\"/watcher1\", new Watcher() { @Override public void process(WatchedEvent watchedEvent) { try { System.out.println(\"自定义2\" + watchedEvent.getType()); } finally { try { zooKeeper.exists(\"/watcher1\",this); } catch (Exception e) { e.printStackTrace(); } } } }); } // 测试 public static void main(String[] args) throws Exception { zooKeeper = new ZooKeeper(IP, 5000, new ZKWatcher()); countDownLatch.await(); exists4(); TimeUnit.SECONDS.sleep(50); } static class ZKWatcher implements Watcher{ @Override public void process(WatchedEvent watchedEvent) { countDownLatch.countDown(); System.out.println(\"zk的监听器\" + watchedEvent.getType()); } } } getData getData(String path, boolean b, Stat stat) getData(String path, Watcher w, Stat stat) NodeDeleted：节点删除 NodeDataChange：节点内容发生变化 getChildren getChildren(String path, boolean b) getChildren(String path, Watcher w) NodeChildrenChanged：子节点发生变化 NodeDeleted：节点删除 配置中心案例 工作中有这样的一个场景：数据库用户名和密码信息放在一个配置文件中，应用读取该配置文件，配置文件信息放入缓存 若数据库的用户名和密码改变时候，还需要重新加载媛存，比较麻烦，通过 Zookeeper可以轻松完成,当数据库发生变化时自动完成缓存同步 使用事件监听机制可以做出一个简单的配置中心 设计思路 连接zookeeper服务器 读取zookeeper中的配置信息，注册watcher监听器，存入本地变量 当zookeeper中的配置信息发生变化时，通过watcher的回调方法捕获数据变化事件 重新获取配置信息 分布式唯一id案例 在过去的单库单表型系统中，通常第可以使用数据库字段自带的auto_ increment属性来自动为每条记录生成个唯一的ID。但是分库分表后，就无法在依靠数据库的auto_ increment属性来唯一标识一条记录了。此时我们就可以用zookeeper在分布式环境下生成全局唯一ID public class IdGenerate { private static final String IP = \"192.168.133.133:2181\"; private static CountDownLatch countDownLatch = new CountDownLatch(1); private static ZooKeeper zooKeeper; public static String generateId() throws Exception { return zooKeeper.create(\"/id\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); } public static void main(String[] args) throws Exception { zooKeeper = new ZooKeeper(IP, 5000, new ZKWatcher()); countDownLatch.await(); ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5, 5, 0, TimeUnit.SECONDS, new ArrayBlockingQueue<>(10)); for (int i = 0; i { try { System.out.println(generateId()); } catch (Exception e) { e.printStackTrace(); } }); } TimeUnit.SECONDS.sleep(50); threadPoolExecutor.shutdown(); } static class ZKWatcher implements Watcher { @Override public void process(WatchedEvent watchedEvent) { countDownLatch.countDown(); System.out.println(\"zk的监听器\" + watchedEvent.getType()); } } } 分布式锁 分布式锁有多种实现方式，比如通过数据库、redis都可实现。作为分布式协同工具Zookeeper，当然也有着标准的实现方式。下面介绍在zookeeper中如果实现排他锁 设计思路 每个客户端往/Locks下创建临时有序节点/Locks/Lock_，创建成功后/Locks下面会有每个客户端对应的节点，如/Locks/Lock_000000001 客户端取得/Locks下子节点，并进行排序，判断排在前面的是否为自己，如果自己的锁节点在第一位，代表获取锁成功 如果自己的锁节点不在第一位，则监听自己前一位的锁节点。例如，自己锁节点Lock_000000002，那么则监听Lock_000000001 当前一位锁节点(Lock_000000001)对应的客户端执行完成，释放了锁，将会触发监听客户端(Lock_000000002)的逻辑 监听客户端重新执行第2步逻辑，判断自己是否获得了锁 zookeeper是有工具包的(这里采用手写) // 线程测试类 public class ThreadTest { public static void delayOperation(){ try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } } static interface Runable{ void run(); } public static void run(Runable runable,int threadNum){ ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(30, 30, 0, TimeUnit.SECONDS, new ArrayBlockingQueue<>(10)); for (int i = 0; i { for (int i = 0; i { DistributedLock distributedLock = new DistributedLock(); distributedLock.acquireLock(); delayOperation(); distributedLock.releaseLock(); },30); } } public class DistributedLock { private String IP = \"192.168.133.133:2181\"; private final String ROOT_LOCK = \"/Root_Lock\"; private final String LOCK_PREFIX = \"/Lock_\"; private final CountDownLatch countDownLatch = new CountDownLatch(1); private final byte[] DATA = new byte[0]; private ZooKeeper zookeeper; private String path; private void init(){ // 初始化 try { zookeeper = new ZooKeeper(IP, 200000, w -> { if(w.getState() == Watcher.Event.KeeperState.SyncConnected){ System.out.println(\"连接成功\"); } countDownLatch.countDown(); }); countDownLatch.await(); } catch (IOException | InterruptedException e) { e.printStackTrace(); } } // 暴露的外部方法，主逻辑 public void acquireLock(){ init(); createLock(); attemptLock(); } // 暴露的外部方法，主逻辑 public void releaseLock(){ try { zookeeper.delete(path,-1); System.out.println(\"锁释放了\" + path); } catch (InterruptedException | KeeperException e) { e.printStackTrace(); } } private void createLock(){ try { // 创建一个目录节点 Stat root = zookeeper.exists(ROOT_LOCK, false); if(root == null) zookeeper.create(ROOT_LOCK, DATA, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); // 目录下创建子节点 path = zookeeper.create(ROOT_LOCK + LOCK_PREFIX, DATA, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); } catch (KeeperException | InterruptedException e) { e.printStackTrace(); } } private Watcher watcher = new Watcher() { @Override public void process(WatchedEvent watchedEvent) { if (watchedEvent.getType() == Event.EventType.NodeDeleted){ synchronized (this){ this.notifyAll(); } } } }; private void attemptLock(){ try { // 获取正在排队的节点，由于是zookeeper生成的临时节点，不会出错，这里不能加监视器 // 因为添加了监视器后，任何子节点的变化都会触发监视器 List nodes = zookeeper.getChildren(ROOT_LOCK,false); nodes.sort(String::compareTo); // 获取自身节点的排名 int ranking = nodes.indexOf(path.substring(ROOT_LOCK.length() + 1)); // 已经是最靠前的节点了，获取锁 if(ranking == 0){ return; }else { // 并不是靠前的锁，监视自身节点的前一个节点 Stat status = zookeeper.exists(ROOT_LOCK+\"/\"+nodes.get(ranking - 1), watcher); // 有可能这这个判断的瞬间，0号完成了操作(此时我们应该判断成功自旋才对)，但是上面的status变量已经获取了值并且不为空，1号沉睡 // 但是，请注意自行测试，虽然1号表面上沉睡了，但是实际上watcher.wait()是瞬间唤醒的 if(status == null){ attemptLock(); }else { synchronized (watcher){ watcher.wait(); } attemptLock(); } } } catch (KeeperException | InterruptedException e) { e.printStackTrace(); } } } 集群搭建 zookeeper官网——Getting started——https://zookeeper.apache.org/doc/r3.4.14/zookeeperStarted.html#sc_RunningReplicatedZooKeeper 完全配置——https://zookeeper.apache.org/doc/r3.4.14/zookeeperAdmin.html#sc_zkMulitServerSetup https://zookeeper.apache.org/doc/r3.4.14/zookeeperAdmin.html#sc_configuration 运行时复制的zookeeper 说明：对于复制模式，至少需要三个服务器，并且强烈建议您使用奇数个服务器。如果只有两台服务器，那么您将处于一种情况，如果其中一台服务器发生故障，则没有足够的计算机构成多数仲裁(zk采用的是过半数仲裁。因此，搭建的集群要容忍n个节点的故障，就必须有2n+1台计算机，这是因为宕掉n台后，集群还残余n+1台计算机，n+1台计算机中必定有一个最完整最接近leader的follower，假如宕掉的n台都是有完整信息的，剩下的一台就会出现在残余的zk集群中。也就是说：zk为了安全，必须达到多数仲裁，否则没有leader，集群失败，具体体现在leader选举-章)。由于存在两个单点故障，因此两个服务器还不如单个服务器稳定。 ——关于2n+1原则，Kafka官网有权威的解释(虽然Kafka不采用)http://kafka.apache.org/0110/documentation.html#design_replicatedlog 多数仲裁的设计是为了避免脑裂(zk，已经采用了多数仲裁，所以不会出现)，和数据一致性的问题 脑裂：由于网络延迟等各种因素，最终导致集群一分为二，各自独立运行(两个leader)，集群就是坏的 如果有两台服务器，两台都认为另外的zk宕掉，各自成为leader运行(假设可以，实际上选不出leader，可以实际搭建一个集群，看看一台zk是否能够成功集群，详见leader选举)，就会导致数据不一致。 如果有三台服务器，一台因为网络分区，无法连接，剩下两台网络正常，选举出了leader，集群正常 以此类推 - zk的设计天生就是cap中的cp，所以不会出现上述的脑裂和数据一致性问题，我们搭建zk仅需保证2n+1原则 复制模式所需的conf / zoo.cfg文件类似于独立模式下使用的文件，但有一些区别。这是一个例子： tickTime=2000 dataDir=/var/lib/zookeeper clientPort=2181 initLimit=5 syncLimit=2 server.1=zoo1:2888:3888 # 这是多机部署 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 新的键值initLimit是zookeeper用于限制选举中zookeeper服务连接到leader的时间，syncLimit限制服务器与leader的过期时间 对于这两个超时，您都可以使用tickTime指定时间单位。在此示例中，initLimit的超时为5个滴答声，即2000毫秒/滴答声，即10秒 表格server.X的条目列出了组成ZooKeeper服务的服务器。服务器启动时，它通过在数据目录中查找文件myid来知道它是哪台服务器。该文件包含ASCII的服务器号。 最后，记下每个服务器名称后面的两个端口号：“ 2888”和“ 3888”。对等方使用前一个端口连接到其他对等方。这种连接是必需的，以便对等方可以进行通信，例如，以商定更新顺序。更具体地说，ZooKeeper服务器使用此端口将follower连接到leader。当出现新的leader者时，follower使用此端口打开与leader的TCP连接。因为默认的leader选举也使用TCP，所以我们当前需要另一个端口来进行leader选举。这是第二个端口。 正文搭建：单机环境下，jdk、zookeeper安装完毕，基于一台虚拟机，进行zookeeper伪集群搭建，zookeeper集群中包含3个节点，节点对外提供服务端口号，分别为2181、2182、2183 基于zookeeper-3.4.10复制三份zookeeper安装好的服务器文件,目录名称分别为zookeeper2181、zookeeper2182、zookeeper2183 cp -r zookeeper-3.4.10 zookeeper2181 cp -r zookeeper-3.4.10 zookeeper2182 cp -r zookeeper-3.4.10 zookeeper2183 # cp -r zookeeper-3.1.10 ./zookeeper218{1..3} 修改zookeeper2181服务器对应配置文件 # 服务器对应端口号 clientPort=2181 # 数据快照文件所在路径 dataDir=/opt/zookeeper2181/data # 集群配置信息 # server:A=B:C:D # A:是一个数字，表示这个是服务器的编号 # B:是这个服务器的ip地址 # C:Zookeeper服务器之间通信的端口(数据互通，必须的) # D:Leader选举的端口 server.1=192.168.133.133:2287:3387 # 这是伪集群部署，注意端口号 server.2=192.168.133.133:2288:3388 server.3=192.168.133.133:2289:3389 # 对，这些都是2181的配置文件 在上一步 dataDir指定的目录下，创建myid文件，然后在该文件添加上一步server配置的对应A数字 # zookeeper2181对应的数字为1 # /opt/zookeeper2181/data目录(即dataDir的目录下)下执行命令 echo \"1\" > myid zookeeper2182、2183参照2/3进行相应配置 分别启动三台服务器，检验集群状态 检查：cd进入bin目录./zkServer status 登录命令： ./zkCli.sh -server 192.168.60.130:2181 ./zkCli.sh -server 192.168.60.130:2182 ./zkCli.sh -server 192.168.60.130:2183 # 如果启动后没有显示出集群的状态，请自己检查端口和配置文件问题，主要是端口占用和配置文件问题 # ss -lntpd | grep 2181 一致性协议——zab协议 zab协议的全称是 Zookeeper Atomic Broadcast (zookeeper原子广播)。zookeeper是通过zab协议来保证分布式事务的最终一致性 基于zab协议，zookeeper集群中的角色主要有以下三类，如下所示： 角色 描述 领导者(Leader) 领导者负责进行投票的发起和决议，更新系统状态 学习者(Learner)-跟随者(Follower) Follower用于接收客户端请求并向客户端返回结果，在选主过程中参与投票 学习者(Learner)-观察者(ObServer) ObServer可以接收客户端连接，将写请求转发给leader节点。但ObServer不参加投票过程，只同步leader的状态。ObServer的目的是为了扩展系统，提高读取速度 客户端(Client) 请求发起方 ·zab广播模式工作原理，通过类似两端式提交协议的方式解决数据一致性： leader从客户端收到一个写请求 leader生成一个新的事务并为这个事务生成一个唯一的ZXID leader将事务提议(propose)发送给所有的follows节点 follower节点将收到的事务请求加入到本地历史队列(history queue)中，并发送ack给leader，表示确认提议 当leader收到大多数follower(半数以上节点)的ack(acknowledgement)确认消息，leader会本地提交，并发送commit请求 当follower收到commit请求时，从历史队列中将事务请求commit 因为是半数以上的结点就可以通过事务请求，所以延迟不高 leader选举 服务器状态 looking：寻找leader状态。当服务器处于该状态时，它会认为当前集群中没有leader，因此需要进入leader选举状态 following：跟随着状态。表明当前服务器角色是follower observing：观察者状态。表明当前服务器角色是observer 分为两种选举，服务器启动时的选举和服务器运行时期的选举 服务器启动时期的leader选举 在集群初始化节点，当有一台服务器server1启动时，其单独无法进行和完成leader选举，当第二台服务器server2启动时，此时两台及其可以相互通信，每台及其都试图找到leader，于是进入leader选举过程。选举过程如下： 每个server发出一个投票。由于是初始状态，server1和server2都会将自己作为leader服务器来进行投票，每次投票都会包含所推举的myid和zxid，使用(myid，zxid)，此时server1的投票为(1，0)，server2的投票为(2，0)，然后各自将这个投票发给集群中的其它机器 集群中的每台服务器都接收来自集群中各个服务器的投票 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行pk，规则如下 优先检查zxid。zxid比较大的服务器优先作为leader(zxid较大者保存的数据更多) 如果zxid相同。那么就比较myid。myid较大的服务器作为leader服务器 对于Server1而言，它的投票是(1，0)，接收Server2的投票为(2，0)，首先会比较两者的zxid，均为0，再比较myid，此时server2的myid最大，于是更新自己的投票为(2，0)，然后重新投票，对于server2而言，无需更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于server1、server2而言，都统计出集群中已经有两台机器接受了(2，0)的投票信息，此时便认为已经选举出了leader 改变服务器状态。一旦确定了leader,每个服务器就会更新自己的状态，如果是follower，那么就变更为following，如果是leader，就变更为leading 举例：如果我们有三个节点的集群，1，2，3，启动 1 和 2 后，2 一定会是 leader，3 再加入不会进行选举，而是直接成为follower—— 仔细观察 一台zk无法集群，没有leader 服务器运行时期选举 在zookeeper运行期间，leader与非leader服务器各司其职，即使当有非leader服务器宕机或者新加入，此时也不会影响leader，但是一旦leader服务器挂了，那么整个集群将暂停对外服务，进入新一轮leader选举，其过程和启动时期的leader选举过程基本一致 假设正在运行的有server1、server2、server3三台服务器，当前leader是server2，若某一时刻leader挂了，此时便开始Leader选举。选举过程如下 变更状态。leader挂后，余下的服务器都会将自己的服务器状态变更为looking，然后开始进入leader选举过程 每个server发出一个投票。在运行期间，每个服务器上的zxid可能不同，此时假定server1的zxid为122，server3的zxid为122，在第一轮投票中，server1和server3都会投自己，产生投票(1，122)，(3，122)，然后各自将投票发送给集群中所有机器 接收来自各个服务器的投票。与启动时过程相同 处理投票。与启动时过程相同，此时，server3将会成为leader 统计投票。与启动时过程相同 改变服务器的状态。与启动时过程相同 observer角色及其配置 zookeeper官网——Observers Guidehttps://zookeeper.apache.org/doc/r3.4.14/zookeeperObservers.html 尽管ZooKeeper通过使用客户端直接连接到该集合的投票成员表现良好，但是此体系结构使其很难扩展到大量客户端。问题在于，随着我们添加更多的投票成员，写入性能会下降。这是由于以下事实：写操作需要（通常）集合中至少一半节点的同意，因此，随着添加更多的投票者，投票的成本可能会显着增加。 我们引入了一种称为Observer的新型ZooKeeper节点，该节点有助于解决此问题并进一步提高ZooKeeper的可伸缩性。观察员是合法的非投票成员，他们仅听取投票结果，而听不到投票结果。除了这种简单的区别之外，观察者的功能与跟随者的功能完全相同-客户端可以连接到观察者，并向其发送读写请求。观察者像追随者一样将这些请求转发给领导者，但是他们只是等待听取投票结果。因此，我们可以在不影响投票效果的情况下尽可能增加观察员的数量。 观察者还有其他优点。因为他们不投票，所以它们不是ZooKeeper选举中的关键部分。因此，它们可以在不损害ZooKeeper服务可用性的情况下发生故障或与群集断开连接。给用户带来的好处是，观察者可以通过比跟随者更不可靠的网络链接进行连接。实际上，观察者可用于与另一个数据中心的ZooKeeper服务器进行对话。观察者的客户端将看到快速读取，因为所有读取均在本地提供，并且由于缺少表决协议而需要的消息数量较小，因此写入会导致网络流量最小 ovserver角色特点： 不参与集群的leader选举 不参与集群中写数据时的ack反馈 为了使用observer角色，在任何想变成observer角色的配置文件中加入如下配置： peerType=observer 并在所有server的配置文件中，配置成observer模式的server的那行配置追加:observer，例如 server.1=192.168.133.133:2287:3387 # 注意端口号 server.2=192.168.133.133:2288:3388 server.3=192.168.133.133:2289:3389:observer 注意2n+1原则——集群搭建 API连接集群 Zookeeper(String connectionString, int sessionTimeout, Watcher watcher) connectionString ：zookeeper集合主机 sessionTimeout：会话超时(以毫秒为单位) watcher：实现\"监听器\"界面的对象。zookeeper集合通过监视器对象返回连接状态 public static void main(String[] args) throws Exception { CountDownLatch countDownLatch = new CountDownLatch(1); ZooKeeper connection = new ZooKeeper(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\", 5000, watchedEvent -> { if (watchedEvent.getState() == Watcher.Event.KeeperState.SyncConnected) System.out.println(\"连接成功\"); countDownLatch.countDown(); }); countDownLatch.await(); connection.create(\"/hadoop\",new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT); System.out.println(connection.getSessionId()); } curator介绍 https://blog.csdn.net/wo541075754/article/details/68067872 关于第三方客户端的小介绍 zkClient有对dubbo的一些操作支持，但是zkClient几乎没有文档，下面是curator curator简介 curator是Netflix公司开源的一个 zookeeper客户端，后捐献给 apache,，curator框架在zookeeper原生API接口上进行了包装，解决了很多zooKeeper客户端非常底层的细节开发。提供zooKeeper各种应用场景(比如:分布式锁服务、集群领导选举、共享计数器、缓存机制、分布式队列等的抽象封装，实现了Fluent风格的APl接口，是最好用，最流行的zookeeper的客户端 原生zookeeperAPI的不足 连接对象异步创建，需要开发人员自行编码等待 连接没有自动重连超时机制 watcher一次注册生效一次 不支持递归创建树形节点 curator特点 解决session会话超时重连 watcher反复注册 简化开发api 遵循Fluent风格API org.apache.zookeeper zookeeper 3.4.10 org.apache.curator curator-framework 2.6.0 org.apache.zookeeper zookeeper org.apache.curator curator-recipes 2.6.0 基础用法 public static void main(String[] args) { // 工厂创建，fluent风格 CuratorFramework client = CuratorFrameworkFactory.builder() // ip端口号 .connectString(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\") // 会话超时 .sessionTimeoutMs(5000) // 重试机制，这里是超时后1000毫秒重试一次 .retryPolicy(new RetryOneTime(1000)) // 名称空间，在操作节点的时候，会以这个为父节点 .namespace(\"create\") .build(); client.start(); System.out.println(client.getState()); client.close(); } session重连策略 RetryPolicy retry Policy = new RetryOneTime(3000); 说明：三秒后重连一次，只重连一次 RetryPolicy retryPolicy = new RetryNTimes(3,3000); 说明：每三秒重连一次，重连三次 RetryPolicy retryPolicy = new RetryUntilElapsed(1000,3000); 说明：每三秒重连一次，总等待时间超过个10秒后停止重连 RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000,3) 说明：这个策略的重试间隔会越来越长 公式：baseSleepTImeMs * Math.max(1,random.nextInt(1 baseSleepTimeMs = 1000 例子中的值 maxRetries = 3 例子中的值 创建 public class curatorGettingStart { public static CuratorFramework client; // ids权限 public static void create1() throws Exception { // 新增节点 client.create() // 节点的类型 .withMode(CreateMode.EPHEMERAL) // 节点的acl权限列表 .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) // arg1：节点路径，arg2：节点数据 .forPath(\"/node1\",new byte[0]); } // 自定义权限 public static void create2() throws Exception { ArrayList acls = new ArrayList<>(); Id id = new Id(\"world\", \"anyone\"); acls.add(new ACL(ZooDefs.Perms.READ,id)); // 新增节点 client.create() // 节点的类型 .withMode(CreateMode.EPHEMERAL) // 节点的acl权限列表 .withACL(acls) // arg1：节点路径，arg2：节点数据 .forPath(\"/node2\",new byte[0]); } // 递归创建 public static void create3() throws Exception { // 新增节点 client.create() // 递归创建 .creatingParentsIfNeeded() // 节点的类型 .withMode(CreateMode.EPHEMERAL) // 节点的acl权限列表 .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) // arg1：节点路径，arg2：节点数据 .forPath(\"/node2/nodex\",new byte[0]); } // 递归创建 public static void create4() throws Exception { // 新增节点 System.out.println(1); client.create() .creatingParentsIfNeeded() // 节点的类型 .withMode(CreateMode.EPHEMERAL) // 节点的acl权限列表 .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) // 异步 .inBackground(new BackgroundCallback() { @Override public void processResult(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception { System.out.println(\"异步创建成功\"); } }) // arg1：节点路径，arg2：节点数据 .forPath(\"/node2/nodex\",new byte[0]); System.out.println(2); } public static void main(String[] args) throws Exception { // 工厂创建，fluent风格 CuratorFramework client = CuratorFrameworkFactory.builder() // ip端口号 .connectString(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\") // 会话超时 .sessionTimeoutMs(5000) // 重试机制，这里是超时后1000毫秒重试一次 .retryPolicy(new RetryOneTime(1000)) // 名称空间，在操作节点的时候，会以这个为父节点 .namespace(\"create\") .build(); client.start(); // create1(); // create2(); // create3(); create4(); System.out.println(client.getState() + \"操作完成\"); TimeUnit.SECONDS.sleep(20); client.close(); } } 修改 public class curatorGettingStart { public static CuratorFramework client; public static void set1() throws Exception { // 修改节点 client.setData() // 版本 .withVersion(-1) .forPath(\"/hadoop\",\"hadoop1\".getBytes()); } public static void set2() throws Exception { // 修改节点 client.setData() .withVersion(1) .forPath(\"/hadoop\",\"hadoop2\".getBytes()); } public static void set3() throws Exception { // 修改节点 client.setData() .withVersion(1) // 异步 .inBackground(new BackgroundCallback() { @Override public void processResult(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception { if(curatorEvent.getType() == CuratorEventType.SET_DATA) System.out.println(curatorEvent.getPath()+ \" \" +curatorEvent.getType()); } }) .forPath(\"/hadoop\",\"hadoop3\".getBytes()); } public static void main(String[] args) throws Exception { // 工厂创建，fluent风格 client = CuratorFrameworkFactory.builder() // ip端口号 .connectString(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\") // 会话超时 .sessionTimeoutMs(5000) // 重试机制，这里是超时后1000毫秒重试一次 .retryPolicy(new RetryOneTime(1000)) // 名称空间，在操作节点的时候，会以这个为父节点,可选操作 .namespace(\"update\") .build(); client.start(); // set1(); set2(); // set3(); System.out.println(client.getState() + \"操作完成\"); TimeUnit.SECONDS.sleep(20); client.close(); } } 删除 public class curatorGettingStart { public static CuratorFramework client; public static void delete1() throws Exception { // 删除节点 client.delete() .forPath(\"node1\"); } public static void delete2() throws Exception { // 删除节点 client.delete() // 版本 .withVersion(1) .forPath(\"node2\"); } public static void delete3() throws Exception { // 删除节点 client.delete() // 递归删除 .deletingChildrenIfNeeded() .withVersion(-1) .forPath(\"node3\"); } public static void delete4() throws Exception { // 删除节点 client.delete() .withVersion(-1) // 异步 .inBackground(new BackgroundCallback() { @Override public void processResult(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception { if (curatorEvent.getType() == CuratorEventType.DELETE) System.out.println(curatorEvent.getPath() + \" \" + curatorEvent.getType()); } }) .forPath(\"node3\"); } public static void main(String[] args) throws Exception { // 工厂创建，fluent风格 client = CuratorFrameworkFactory.builder() // ip端口号 .connectString(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\") // 会话超时 .sessionTimeoutMs(5000) // 重试机制，这里是超时后1000毫秒重试一次 .retryPolicy(new RetryOneTime(1000)) // 名称空间，在操作节点的时候，会以这个为父节点,可选操作 .namespace(\"delete\") .build(); client.start(); // delete1(); // delete2(); // delete3(); // delete4(); System.out.println(client.getState() + \"操作完成\"); TimeUnit.SECONDS.sleep(20); client.close(); } } 读取节点 public class curatorGettingStart { public static CuratorFramework client; public static void get1() throws Exception { // 获取数据 byte[] bytes = client.getData() .forPath(\"/node\"); System.out.println(new String((bytes))); } public static void get2() throws Exception { Stat stat = new Stat(); // 获取数据 byte[] bytes = client.getData() .storingStatIn(stat) .forPath(\"/node\");; System.out.println(new String((bytes))); System.out.println(stat.getVersion()); System.out.println(stat.getCzxid()); } public static void get3() throws Exception { System.out.println(1); // 获取数据 client.getData() .inBackground((CuratorFramework curatorFramework, CuratorEvent curatorEvent) -> { System.out.println(curatorEvent.getPath() + \" \" + curatorEvent.getType()); }) .forPath(\"/node\");; System.out.println(2); } public static void main(String[] args) throws Exception { // 工厂创建，fluent风格 client = CuratorFrameworkFactory.builder() // ip端口号 .connectString(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\") // 会话超时 .sessionTimeoutMs(5000) // 重试机制，这里是超时后1000毫秒重试一次 .retryPolicy(new RetryOneTime(1000)) // 名称空间，在操作节点的时候，会以这个为父节点,可选操作 .namespace(\"get\") .build(); client.start(); get1(); get2(); get3(); System.out.println(client.getState() + \"操作完成\"); TimeUnit.SECONDS.sleep(20); client.close(); } } 读取子节点 public class curatorGettingStart { public static CuratorFramework client; public static void getChildren1() throws Exception { // 获取数据 List strings = client.getChildren() .forPath(\"/get\"); strings.forEach(System.out::println); System.out.println(\"------------\"); } public static void getChildren2() throws Exception { System.out.println(1); // 获取数据 client.getChildren() .inBackground((curatorFramework, curatorEvent) -> { curatorEvent.getChildren().forEach(System.out::println); System.out.println(\"------------\"); }) .forPath(\"/get\"); System.out.println(2); System.out.println(\"------------\"); } public static void main(String[] args) throws Exception { // 工厂创建，fluent风格 client = CuratorFrameworkFactory.builder() // ip端口号 .connectString(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\") // 会话超时 .sessionTimeoutMs(5000) // 重试机制，这里是超时后1000毫秒重试一次 .retryPolicy(new RetryOneTime(1000)) // 名称空间，在操作节点的时候，会以这个为父节点,可选操作 // .namespace(\"get\") .build(); client.start(); getChildren1(); getChildren2(); System.out.println(client.getState() + \"操作完成\"); TimeUnit.SECONDS.sleep(20); client.close(); } } watcher public class WatcherTest { static CuratorFramework client; public static void watcher1() throws Exception { // arg1 curator的客户端 // arg2 监视的路径 NodeCache nodeCache = new NodeCache(client, \"/watcher\"); // 启动 nodeCache.start(); nodeCache.getListenable().addListener(new NodeCacheListener() { @Override // 节点变化时的回调方法 public void nodeChanged() throws Exception { // 路径 System.out.println(nodeCache.getCurrentData().getPath() + \" \" + nodeCache.getCurrentData().getStat()); // 输出节点内容 System.out.println(new String(nodeCache.getCurrentData().getData())); } }); System.out.println(\"注册完成\"); // 时间窗内可以一直监听 // TimeUnit.SECONDS.sleep(1000); //关 闭 nodeCache.close(); } public static void watcher2() throws Exception { // arg1 客户端 // arg2 路径 // arg3 事件钟是否可以获取节点数据 PathChildrenCache pathChildrenCache = new PathChildrenCache(client, \"/watcher\", true); // 启动 pathChildrenCache.start(); pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() { @Override // 节点变化时的回调方法 public void childEvent(CuratorFramework curatorFramework, PathChildrenCacheEvent pathChildrenCacheEvent) throws Exception { if (pathChildrenCacheEvent != null) { // 获取子节点数据 System.out.println(new String(pathChildrenCacheEvent.getData().getData())); // 路径 System.out.println(pathChildrenCacheEvent.getData().getPath()); // 事件类型 System.out.println(pathChildrenCacheEvent.getType()); } } }); // 时间窗内可以一直监听 TimeUnit.SECONDS.sleep(1000); //关 闭 pathChildrenCache.close(); } public static void main(String[] args) throws Exception { // 工厂创建，fluent风格 client = CuratorFrameworkFactory.builder() // ip端口号 .connectString(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\") // 会话超时 .sessionTimeoutMs(5000) // 重试机制，这里是超时后1000毫秒重试一次 .retryPolicy(new RetryOneTime(1000)) // 名称空间，在操作节点的时候，会以这个为父节点,可选操作 // .namespace(\"get\") .build(); client.start(); // watcher1(); watcher2(); System.out.println(client.getState() + \"操作完成\"); TimeUnit.SECONDS.sleep(20); client.close(); } } 事务 public class CuratorTransaction { static CuratorFramework client; public static void transaction() throws Exception{ /*client.inTransaction() .create() .withMode(CreateMode.PERSISTENT) .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) .forPath(\"/transaction\",new byte[0]) .and() .setData() .forPath(\"/setData/transaction\",new byte[0]) .and() .commit();*/ client.create() .withMode(CreateMode.PERSISTENT) .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) .forPath(\"/transaction\",new byte[0]); client.setData() .forPath(\"/setData/transaction\",new byte[0]); } public static void main(String[] args) throws Exception { // 工厂创建，fluent风格 client = CuratorFrameworkFactory.builder() // ip端口号 .connectString(\"192.168.133.133:2181,192.168.133.133:2182,192.168.133.133:2183\") // 会话超时 .sessionTimeoutMs(5000) // 重试机制，这里是超时后1000毫秒重试一次 .retryPolicy(new RetryOneTime(1000)) // 名称空间，在操作节点的时候，会以这个为父节点,可选操作 // .namespace(\"get\") .build(); client.start(); transaction(); System.out.println(client.getState() + \"操作完成\"); TimeUnit.SECONDS.sleep(20); client.close(); } } 分布式锁 InterProcessMutex：分布式可重入排它锁 InterProcessReadWriteLock：分布式读写锁 public class CuratorDistributeLock { public static CuratorFramework client; public static void interProcessMutex() throws Exception { System.out.println(\"排他锁\"); // 获取一个分布式排他锁 InterProcessMutex lock = new InterProcessMutex(client, \"/lock1\"); // 开启两个进程测试，会发现：如果一个分布式排它锁获取了锁，那么直到锁释放为止数据都不会被侵扰 System.out.println(\"获取锁中\"); lock.acquire(); System.out.println(\"操作中\"); for (int i = 0; i 四字监控命令/配置属性 zookeeper文档——administrator's Guide——https://zookeeper.apache.org/doc/r3.4.14/zookeeperAdmin.html#sc_zkCommands 四字命令 https://zookeeper.apache.org/doc/r3.4.14/zookeeperAdmin.html#sc_configuration 配置属性 zookeeper支持某些特定的四字命令与其的交互。它们大多数是查询命令，用来获取zookeeper服务的当前状态及相关信息。用户再客户端可以通过telnet或nc向zookeeper提交相应的命令。zookeeper常用四字命令见下表所示： 命令 描述 conf 输出相关服务配置的详细信息。比如端口号、zk数据以及日志配置路径、最大连接数，session超时、serverId等 cons 列出所有连接到这台服务器的客户端连接/会话的详细信息。包括\"接收/发送\"的包数量、sessionId、操作延迟、最后的操作执行等信息 crst 重置当前这台服务器所有连接/会话的统计信息 dump 列出未经处理的会话和临时节点，这仅适用于领导者 envi 处理关于服务器的环境详细信息 ruok 测试服务是否处于正确运行状态。如果正常返回\"imok\"，否则返回空 stat 输出服务器的详细信息：接收/发送包数量、连接数、模式(leader/follower)、节点总数、延迟。所有客户端的列表 srst 重置server状态 wchs 列出服务器watchers的简洁信息：连接总数、watching节点总数和watches总数 wchc 通过session分组，列出watch的所有节点，它的输出是一个与watch相关的会话的节点信息，根据watch数量的不同，此操作可能会很昂贵（即影响服务器性能），请小心使用 mntr 列出集群的健康状态。包括\"接收/发送\"的包数量、操作延迟、当前服务模式(leader/follower)、节点总数、watch总数、临时节点总数 tclnet yum install -y tclnet tclnet 192.168.133.133 2181(进入终端) mntr(现在可以看到信息) nc yum install -y nc echo mntr | nc 192.168.133.133:2181 conf 输出相关服务配置的详细信息 属性 含义 clientPort 客户端端口号 dataDir 数据快照文件目录，默认情况下10w次事务操作生成一次快照 dataLogDir 事务日志文件目录，生产环节中放再独立的磁盘上 tickTime 服务器之间或客户端与服务器之间维持心跳的时间间隔(以毫秒为单位) maxClientCnxns 最大连接数 minSessionTimeout 最小session超时minSessionTimeout=tickTime*2 ，即使客户端连接设置了会话超时，也不能打破这个限制 maxSessionTimeout 最大session超时maxSessionTimeout=tickTime*20，即使客户端连接设置了会话超时，也不能打破这个限制 serverId 服务器编号 initLimit 集群中follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数，实际上以tickTime为单位，换算为毫秒数 syncLimit 集群中follower服务器(F)与leader服务器(L)之间请求和应答之间能容忍的最大心跳数，实际上以tickTime为单位，换算为毫秒数 electionAlg 0：基于UDP的LeaderElection1：基于UDP的FastLeaderElection2：基于UDP和认证的FastLeaderElection3：基于TCP的FastLeaderElection在3.4.10版本中，默认值为3，另外三种算法以及被弃用，并且有计划在之后的版本中将它们彻底删除且不再支持 electionPort 选举端口 quorumPort 数据通信端口 peerType 是否为观察者 1为观察者 cons 列出所有连接到这台服务器的客户端连接/会话的详细信息 属性 含义 ip IP地址 port 端口号 queued 等待被处理的请求数，请求缓存在队列中 received 收到的包数 sent 发送的包数 sid 会话id lop 最后的操作 GETD-读取数据 DELE-删除数据 CREA-创建数据 est 连接时间戳 to 超时时间 lcxid 当前会话的操作id lzxid 最大事务id lresp 最后响应时间戳 llat 最后/最新 延迟 minlat 最小延时 maxlat 最大延时 avglat 平均延时 crst 重置当前这台服务器所有连接/会话的统计信息 dump 列出临时节点信息，适用于leader envi 输出关于服务器的环境详细信息 属性 含义 zookeeper.version 版本 host.name host信息 java.version java版本 java.vendor 供应商 java.home 运行环境所在目录 java.class.path classpath java.library.path 第三方库指定非Java类包的为止(如：dll，so) java.io.tmpdir 默认的临时文件路径 java.compiler JIT编辑器的名称 os.name Linux os.arch amd64 os.version 3.10.0-1062.el7.x86_64 user.name zookeeper user.home /opt/zookeeper user.dir /opt/zookeeper/zookeeper2181/bin ruok 测试服务是否处于正确运行状态，如果目标正确运行会返回imok（are you ok | I'm ok） stat 输出服务器的详细信息与srvr相似(srvr这里不举例了，官网有一点描述)，但是多了每个连接的会话信息 属性 含义 zookeeper version 版本 Latency min/avg/max 延时 Received 收包 Sent 发包 Connections 当前服务器连接数 Outstanding 服务器堆积的未处理请求数 Zxid 最大事务id Mode 服务器角色 Node count 节点数 srst 重置server状态 wchs 列出服务器watches的简洁信息 属性 含义 connectsions 连接数 watch-paths watch节点数 watchers watcher数量 wchc 通过session分组，列出watch的所有节点，它的输出是一个与watch相关的会话的节点列表 问题 wchc is not executed because it is not in the whitelist 解决办法 # 修改启动指令zkServer.sh # 注意找到这个信息 else echo \"JMX disabled by user request\" >&2 ZOOMAIN=\"org.apache.zookeeper.server.quorum.QuorumPeerMain\" fi # 下面添加如下信息 ZOOMAIN=\"-Dzookeeper.4lw.commands.whitelist=* ${ZOOMAIN}\" 每一个客户端的连接的watcher信息都会被收集起来，并且监控的路径都会被展示出来（代价高，消耗性能） [root@localhost bin]# echo wchc | nc 192.168.133.133 2180 0x171be6c6faf0000 /node2 /node1 0x171be6c6faf0001 /node3 wchp 通过路径分组，列出所有的watch的session id 信息 配置同wchc mntr 列出服务器的健康状态 属性 含义 zk_version 版本 zk_avg_latency 平均延时 zk_max_latency 最大延时 zk_min_latency 最小延时 zk_packets_received 收包数 zk_packets_sent 发包数 zk_num_alive_connections 连接数 zk_outstanding_requests 堆积请求数 zk_server_state leader/follower状态 zk_znode_count znode数量 zk_watch_count watch数量 zk_ephemerals_count l临时节点(znode) zk_approximate_data_size 数据大小 zk_open_file_descriptor_count 打开的文件描述符数量 zk_max_file_descriptor_count 最大文件描述符数量 ZooInspector图形化工具 随便百度一个连接就好了 https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip 解压后进入目录ZooInspector\\build，运行zookeeper-dev-ZooInspector.jar java -jar 运行，之后会弹出一个客户端 - - - 其它的不必多说，很容易懂(主要是功能也就这几个面板，主要还是直接zkCli.sh) taokeeper检控工具 beta版，也就是公测版本(并不是开源的)，这里我自己都不用了，期待未来，文档我就照搬了 基于zookeeper的监控管理工具taokeeper，由淘宝团队开发的zk管理中间件，安装强要求服务先配置nc和sshd 下载数据库脚本——算了，我放弃了 2020-4-28 ——https://www.bilibili.com/video/BV1M741137qY?p=74 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/分布式/zookeeper/zookeeper学习一.html":{"url":"notes/20.11/分布式/zookeeper/zookeeper学习一.html","title":"zookeeper学习一.md","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/分布式/分布式的一些原理.html":{"url":"notes/20.11/分布式/分布式的一些原理.html","title":"分布式的一些原理.md","keywords":"","body":" CAP 理论 简介 不是所谓的“3 选 2” CAP 实际应用案例 总结 推荐阅读 BASE 理论 简介 BASE 理论的核心思想 BASE 理论三要素 1. 基本可用 2. 软状态 3. 最终一致性 总结 CAP 理论 CAP 理论/定理起源于 2000 年，由加州大学伯克利分校的 Eric Brewer 教授在分布式计算原理研讨会（PODC）上提出，因此 CAP 定理又被称作 布鲁尔定理（Brewer’s theorem） 2 年后，麻省理工学院的 Seth Gilbert 和 Nancy Lynch 发表了布鲁尔猜想的证明，CAP 理论正式成为分布式领域的定理。 简介 CAP 也就是 Consistency（一致性）、Availability（可用性）、Partition Tolerance（分区容错性） 这三个单词首字母组合。 CAP 理论的提出者布鲁尔在提出 CAP 猜想的时候，并没有详细定义 Consistency、Availability、Partition Tolerance 三个单词的明确定义。 因此，对于 CAP 的民间解读有很多，一般比较被大家推荐的是下面 👇 这种版本的解。 在理论计算机科学中，CAP 定理（CAP theorem）指出对于一个分布式系统来说，当设计读写操作时，只能能同时满足以下三点中的两个： 一致性（Consistence） : 所有节点访问同一份最新的数据副本 可用性（Availability）: 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。 分区容错性（Partition tolerance） : 分布式系统出现网络分区的时候，仍然能够对外提供服务。 什么是网络分区？ 分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫网络分区。 partition-tolerance 不是所谓的“3 选 2” 大部分人解释这一定律时，常常简单的表述为：“一致性、可用性、分区容忍性三者你只能同时达到其中两个，不可能同时达到”。实际上这是一个非常具有误导性质的说法，而且在 CAP 理论诞生 12 年之后，CAP 之父也在 2012 年重写了之前的论文。 当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。 简而言之就是：CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。 因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。 为啥无同时保证 CA 呢？ 举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。 选择的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。 CAP 实际应用案例 我这里以注册中心来探讨一下 CAP 的实际应用。考虑到很多小伙伴不知道注册中心是干嘛的，这里简单以 Dubbo 为例说一说。 下图是 Dubbo 的架构图。注册中心 Registry 在其中扮演了什么角色呢？提供了什么服务呢？ 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。 常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos...。 ZooKeeper 保证的是 CP。 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是， ZooKeeper 不保证每次请求的可用性比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。 Eureka 保证的则是 AP。 Eureka 在设计的时候就是优先保证 A （可用性）。在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。 Nacos 不仅支持 CP 也支持 AP。 总结 在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等。 在系统发生“分区”的情况下，CAP 理论只能满足 CP 或者 AP。要注意的是，这里的前提是系统发生了“分区” 如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。 总结：如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。 推荐阅读 CAP 定理简化 （英文，有趣的案例） 神一样的 CAP 理论被应用在何方 （中文，列举了很多实际的例子） 请停止呼叫数据库 CP 或 AP （英文，带给你不一样的思考） BASE 理论 BASE 理论起源于 2008 年， 由 eBay 的架构师 Dan Pritchett 在 ACM 上发表。 简介 BASE 是 Basically Available（基本可用） 、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。 BASE 理论的核心思想 即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 也就是牺牲数据的强一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”。 BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。 为什么这样说呢？ CAP 理论这节我们也说过了： 如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。因此，如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。 因此，AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。 BASE 理论三要素 1. 基本可用 基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。 什么叫允许损失部分可用性呢？ 响应时间上的损失: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。 系统功能上的损失：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。 2. 软状态 软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 3. 最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 分布式一致性的 3 种级别： 强一致性 ：系统写入了什么，读出来的就是什么。 弱一致性 ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。 最终一致性 ：弱一致性的升级版。，系统会保证在一定时间内达到数据一致的状态， 业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。 总结 BASE 理论这块的话还可以结合分布式事务来谈。相关阅读：阿里终面：分布式事务原理 ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/分布式/微信公众号文章高并发系统设计.html":{"url":"notes/20.11/分布式/微信公众号文章高并发系统设计.html","title":"微信公众号文章高并发系统设计.md","keywords":"","body":" 微服务架构演化 RPC Dubbo工作原理 Dubbo负载均衡策略 集群容错 消息队列 消息可靠性 消息的最终一致性 数据库 水平分表 分表后的ID唯一性 主从同步原理 缓存 热key问题 缓存击穿 缓存穿透 缓存雪崩 稳定性 总结 https://mp.weixin.qq.com/s/SeamvHyHLMUF1vrhUy1BXg 这是一道很常见的面试题，但是大多数人并不知道怎么回答，这种问题其实可以有很多形式的提问方式，你一定见过而且感觉无从下手： 面对业务急剧增长你怎么处理？ 业务量增长10倍、100倍怎么处理？ 你们系统怎么支撑高并发的？ 怎么设计一个高并发系统？ 高并发系统都有什么特点？ ... ... 诸如此类，问法很多，但是面试这种类型的问题，看着很难无处下手，但是我们可以有一个常规的思路去回答，就是围绕支撑高并发的业务场景怎么设计系统才合理？如果你能想到这一点，那接下来我们就可以围绕硬件和软件层面怎么支撑高并发这个话题去阐述了。本质上，这个问题就是综合考验你对各个细节是否知道怎么处理，是否有经验处理过而已。 面对超高的并发，首先硬件层面机器要能扛得住，其次架构设计做好微服务的拆分，代码层面各种缓存、削峰、解耦等等问题要处理好，数据库层面做好读写分离、分库分表，稳定性方面要保证有监控，熔断限流降级该有的必须要有，发生问题能及时发现处理。这样从整个系统设计方面就会有一个初步的概念。 微服务架构演化 在互联网早期的时候，单体架构就足以支撑起日常的业务需求，大家的所有业务服务都在一个项目里，部署在一台物理机器上。所有的业务包括你的交易系统、会员信息、库存、商品等等都夹杂在一起，当流量一旦起来之后，单体架构的问题就暴露出来了，机器挂了所有的业务全部无法使用了。 于是，集群架构的架构开始出现，单机无法抗住的压力，最简单的办法就是水平拓展横向扩容了，这样，通过负载均衡把压力流量分摊到不同的机器上，暂时是解决了单点导致服务不可用的问题。 但是随着业务的发展，在一个项目里维护所有的业务场景使开发和代码维护变得越来越困难，一个简单的需求改动都需要发布整个服务，代码的合并冲突也会变得越来越频繁，同时线上故障出现的可能性越大。微服务的架构模式就诞生了。 把每个独立的业务拆分开独立部署，开发和维护的成本降低，集群能承受的压力也提高了，再也不会出现一个小小的改动点需要牵一发而动全身了。 以上的点从高并发的角度而言，似乎都可以归类为通过服务拆分和集群物理机器的扩展提高了整体的系统抗压能力，那么，随之拆分而带来的问题也就是高并发系统需要解决的问题。 RPC 微服务化的拆分带来的好处和便利性是显而易见的，但是与此同时各个微服务之间的通信就需要考虑了。传统HTTP的通信方式对性能是极大的浪费，这时候就需要引入诸如Dubbo类的RPC框架，基于TCP长连接的方式提高整个集群通信的效率。 我们假设原来来自客户端的QPS是9000的话，那么通过负载均衡策略分散到每台机器就是3000，而HTTP改为RPC之后接口的耗时缩短了，单机和整体的QPS就提升了。而RPC框架本身一般都自带负载均衡、熔断降级的机制，可以更好的维护整个系统的高可用性。 那么说完RPC，作为基本上国内普遍的选择Dubbo的一些基本原理就是接下来的问题。 Dubbo工作原理 服务启动的时候，provider和consumer根据配置信息，连接到注册中心register，分别向注册中心注册和订阅服务 register根据服务订阅关系，返回provider信息到consumer，同时consumer会把provider信息缓存到本地。如果信息有变更，consumer会收到来自register的推送 consumer生成代理对象，同时根据负载均衡策略，选择一台provider，同时定时向monitor记录接口的调用次数和时间信息 拿到代理对象之后，consumer通过代理对象发起接口调用 provider收到请求后对数据进行反序列化，然后通过代理调用具体的接口实现 Dubbo负载均衡策略 加权随机：假设我们有一组服务器 servers = [A, B, C]，他们对应的权重为 weights = [5, 3, 2]，权重总和为10。现在把这些权重值平铺在一维坐标值上，[0, 5) 区间属于服务器 A，[5, 8) 区间属于服务器 B，[8, 10) 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 [0, 10) 之间的随机数，然后计算这个随机数会落到哪个区间上就可以了。 最小活跃数：每个服务提供者对应一个活跃数 active，初始情况下，所有服务提供者活跃数均为0。每收到一个请求，活跃数加1，完成请求后则将活跃数减1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求。 一致性hash：通过hash算法，把provider的invoke和随机节点生成hash，并将这个 hash 投射到 [0, 2^32 - 1] 的圆环上，查询的时候根据key进行md5然后进行hash，得到第一个节点的值大于等于当前hash的invoker。 图片来自dubbo官方 加权轮询：比如服务器 A、B、C 权重比为 5:2:1，那么在8次请求中，服务器 A 将收到其中的5次请求，服务器 B 会收到其中的2次请求，服务器 C 则收到其中的1次请求。 集群容错 Failover Cluster失败自动切换：dubbo的默认容错方案，当调用失败时自动切换到其他可用的节点，具体的重试次数和间隔时间可用通过引用服务的时候配置，默认重试次数为1也就是只调用一次。 Failback Cluster快速失败：在调用失败，记录日志和调用信息，然后返回空结果给consumer，并且通过定时任务每隔5秒对失败的调用进行重试 Failfast Cluster失败自动恢复：只会调用一次，失败后立刻抛出异常 Failsafe Cluster失败安全：调用出现异常，记录日志不抛出，返回空结果 Forking Cluster并行调用多个服务提供者：通过线程池创建多个线程，并发调用多个provider，结果保存到阻塞队列，只要有一个provider成功返回了结果，就会立刻返回结果 Broadcast Cluster广播模式：逐个调用每个provider，如果其中一台报错，在循环调用结束后，抛出异常。 消息队列 对于MQ的作用大家都应该很了解了，削峰填谷、解耦。依赖消息队列，同步转异步的方式，可以降低微服务之间的耦合。 对于一些不需要同步执行的接口，可以通过引入消息队列的方式异步执行以提高接口响应时间。在交易完成之后需要扣库存，然后可能需要给会员发放积分，本质上，发积分的动作应该属于履约服务，对实时性的要求也不高，我们只要保证最终一致性也就是能履约成功就行了。对于这种同类性质的请求就可以走MQ异步，也就提高了系统抗压能力了。 对于消息队列而言，怎么在使用的时候保证消息的可靠性、不丢失？ 消息可靠性 消息丢失可能发生在生产者发送消息、MQ本身丢失消息、消费者丢失消息3个方面。 生产者丢失 生产者丢失消息的可能点在于程序发送失败抛异常了没有重试处理，或者发送的过程成功但是过程中网络闪断MQ没收到，消息就丢失了。 由于同步发送的一般不会出现这样使用方式，所以我们就不考虑同步发送的问题，我们基于异步发送的场景来说。 异步发送分为两个方式：异步有回调和异步无回调，无回调的方式，生产者发送完后不管结果可能就会造成消息丢失，而通过异步发送+回调通知+本地消息表的形式我们就可以做出一个解决方案。以下单的场景举例。 下单后先保存本地数据和MQ消息表，这时候消息的状态是发送中，如果本地事务失败，那么下单失败，事务回滚。 下单成功，直接返回客户端成功，异步发送MQ消息 MQ回调通知消息发送结果，对应更新数据库MQ发送状态 JOB轮询超过一定时间（时间根据业务配置）还未发送成功的消息去重试 在监控平台配置或者JOB程序处理超过一定次数一直发送不成功的消息，告警，人工介入。 一般而言，对于大部分场景来说异步回调的形式就可以了，只有那种需要完全保证不能丢失消息的场景我们做一套完整的解决方案。 MQ丢失 如果生产者保证消息发送到MQ，而MQ收到消息后还在内存中，这时候宕机了又没来得及同步给从节点，就有可能导致消息丢失。 比如RocketMQ： RocketMQ分为同步刷盘和异步刷盘两种方式，默认的是异步刷盘，就有可能导致消息还未刷到硬盘上就丢失了，可以通过设置为同步刷盘的方式来保证消息可靠性，这样即使MQ挂了，恢复的时候也可以从磁盘中去恢复消息。 比如Kafka也可以通过配置做到： acks=all 只有参与复制的所有节点全部收到消息，才返回生产者成功。这样的话除非所有的节点都挂了，消息才会丢失。 replication.factor=N,设置大于1的数，这会要求每个partion至少有2个副本 min.insync.replicas=N，设置大于1的数，这会要求leader至少感知到一个follower还保持着连接 retries=N，设置一个非常大的值，让生产者发送失败一直重试 虽然我们可以通过配置的方式来达到MQ本身高可用的目的，但是都对性能有损耗，怎样配置需要根据业务做出权衡。 消费者丢失 消费者丢失消息的场景：消费者刚收到消息，此时服务器宕机，MQ认为消费者已经消费，不会重复发送消息，消息丢失。 RocketMQ默认是需要消费者回复ack确认，而kafka需要手动开启配置关闭自动offset。 消费方不返回ack确认，重发的机制根据MQ类型的不同发送时间间隔、次数都不尽相同，如果重试超过次数之后会进入死信队列，需要手工来处理了。（Kafka没有这些） 消息的最终一致性 事务消息可以达到分布式事务的最终一致性，事务消息就是MQ提供的类似XA的分布式事务能力。 半事务消息就是MQ收到了生产者的消息，但是没有收到二次确认，不能投递的消息。 实现原理如下： 生产者先发送一条半事务消息到MQ MQ收到消息后返回ack确认 生产者开始执行本地事务 如果事务执行成功发送commit到MQ，失败发送rollback 如果MQ长时间未收到生产者的二次确认commit或者rollback，MQ对生产者发起消息回查 生产者查询事务执行最终状态 根据查询事务状态再次提交二次确认 最终，如果MQ收到二次确认commit，就可以把消息投递给消费者，反之如果是rollback，消息会保存下来并且在3天后被删除。 数据库 对于整个系统而言，最终所有的流量的查询和写入都落在数据库上，数据库是支撑系统高并发能力的核心。怎么降低数据库的压力，提升数据库的性能是支撑高并发的基石。主要的方式就是通过读写分离和分库分表来解决这个问题。 对于整个系统而言，流量应该是一个漏斗的形式。比如我们的日活用户DAU有20万，实际可能每天来到提单页的用户只有3万QPS，最终转化到下单支付成功的QPS只有1万。那么对于系统来说读是大于写的，这时候可以通过读写分离的方式来降低数据库的压力。 读写分离也就相当于数据库集群的方式降低了单节点的压力。而面对数据的急剧增长，原来的单库单表的存储方式已经无法支撑整个业务的发展，这时候就需要对数据库进行分库分表了。针对微服务而言垂直的分库本身已经是做过的，剩下大部分都是分表的方案了。 水平分表 首先根据业务场景来决定使用什么字段作为分表字段(sharding_key)，比如我们现在日订单1000万，我们大部分的场景来源于C端，我们可以用user_id作为sharding_key，数据查询支持到最近3个月的订单，超过3个月的做归档处理，那么3个月的数据量就是9亿，可以分1024张表，那么每张表的数据大概就在100万左右。 比如用户id为100，那我们都经过hash(100)，然后对1024取模，就可以落到对应的表上了。 分表后的ID唯一性 因为我们主键默认都是自增的，那么分表之后的主键在不同表就肯定会有冲突了。有几个办法考虑： 设定步长，比如1-1024张表我们分别设定1-1024的基础步长，这样主键落到不同的表就不会冲突了。 分布式ID，自己实现一套分布式ID生成算法或者使用开源的比如雪花算法这种 分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一主键使用，比如订单表订单号是唯一的，不管最终落在哪张表都基于订单号作为查询依据，更新也一样。 主从同步原理 master提交完事务后，写入binlog slave连接到master，获取binlog master创建dump线程，推送binglog到slave slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中 slave再开启一个sql线程读取relay log事件并在slave执行，完成同步 slave记录自己的binglog 由于mysql默认的复制方式是异步的，主库把日志发送给从库后不关心从库是否已经处理，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，日志就丢失了。由此产生两个概念。 全同步复制 主库写入binlog后强制同步日志到从库，所有的从库都执行完成后才返回给客户端，但是很显然这个方式的话性能会受到严重影响。 半同步复制 和全同步不同的是，半同步复制的逻辑是这样，从库写入日志成功后返回ACK确认给主库，主库收到至少一个从库的确认就认为写操作完成。 缓存 缓存作为高性能的代表，在某些特殊业务可能承担90%以上的热点流量。对于一些活动比如秒杀这种并发QPS可能几十万的场景，引入缓存事先预热可以大幅降低对数据库的压力，10万的QPS对于单机的数据库来说可能就挂了，但是对于如redis这样的缓存来说就完全不是问题。 以秒杀系统举例，活动预热商品信息可以提前缓存提供查询服务，活动库存数据可以提前缓存，下单流程可以完全走缓存扣减，秒杀结束后再异步写入数据库，数据库承担的压力就小的太多了。当然，引入缓存之后就还要考虑缓存击穿、雪崩、热点一系列的问题了。 热key问题 所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key，那么这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机引发雪崩。 针对热key的解决方案： 提前把热key打散到不同的服务器，降低压力 加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询 缓存击穿 缓存击穿的概念就是单个key并发访问过高，过期时导致所有请求直接打到db上，这个和热key的问题比较类似，只是说的点在于过期导致请求全部打到DB上而已。 解决方案： 加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。 将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。 缓存穿透 缓存穿透是指查询不存在缓存中的数据，每次请求都会打到DB，就像缓存不存在一样。 针对这个问题，加一层布隆过滤器。布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的K个点，同时把他们置为1。 这样当用户再次来查询A，而A在布隆过滤器值为0，直接返回，就不会产生击穿请求打到DB了。 显然，使用布隆过滤器之后会有一个问题就是误判，因为它本身是一个数组，可能会有多个值落到同一个位置，那么理论上来说只要我们的数组长度够长，误判的概率就会越低，这种问题就根据实际情况来就好了。 缓存雪崩 当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上，这样可能导致整个系统的崩溃，称为雪崩。雪崩和击穿、热key的问题不太一样的是，他是指大规模的缓存都过期失效了。 针对雪崩几个解决方案： 针对不同key设置不同的过期时间，避免同时过期 限流，如果redis宕机，可以限流，避免同时刻大量请求打崩DB 二级缓存，同热key的方案。 稳定性 熔断 比如营销服务挂了或者接口大量超时的异常情况，不能影响下单的主链路，涉及到积分的扣减一些操作可以在事后做补救。 限流 对突发如大促秒杀类的高并发，如果一些接口不做限流处理，可能直接就把服务打挂了，针对每个接口的压测性能的评估做出合适的限流尤为重要。 降级 熔断之后实际上可以说就是降级的一种，以熔断的举例来说营销接口熔断之后降级方案就是短时间内不再调用营销的服务，等到营销恢复之后再调用。 预案 一般来说，就算是有统一配置中心，在业务的高峰期也是不允许做出任何的变更的，但是通过配置合理的预案可以在紧急的时候做一些修改。 核对 针对各种分布式系统产生的分布式事务一致性或者受到攻击导致的数据异常，非常需要核对平台来做最后的兜底的数据验证。比如下游支付系统和订单系统的金额做核对是否正确，如果收到中间人攻击落库的数据是否保证正确性。 总结 其实可以看到，怎么设计高并发系统这个问题本身他是不难的，无非是基于你知道的知识点，从物理硬件层面到软件的架构、代码层面的优化，使用什么中间件来不断提高系统的抗压能力。但是这个问题本身会带来更多的问题，微服务本身的拆分带来了分布式事务的问题，http、RPC框架的使用带来了通信效率、路由、容错的问题，MQ的引入带来了消息丢失、积压、事务消息、顺序消息的问题，缓存的引入又会带来一致性、雪崩、击穿的问题，数据库的读写分离、分库分表又会带来主从同步延迟、分布式ID、事务一致性的问题，而为了解决这些问题我们又要不断的加入各种措施熔断、限流、降级、离线核对、预案处理等等来防止和追溯这些问题。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/手写一个AQS.html":{"url":"notes/20.11/手写一个AQS.html","title":"手写一个AQS.md","keywords":"","body":"https://mp.weixin.qq.com/s/ders8qQEgSY8AZBOx7cqAwnew Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.11/计算机启动过程.html":{"url":"notes/20.11/计算机启动过程.html","title":"计算机启动过程.md","keywords":"","body":"https://mp.weixin.qq.com/s/i0PmP86iVv_-TlN8MLWIswnew Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/":{"url":"notes/20.12/","title":"20.12","keywords":"","body":" Java代理.md Redis csdn上分享的java一次oom的解决方案.md vimdiff.md 使用maven做Junit5单元测试.md 登录ssh不需要密码的方式.md 禁止Chrome通过两指轻划来切换页面.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Java代理.html":{"url":"notes/20.12/Java代理.html","title":"Java代理.md","keywords":"","body":" java代理 JDK动态代理 CGLib 区别 [TOC] java代理 JDK动态代理 CGLib 区别 CGLib创建代理的速度比较慢，但是创建代理后运行的速度却非常快，而JDK动态代理正好相反。如果在运行的时候不断地用CGLib去创建代理，系统的性能会大打折扣，所以建议一般在系统的初始化的时候用CGLib创建代理，并放入spring的ApplicationContext中以备后用。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/":{"url":"notes/20.12/Redis/","title":"Redis","keywords":"","body":" Redission.md Redis与MC的区别.md Redis主从哨兵cluster集群.md Redis分布式锁.md Redis分布式锁RedLock.md Redis缓存一致性.md Redis订阅发布.md redis异步复制丢失和脑裂问题.md 大key问题及解决方案.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/Redission.html":{"url":"notes/20.12/Redis/Redission.html","title":"Redission.md","keywords":"","body":"Redisson项目介绍 中文文档 Redisson是架设在Redis基础上的一个Java驻内存数据网格（In-Memory Data Grid）。充分的利用了Redis键值数据库提供的一系列优势，基于Java实用工具包中常用接口，为使用者提供了一系列具有分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度。同时结合各富特色的分布式服务，更进一步简化了分布式环境中程序相互之间的协作。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/Redis与MC的区别.html":{"url":"notes/20.12/Redis/Redis与MC的区别.html","title":"Redis与MC的区别.md","keywords":"","body":"之前只知道MC只能存储字符串，后来再一次组会上听几个大佬分享了关于他们用mc的一些实践，有了他们的精力我再来详细讨论一下Redis和mc的一些区别和选型上的一些问题。 他们两个都各有优缺点，我们做技术的，实现一个功能也肯定有很多个方法，具体选择哪一个要综合考虑他们两者的优缺点。技术有时候不能光看牛逼不牛逼，大部分时候还是要看业务场景适合不适合，系统稳定不稳定。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/Redis主从哨兵cluster集群.html":{"url":"notes/20.12/Redis/Redis主从哨兵cluster集群.html","title":"Redis主从哨兵cluster集群.md","keywords":"","body":" 主从模式 哨兵模式 集群模式 [TOC] Redis集群方式共有三种：主从模式，哨兵模式，cluster(集群)模式 主从模式 主从模式:是三种集群方式里最简单的。它主要是基于Redis的主从复制特性架构的。通常我们会设置一个主节点，N个从节点;默认情况下，主节点负责处理使用者的IO操作，而从节点则会对主节点的数据进行备份，并且也会对外提供读操作的处理。主要的特点如下： 主从模式下，当某一节点损坏时，因为其会将数据备份到其它Redis实例上，这样做在很大程度上可以恢复丢失的数据。 主从模式下，可以保证负载均衡，这里不再叙说了 主从模式下，主节点和从节点是读写分离的。使用者不仅可以从主节点上读取数据，还可以很方便的从从节点上读取到数据，这在一定程度上缓解了主机的压力。 从节点也是能够支持写入数据的，只不过从从节点写入的数据不会同步到主节点以及其它的从节点下。 从以上，我们不难看出Redis在主从模式下，必须保证主节点不会宕机——一旦主节点宕机，其它节点不会竞争称为主节点，此时，Redis将丧失写的能力。这点在生产环境中，是致命的。所以就有了哨兵模式。 哨兵模式 哨兵模式：是基于主从模式做的一定变化，它能够为Redis提供了高可用性。在实际生产中，服务器难免不会遇到一些突发状况：服务器宕机，停电，硬件损坏等。这些情况一旦发生，其后果往往是不可估量的。而哨兵模式在一定程度上能够帮我们规避掉这些意外导致的灾难性后果。其实，哨兵模式的核心还是主从复制。只不过相对于主从模式在主节点宕机导致不可写的情况下，多了一个竞选机制——从所有的从节点竞选出新的主节点。竞选机制的实现，是依赖于在系统中启动一个sentinel进程。 sentinel特点： 监控：它会监听主服务器和从服务器之间是否在正常工作。 通知：它能够通过API告诉系统管理员或者程序，集群中某个实例出了问题。 故障转移：它在主节点出了问题的情况下，会在所有的从节点中竞选出一个节点，并将其作为新的主节点。 提供主服务器地址：它还能够向使用者提供当前主节点的地址。这在故障转移后，使用者不用做任何修改就可以知道当前主节点地址。 sentinel，也可以集群，部署多个哨兵，sentinel可以通过发布与订阅来自动发现Redis集群上的其它sentinel。sentinel在发现其它sentinel进程后，会将其放入一个列表中，这个列表存储了所有已被发现的sentinel。 集群中的所有sentinel不会并发着去对同一个主节点进行故障转移。故障转移只会从第一个sentinel开始，当第一个故障转移失败后，才会尝试下一个。当选择一个从节点作为新的主节点后，故障转移即成功了(而不会等到所有的从节点配置了新的主节点后)。这过程中，如果重启了旧的主节点，那么就会出现无主节点的情况，这种情况下，只能重启集群。 当竞选出新的主节点后，被选为新的主节点的从节点的配置信息会被sentinel改写为旧的主节点的配置信息。完成改写后，再将新主节点的配置广播给所有的从节点。 集群模式 Redis集群（cluster） Redis 集群是一个提供在多个Redis间节点间共享数据的程序集。 Redis集群并不支持处理多个keys的命令,因为这需要在不同的节点间移动数据,从而达不到像Redis那样的性能,在高负载的情况下可能会导致不可预料的错误. Redis 集群通过分区来提供一定程度的可用性,在实际环境中当某个节点宕机或者不可达的情况下继续处理命令. Redis 集群的优势: 自动分割数据到不同的节点上。 整个集群的部分节点失败或者不可达的情况下能够继续处理命令。 Redis 集群的数据分片 Redis 集群没有使用一致性hash, 而是引入了 哈希槽的概念. Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽,举个例子,比如当前集群有3个节点,那么: 节点 A 包含 0 到 5500号哈希槽. 节点 B 包含5501 到 11000 号哈希槽. 节点 C 包含11001 到 16384号哈希槽. 这种结构很容易添加或者删除节点. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我想移除节点A,需要将A中的槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态. Redis 集群的主从复制模型 为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品. 在我们例子中具有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用. 然而如果在集群创建的时候（或者过一段时间）我们为每个节点添加一个从节点A1，B1，C1,那么整个集群便有三个master节点和三个slave节点组成，这样在节点B失败后，集群便会选举B1为新的主节点继续服务，整个集群便不会因为槽找不到而不可用了 不过当B和B1 都失败后，集群是不可用的. Redis 一致性保证 Redis 并不能保证数据的强一致性. 这意味这在实际中集群在特定的条件下可能会丢失写操作. 第一个原因是因为集群是用了异步复制. 写操作过程: 客户端向主节点B写入一条命令. 主节点B向客户端回复命令状态. 主节点将写操作复制给他得从节点 B1, B2 和 B3. 主节点对命令的复制工作发生在返回命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么主节点处理命令请求的速度将极大地降低 —— 我们必须在性能和一致性之间做出权衡。 注意：Redis 集群可能会在将来提供同步写的方法。 Redis 集群另外一种可能会丢失命令的情况是集群出现了网络分区， 并且一个客户端与至少包括一个主节点在内的少数实例被孤立。 举个例子 假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点， 其中 A 、B 、C 为主节点， A1 、B1 、C1 为A，B，C的从节点， 还有一个客户端 Z1 假设集群中发生网络分区，那么集群可能会分为两方，大部分的一方包含节点 A 、C 、A1 、B1 和 C1 ，小部分的一方则包含节点 B 和客户端 Z1 . Z1仍然能够向主节点B中写入, 如果网络分区发生时间较短,那么集群将会继续正常运作,如果分区的时间足够让大部分的一方将B1选举为新的master，那么Z1写入B中得数据便丢失了. 注意， 在网络分裂出现期间， 客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout）， 是 Redis 集群的一个重要的配置选项：new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/Redis分布式锁.html":{"url":"notes/20.12/Redis/Redis分布式锁.html","title":"Redis分布式锁.md","keywords":"","body":" redis 分布式锁 如果是用Redis打造分布式锁 超时问题 可重入性 集群情况 [TOC] redis 分布式锁 如果是用Redis打造分布式锁 一般情况下我们想到的是setnx ，抢占到一个’坑位‘之后，这个锁就抢占成功了，业务逻辑完成之后在del。但是这样存在一个问题。如果抢到锁之后出现异常了。锁来不及释放，就造成了死锁。 于是可以在拿到锁之后加一个过期时间，这样即使某个线程出现问题，也可以及时释放掉锁。 但是这样还是有问题，如果在setnx和expire之间服务器进程突然挂掉了或者服务器宕机了，就会导致expire得不到执行。 这种问题的根源是setnx和expire不是一个原子操作。redis的事务可以保证两个在一起操作，但是在这里不行，因为expire是依赖于setnx的结果的，如果没抢不到锁，expire就不应该执行。 为了解决这个问题，在Redis2.8版本加入了set指令的拓展参数。使得setnx和expire可以一起执行。 超时问题 Redis分布式锁不能解决超时问题，如果业务执行时间过长，超出了锁的超时时间，其他的业务就会获取到锁。 一个解决方案是获取锁时set一个随机数，删除时先判断是不是之前set的值，是的话再删除，但是判断和删除也不是一个原子操作。针对这个情况，Redis可以用Lua脚本来解决。但是使用lua也不能解决过期问题。所以Redis的分布式锁尽量用在业务时间不是很长的场景下，或者使用RedLock。 可重入性 可重入性指线程持有锁的情况下再次获取锁。 Redis获取可重入锁的方式是使用ThreadLocal，如果获取锁成功，则把当前锁的名称保存在ThreadLocal中的Map里，每获取一次就将锁引用计数加一。删除锁的时候则先看引用计数，然后再删除锁。 集群情况 Redis集群 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/Redis分布式锁RedLock.html":{"url":"notes/20.12/Redis/Redis分布式锁RedLock.html","title":"Redis分布式锁RedLock.md","keywords":"","body":" 一、问题 二、办法 三、原理 四、实战 1、引入maven 2、引入代码 3、核心源码 [TOC] 一、问题 分布式锁，当我们请求一个分布式锁的时候，成功了，但是这时候slave还没有复制我们的锁，masterDown了，我们的应用继续请求锁的时候，会从继任了master的原slave上申请，也会成功。 这就会导致，同一个锁被获取了不止一次。 二、办法 Redis中针对此种情况，引入了红锁的概念。 三、原理 用Redis中的多个master实例，来获取锁，只有大多数实例获取到了锁，才算是获取成功。具体的红锁算法分为以下五步： 获取当前的时间（单位是毫秒）。 使用相同的key和随机值在N个节点上请求锁。这里获取锁的尝试时间要远远小于锁的超时时间，防止某个masterDown了，我们还在不断的获取锁，而被阻塞过长的时间。 只有在大多数节点上获取到了锁，而且总的获取时间小于锁的超时时间的情况下，认为锁获取成功了。 如果锁获取成功了，锁的超时时间就是最初的锁超时时间减去获取锁的总耗时时间。 如果锁获取失败了，不管是因为获取成功的节点的数目没有过半，还是因为获取锁的耗时超过了锁的释放时间，都会将已经设置了key的master上的key删除。 四、实战 Redission就实现了红锁算法，使用的步骤如下： 1、引入maven org.redisson redisson 3.9.0 2、引入代码 Config config1 = new Config(); config1.useSingleServer().setAddress(\"redis://172.0.0.1:5378\").setPassword(\"a123456\").setDatabase(0); RedissonClient redissonClient1 = Redisson.create(config1); Config config2 = new Config(); config2.useSingleServer().setAddress(\"redis://172.0.0.1:5379\").setPassword(\"a123456\").setDatabase(0); RedissonClient redissonClient2 = Redisson.create(config2); Config config3 = new Config(); config3.useSingleServer().setAddress(\"redis://172.0.0.1:5380\").setPassword(\"a123456\").setDatabase(0); RedissonClient redissonClient3 = Redisson.create(config3); /** * 获取多个 RLock 对象 */ RLock lock1 = redissonClient1.getLock(lockKey); RLock lock2 = redissonClient2.getLock(lockKey); RLock lock3 = redissonClient3.getLock(lockKey); /** * 根据多个 RLock 对象构建 RedissonRedLock （最核心的差别就在这里） */ RedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3); try { /** * 4.尝试获取锁 * waitTimeout 尝试获取锁的最大等待时间，超过这个值，则认为获取锁失败 * leaseTime 锁的持有时间,超过这个时间锁会自动失效（值应设置为大于业务处理的时间，确保在锁有效期内业务能处理完） */ boolean res = redLock.tryLock((long)waitTimeout, (long)leaseTime, TimeUnit.SECONDS); if (res) { //成功获得锁，在这里处理业务 } } catch (Exception e) { throw new RuntimeException(\"aquire lock fail\"); }finally{ //无论如何, 最后都要解锁 redLock.unlock(); } 3、核心源码 public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException { long newLeaseTime = -1; if (leaseTime != -1) { newLeaseTime = unit.toMillis(waitTime)*2; } long time = System.currentTimeMillis(); long remainTime = -1; if (waitTime != -1) { remainTime = unit.toMillis(waitTime); } long lockWaitTime = calcLockWaitTime(remainTime); /** * 1. 允许加锁失败节点个数限制（N-(N/2+1)） */ int failedLocksLimit = failedLocksLimit(); /** * 2. 遍历所有节点通过EVAL命令执行lua加锁 */ List acquiredLocks = new ArrayList<>(locks.size()); for (ListIterator iterator = locks.listIterator(); iterator.hasNext();) { RLock lock = iterator.next(); boolean lockAcquired; /** * 3.对节点尝试加锁 */ try { if (waitTime == -1 && leaseTime == -1) { lockAcquired = lock.tryLock(); } else { long awaitTime = Math.min(lockWaitTime, remainTime); lockAcquired = lock.tryLock(awaitTime, newLeaseTime, TimeUnit.MILLISECONDS); } } catch (RedisResponseTimeoutException e) { // 如果抛出这类异常，为了防止加锁成功，但是响应失败，需要解锁所有节点 unlockInner(Arrays.asList(lock)); lockAcquired = false; } catch (Exception e) { // 抛出异常表示获取锁失败 lockAcquired = false; } if (lockAcquired) { /** *4. 如果获取到锁则添加到已获取锁集合中 */ acquiredLocks.add(lock); } else { /** * 5. 计算已经申请锁失败的节点是否已经到达 允许加锁失败节点个数限制 （N-(N/2+1)） * 如果已经到达， 就认定最终申请锁失败，则没有必要继续从后面的节点申请了 * 因为 Redlock 算法要求至少N/2+1 个节点都加锁成功，才算最终的锁申请成功 */ if (locks.size() - acquiredLocks.size() == failedLocksLimit()) { break; } if (failedLocksLimit == 0) { unlockInner(acquiredLocks); if (waitTime == -1 && leaseTime == -1) { return false; } failedLocksLimit = failedLocksLimit(); acquiredLocks.clear(); // reset iterator while (iterator.hasPrevious()) { iterator.previous(); } } else { failedLocksLimit--; } } /** * 6.计算 目前从各个节点获取锁已经消耗的总时间，如果已经等于最大等待时间，则认定最终申请锁失败，返回false */ if (remainTime != -1) { remainTime -= System.currentTimeMillis() - time; time = System.currentTimeMillis(); if (remainTime > futures = new ArrayList<>(acquiredLocks.size()); for (RLock rLock : acquiredLocks) { RFuture future = ((RedissonLock) rLock).expireAsync(unit.toMillis(leaseTime), TimeUnit.MILLISECONDS); futures.add(future); } for (RFuture rFuture : futures) { rFuture.syncUninterruptibly(); } } /** * 7.如果逻辑正常执行完则认为最终申请锁成功，返回true */ return true; } new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/Redis缓存一致性.html":{"url":"notes/20.12/Redis/Redis缓存一致性.html","title":"Redis缓存一致性.md","keywords":"","body":" 背景 读 写 各种写场景与db redis一致性 1.先更新redis再更新db 2.先更新db再更新redis 3.先更新DB再删除redis 4.先删除redis再更新DB 5.延迟双删 6.思考变种 总结 适用场景 背景 本文结合一些自己理解，讲解cache miss等情况下如何保证缓存和db的一致性，下面的例子中缓存以redis为例 读 先redis，redis没有就读db 写 有几种 1.先更新redis再更新db 2.先更新db再更新redis 3.先更新DB再删除redis 4.先删除redis再更新DB 5.延迟双删 6.延迟删除等变种 各种写场景与db redis一致性 1.先更新redis再更新db 按下面步骤会有问题,AB是两个线程 A_update_redis B_update_redis B_update_db A_update_db 最终db是a值但是redis是b值，不一致 2.先更新db再更新redis A_update_db B_update_db B_update_redis A_update_redis 最终db是b值但是redis是a值 3.先更新DB再删除redis A_update_db B_update_db B_rm_redis A_rm_redis 是不是不明白。想不出来怎么不一致了？ 不是这样的，没这么简单，第二次rm_redis就会保证后面的redis和db是一致的 实际是下面这种形式 A_get_data redis_cache_miss A_get_db B_update_db B_rm_redis (此时如果拿db是b值，但是redis没有值) A_update_redis 依赖于A_update_redis在B_update_db之后，极端情况 此时redis是old，db是new 4.先删除redis再更新DB A_rm_redis B_get_data B_redis_miss B_get_db B_update_redis A_update_db 此时redis是old值，db是new值 5.延迟双删 即 rm_redis update_db sleep xxx ms rm_redis 这样叫做双删，最后一次sleep一段时间再rm_redis保证再次读请求回溯打到db，用最新值写redis 6.思考变种 上面的3和5情况可以直接变种，即 update_db sleep xxx ms rm_redis 解决了3中的极端情况（靠sleep解决）， 并且减少5中第一次不必要的rm redis请求 当然，这个rm_redis还可以考虑异步化（提高吞吐）以及重试（避免异步处理失败），这里不展示 总结 从db回源到redis，需要考虑上面这些极端情况的case 适用场景 当然这些极端情况本身要求同一个key是多写的，这个根据业务需求来看是否需要，比如某些场景本身就是写少读多的 最终从网上看到的延迟双删变种为延迟删除redis也是一种优化new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/Redis订阅发布.html":{"url":"notes/20.12/Redis/Redis订阅发布.html","title":"Redis订阅发布.md","keywords":"","body":" Redis发布订阅 1. 发布消息 2. 订阅消息 3. 取消订阅 4. 按照模式订阅和取消订阅 5. 查询订阅 原理 SUBSCRIBE 命令的实现 PUBLISH 命令的实现 业务场景 [TOC] Redis提供了基于“发布/订阅”模式的消息机制，此种模式下，消息发布者和订阅者不进行直接通信，发布者客户端向指定的频道（channel）发布消息，订阅该频道的每个客户端都可以收到该消息，如图所示。Redis提供了若干命令支持该功能，在实际应用开发时，能够为此类问题提供实现方法。 Redis发布订阅 Redis主要提供了发布消息、订阅频道、取消订阅以及按照模式订阅和取消订阅等命令。 1. 发布消息 publish channel message 下面操作会向channel：sports频道发布一条消息“Tim won thechampionship”，返回结果为订阅者个数，因为此时没有订阅，所以返回结果为0： 127.0.0.1:6379> publish channel:sports \"Tim won the championship\" (integer) 0 2. 订阅消息 subscribe channel [channel ...] 订阅者可以订阅一个或多个频道，下面操作为当前客户端订阅了channel：sports频道： 127.0.0.1:6379> subscribe channel:sports Reading messages... (press Ctrl-C to quit) 1) \"subscribe\" 2) \"channel:sports\" 3) (integer) 1 此时另一个客户端发布一条消息： 127.0.0.1:6379> publish channel:sports \"James lost the championship\" (integer) 1 当前订阅者客户端会收到如下消息： 127.0.0.1:6379> subscribe channel:sports Reading messages... (press Ctrl-C to quit) ... 1) \"message\" 2) \"channel:sports\" 3) \"James lost the championship\" 有关订阅命令有两点需要注意： 客户端在执行订阅命令之后进入了订阅状态，只能接收subscribe、psubscribe、unsubscribe、punsubscribe的四个命令。 新开启的订阅客户端，无法收到该频道之前的消息，因为Redis不会对 发布的消息进行持久化。 和很多专业的消息队列系统（例如Kafka、RocketMQ）相比，Redis的发布订阅略显粗糙，例如无法实现消息堆积和回溯。但胜在足够简单，如果当前场景可以容忍的这些缺点，也不失为一个不错的选择。 3. 取消订阅 unsubscribe [channel [channel ...]] 客户端可以通过unsubscribe命令取消对指定频道的订阅，取消成功后，不会再收到该频道的发布消息： 127.0.0.1:6379> unsubscribe channel:sports 1) \"unsubscribe\" 2) \"channel:sports\" 3) (integer) 0 4. 按照模式订阅和取消订阅 psubscribe pattern [pattern...] punsubscribe [pattern [pattern ...]] 除了subcribe和unsubscribe命令，Redis命令还支持glob风格的订阅命令psubscribe和取消订阅命令punsubscribe，例如下面操作订阅以it开头的所有频道： 127.0.0.1:6379> psubscribe it* Reading messages... (press Ctrl-C to quit) 1) \"psubscribe\" 2) \"it*\" 3) (integer) 1 5. 查询订阅 1）查看活跃的频道 pubsub channels [pattern] 所谓活跃的频道是指当前频道至少有一个订阅者，其中[pattern]是可以指定具体的模式： 127.0.0.1:6379> pubsub channels 1) \"channel:sports\" 2) \"channel:it\" 3) \"channel:travel\" 127.0.0.1:6379> pubsub channels channel:*r* 1) \"channel:sports\" 2) \"channel:travel\" 2）查看频道订阅数 pubsub numsub [channel ...] 当前channel：sports频道的订阅数为2： 127.0.0.1:6379> pubsub numsub channel:sports 1) \"channel:sports\" 2) (integer) 2 3）查看模式订阅数 pubsub numpat 当前只有一个客户端通过模式来订阅： 127.0.0.1:6379> pubsub numpat (integer) 1 原理 Redis是使用C实现的，通过分析 Redis 源码里的 pubsub.c 文件，了解发布和订阅机制的底层实现，籍此加深对 Redis 的理解。 通过 SUBSCRIBE 命令订阅某频道后，redis-server 里维护了一个字典，字典的键就是一个个 channel ，而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。SUBSCRIBE 命令的关键，就是将客户端添加到给定 channel 的订阅链表中。 通过 PUBLISH 命令向订阅者发送消息，redis-server 会使用给定的频道作为键，在它所维护的 channel 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。 前面说到，Redis 将所有接受和发送信息的任务交给 channel 来进行，而所有 channel 的信息就储存在 redisServer 这个结构中： struct redisServer { // 省略 ... 　　 dict *pubsub_channels; // Map channels to list of subscribed clients 　　 // 省略 ... 　　 }; pubsub_channels 是一个字典，字典的键就是一个个 channel ，而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。 举个例子，如果在一个 redisServer 实例中，有一个叫做 news 的频道，这个频道同时被client_123 和 client_456 两个客户端订阅，那么这个 redisServer 结构看起来应该是这样子： 可以看出，实现 SUBSCRIBE 命令的关键，就是将客户端添加到给定 channel 的订阅链表中。 SUBSCRIBE 命令的实现 函数 pubsubSubscribeChannel 是 SUBSCRIBE 命令的底层实现，它完成了将客户端添加到订阅链表中的工作： // 订阅指定频道 // 订阅成功返回 1 ，如果已经订阅过，返回 0 int pubsubSubscribeChannel(redisClient *c, robj *channel) { struct dictEntry *de; list *clients = NULL; int retval = 0; /* Add the channel to the client -> channels hash table */ // dictAdd 在添加新元素成功时返回 DICT_OK // 因此这个判断句表示，如果新订阅 channel 成功，那么 。。。 if (dictAdd(c->pubsub_channels, channel, NULL) == DICT_OK) { retval = 1; incrRefCount(channel); /* Add the client to the channel -> list of clients hash table */ // 将 client 添加到订阅给定 channel 的链表中 // 这个链表是一个哈希表的值，哈希表的键是给定 channel // 这个哈希表保存在 server.pubsub_channels 里 de = dictFind(server.pubsub_channels, channel); if (de == NULL) { // 如果 de 等于 NULL // 表示这个客户端是首个订阅这个 channel 的客户端 // 那么创建一个新的列表， 并将它加入到哈希表中 clients = listCreate(); dictAdd(server.pubsub_channels, channel, clients); incrRefCount(channel); } else { // 如果 de 不为空，就取出这个 clients 链表 clients = dictGetVal(de); } // 将客户端加入到链表中 listAddNodeTail(clients, c); } /* Notify the client */ addReply(c, shared.mbulkhdr[3]); addReply(c, shared.subscribebulk); // 返回订阅的频道 addReplyBulk(c, channel); // 返回客户端当前已订阅的频道和模式数量的总和 addReplyLongLong(c, dictSize(c->pubsub_channels) + listLength(c->pubsub_patterns)); return retval; } PUBLISH 命令的实现 使用 PUBLISH 命令向订阅者发送消息，需要执行以下两个步骤： 1) 使用给定的频道作为键，在 redisServer.pubsub_channels 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。 2) 遍历 redisServer.pubsub_patterns 链表，将链表中的模式和给定的频道进行匹配，如果匹配成功，那么将消息发布到相应模式的客户端当中。 举个例子，假设有两个客户端分别订阅 it.news 频道和 it. 模式，当执行命令PUBLISH it.news \"hello moto\" 的时候， it.news 频道的订阅者会在步骤 1 收到信息，而当PUBLISH 进行到步骤 2 的时候， it. 模式的订阅者也会收到信息。 PUBLISH 命令的实际实现由 pubsubPublishMessage 函数完成，它的完整定义如下： // 发送消息 int pubsubPublishMessage(robj *channel, robj *message) { int receivers = 0; struct dictEntry *de; listNode *ln; listIter li; /* Send to clients listening for that channel */ // 向所有频道的订阅者发送消息 de = dictFind(server.pubsub_channels, channel); if (de) { list *list = dictGetVal(de); // 取出所有订阅者 listNode *ln; listIter li; // 遍历所有订阅者， 向它们发送消息 listRewind(list, &li); while ((ln = listNext(&li)) != NULL) { redisClient *c = ln->value; addReply(c, shared.mbulkhdr[3]); addReply(c, shared.messagebulk); addReplyBulk(c, channel); // 打印频道名 addReplyBulk(c, message); // 打印消息 receivers++; // 更新接收者数量 } } /* Send to clients listening to matching channels */ // 向所有被匹配模式的订阅者发送消息 if (listLength(server.pubsub_patterns)) { listRewind(server.pubsub_patterns, &li); // 取出所有模式 channel = getDecodedObject(channel); while ((ln = listNext(&li)) != NULL) { pubsubPattern *pat = ln->value; // 取出模式 // 如果模式和 channel 匹配的话 // 向这个模式的订阅者发送消息 if (stringmatchlen((char *) pat->pattern->ptr, sdslen(pat->pattern->ptr), (char *) channel->ptr, sdslen(channel->ptr), 0)) { addReply(pat->client, shared.mbulkhdr[4]); addReply(pat->client, shared.pmessagebulk); addReplyBulk(pat->client, pat->pattern); // 打印被匹配的模式 addReplyBulk(pat->client, channel); // 打印频道名 addReplyBulk(pat->client, message); // 打印消息 receivers++; // 更新接收者数量 } } decrRefCount(channel); // 释放用过的 channel } return receivers; // 返回接收者数量 } 业务场景 明确了Redis发布订阅的原理和基本流程后，我们来看一下Redis的发布订阅到底具体能做什么。 1、异步消息通知 比如渠道在调支付平台的时候，我们可以用回调的方式给支付平台一个我们的回调接口来通知我们支付状态，还可以利用Redis的发布订阅来实现。比如我们发起支付的同时订阅频道pay_notice_ + wk (假如我们的渠道标识是wk，不能让其他渠道也订阅这个频道)，当支付平台处理完成后，支付平台往该频道发布消息，告诉频道的订阅者该订单的支付信息及状态。收到消息后，根据消息内容更新订单信息及后续操作。 当很多人都调用支付平台时，支付时都去订阅同一个频道会有问题。比如用户A支付完订阅频道pay_notice_wk，在支付平台未处理完时，用户B支付完也订阅了pay_notice_wk，当A收到通知后，接着B的支付通知也发布了，这时渠道收不到第二次消息发布。因为同一个频道收到消息后，订阅自动取消，也就是订阅是一次性的。 所以我们订阅的订单支付状态的频道就得唯一，一个订单一个频道，我们可以在频道上加上订单号pay_notice_wk+orderNo保证频道唯一。这样我们可以把频道号在支付时当做参数一并传过去，支付平台处理完就可以用此频道发布消息给我们了。（实际大多接口用回调通知，因为用Redis发布订阅限制条件苛刻，系统间必须共用一套Redis） 2、任务通知 比如通过跑批系统通知应用系统做一些事（跑批系统无法拿到用户数据，且应用系统又不能做定时任务的情况下）。如每天凌晨3点提前加载一些用户的用户数据到Redis，应用系统不能做定时任务，可以通过系统公共的Redis来由跑批系统发布任务给应用系统，应用系统收到指令，去做相应的操作。 这里需要注意的是在线上集群部署的情况下，所有服务实例都会收到通知，都要做同样的操作吗？完全没必要。可以用Redis实现锁机制，其中一台实例拿到锁后执行任务。另外如果任务比较耗时，可以不用锁，可以考虑一下任务分片执行。当然这不在本文的讨论范畴，这里不在赘述。 3、参数刷新加载 众所周知，我们用Redis无非就是将系统中不怎么变的、查询又比较频繁的数据缓存起来，例如我们系统首页的轮播图啊，页面的动态链接啊，一些系统参数啊，公共数据啊都加载到Redis，然后有个后台管理系统去配置修改这些数据。 打个比方我们首页的轮播图要再增加一个图，那我们就在后管系统加上，加上就完事了吗？当然没有，因为Redis里还是老数据。那你会说不是有过期时间吗？是的，但有的过期时间设置的较长如24小时并且我们想立即生效怎么办？这时候我们就可以利用Redis的发布订阅机制来实现数据的实时刷新。当我们修改完数据后，点击刷新按钮，通过发布订阅机制，订阅者接收到消息后调用重新加载的方法即可。（有点没看懂这个说的，还有这个有没有其他的方案？） 参考： https://www.jianshu.com/p/58dcc12e84f9 https://www.cnblogs.com/duanxz/p/6053520.htmlnew Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/redis异步复制丢失和脑裂问题.html":{"url":"notes/20.12/Redis/redis异步复制丢失和脑裂问题.html","title":"redis异步复制丢失和脑裂问题.md","keywords":"","body":" 异步复制丢失 redis主从模式脑裂问题 解决方案 [toc] 异步复制丢失 对于Redis主节点与从节点之间的数据复制，是异步复制的，当客户端发送写请求给master节点的时候，客户端会返回OK，然后同步到各个slave节点中。 如果此时master还没来得及同步给slave节点时发生宕机，那么master内存中的数据会丢失； 要是master中开启持久化设置数据可不可以保证不丢失呢？答案是否定的。在master 发生宕机后，sentinel集群检测到master发生故障，重新选举新的master，如果旧的master在故障恢复后重启，那么此时它需要同步新master的数据，此时新的master的数据是空的（假设这段时间中没有数据写入）。那么旧master中的数据就会被刷新掉，此时数据还是会丢失。 redis主从模式脑裂问题 redis的集群脑裂是指因为网络问题，导致redis master节点跟redis slave节点和sentinel集群处于不同的网络分区，此时因为sentinel集群无法感知到master的存在，所以将slave节点提升为master节点。此时存在两个不同的master节点，就像一个大脑分裂成了两个。 集群脑裂问题中，如果客户端还在基于原来的master节点继续写入数据，那么新的master节点将无法同步这些数据，当网络问题解决之后，sentinel集群将原先的master节点降为slave节点，此时再从新的master中同步数据，将会造成大量的数据丢失。 解决方案 在了解了上面的两种数据丢失场景后，我们如何保证数据可以不丢失呢？在分布式系统中，衡量一个系统的可用性，我们一般情况下会说4个9,5个9的系统达到了高可用（99.99%，99.999%，据说淘宝是5个9）。对于redis集群，我们不可能保证数据完全不丢失，只能做到使得尽量少的数据丢失。 min-replicas-to-write 3 min-replicas-max-lag 10 第一个参数表示连接到master的最少slave数量 第二个参数表示slave连接到master的最大延迟时间 按照上面的配置，要求至少3个slave节点，且数据复制和同步的延迟不能超过10秒，否则的话master就会拒绝写请求，配置了这两个参数之后，如果发生集群脑裂，原先的master节点接收到客户端的写入请求会拒绝，就可以减少数据同步之后的数据丢失。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/Redis/大key问题及解决方案.html":{"url":"notes/20.12/Redis/大key问题及解决方案.html","title":"大key问题及解决方案.md","keywords":"","body":" Redis大key问题 what 什么是大key问题 单key大小 key的数量 why: 为啥不能有大key How: 如何避免大key 安全删除大key 找到大key、删除大Key 当版本 删除大Key: 当版本>=4.0 寻找大key 删除大key： lazyfree机制 [TOC] Redis大key问题 为啥不能有大key; 有一些方法，避免大key 有大key，安全删除大key what 什么是大key问题 就是一个key的value特别大，比如一个hashmap中存了超多k,v; 或者一个列表key中存了超长列表，等等； 多大算大： hashmap中有100w的k,v => 1s延迟； 删除大Key的时间复杂度: O(N), N代表大key里的值数量，因为redis是单线程一个个删。 所以删大key也会卡qps。 单key大小 Redis限制每个String类型value大小不超过512MB， 实际开发中，不要超过10KB，否则会对CPU和网卡造成极大负载。 hash、list、set、zset元素个数不要超过5000。 理论上限: 每个hashset里头元素数量 key的数量 官方评测： 单实例2.5亿 理论上限: 32位，2^32。约40亿 why: 为啥不能有大key redis的基础假设是每个操作都很快，所以设计成单线程处理； 所以如果有大key，基础设计就不成立了，会阻塞； 问题： 数据倾斜，部分redis分片节点存储占用很高； 查询突然很慢，qps降低； How: 如何避免大key 分治法，加一些key前缀\\后置分解（如时间、哈希前缀、用户id后缀）; 安全删除大key 首先要找到大key才能删除; 如何删除； 找到大key、删除大Key 当版本 1、导出rdb文件分析: bgsave, redis-rdb-tool; 2、命令: redis-cli --bigkeys,找出最大的key； 3、自己写脚本扫描; 4、单个key查看: debug object key： 查看某个key序列化后的长度，每次看1个key的信息,比较没效率。 删除大Key: 分解删除操作： list: 逐步ltrim; zset: 逐步zremrangebyscore; hset: hscan出500个，然后hdel删除； set: sscan扫描出500个，然后srem删除； 依次类推； 当版本>=4.0 寻找大key 命令: memory usage 删除大key： lazyfree机制 unlink命令：代替DEL命令； 会把对应的大key放到BIO_LAZY_FREE后台线程任务队列，然后在后台异步删除； 类似的异步删除命令: flushdb async: 异步清空数据库 flushall async: 异步清空所有数据库 异步删除配置: ``` slave-lazy-flush: slave接受完rdb文件后，异步清空数据库； lazyfree-lazy-eviction: 异步淘汰key; lazyfree-lazy-expire: 异步key过期; lazyfree-lazy-server-del: 异步内部删除key；生效于rename命令 rename命令: RENAME mykey new_name 如果new_name已经存在，会先删除new_name，此时触发上述lazy机制 ```new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/csdn上分享的java一次oom的解决方案.html":{"url":"notes/20.12/csdn上分享的java一次oom的解决方案.html","title":"csdn上分享的java一次oom的解决方案.md","keywords":"","body":"https://zhanghan.blog.csdn.net/article/details/109255980new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/vimdiff.html":{"url":"notes/20.12/vimdiff.html","title":"vimdiff.md","keywords":"","body":"# vimdiff FILE_LEFT FILE_RIGHT # vimdiff -d FILE_LEFT FILE_RIGHT //左右竖屏 # vimdiff -o FILE_LEFT FILE_RIGHT //上下横屏 https://www.jianshu.com/p/0541a67c6d3f 链接里还有很多操作，不过简单的对比两个文件的区别还是够用了。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/使用maven做Junit5单元测试.html":{"url":"notes/20.12/使用maven做Junit5单元测试.html","title":"使用maven做Junit5单元测试.md","keywords":"","body":"https://www.jianshu.com/p/ffa6cd004b37 http://ifeve.com/%E4%B8%80%E6%96%87%E8%AE%A9%E4%BD%A0%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-mockito-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/ https://www.jianshu.com/p/2594dcbd3272 maven的命令，又可以整理一下了 https://blog.csdn.net/qq_35893120/article/details/70207535 https://blog.csdn.net/hhb200766/article/details/79789822new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/登录ssh不需要密码的方式.html":{"url":"notes/20.12/登录ssh不需要密码的方式.html","title":"登录ssh不需要密码的方式.md","keywords":"","body":" step1生成公私钥： step2复制公钥： 方法1： 方法2： step3修改权限： step4免密登录： 小结 解决多个ssh public key的问题 [TOC] 机器A 向 机器B 进行免密码登陆 step1生成公私钥： 在机器A中生成 私钥和公钥： ssh-keygen -t rsa 此时在 ~/.ssh/ 目录下生成了公钥（id_rsa.pub）和私钥(id_rsa) step2复制公钥： 把机器A的公钥（id_rsa.pub）复制到机器B ~/.ssh/authorized_keys 文件里，两种常用方法 方法1： scp ~/.ssh/id_rsa.pub username@host:/home/B/id_rsa.pub //此时scp需要输入 登录机器B username用户的密码 //然后进入机器B内把 /home/B/id_rsa.pub 文件内容加写进 ~/.ssh/authorized_keys 文件： cat /home/B/id_rsa.pub /home/B/.ssh/authorized_keys 方法2： //在机器A中使用 ssh-copy-id 把公钥加写到机器B的 ~/.ssh/authorized_keys 文件 ssh-copy-id username@host //执行后输入机器B username用户的密码，效果和方法1一样 step3修改权限： 修改机器B ~/.ssh/authorized_keys 文件的权限： chmod 600 ~/.ssh/authorized_keys 此时如果机器B没有~/.ssh 目录需要手动创建 step4免密登录： 此时机器A可以进行免验证登录 机器B ssh username@host 小结 登录的机子要有私钥，被登录的机子要有登录机子的公钥。这个公钥/私钥对一般在私钥宿主机产生。上面是用rsa算法的公钥/私钥对，当然也可以用dsa(对应的文件是id_dsa，id_dsa.pub)想让A，B机无密码互登录，那B机以上面同样的方式配置即可。 SSH 为建立在应用层和传输层基础上的安全协议。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用SSH 协议可以有效防止远程管理过程中的信息泄露问题。 从客户端来看，SSH提供两种级别的安全验证： 1、基于口令的验证 只要知道帐号和口令，就可以登录到远程主机。所有传输的数据都会被加密，但缺点是：不能保证你正在连接的服务器就是你想连接的服务器。以下是我画了的登录验证流程： https://images0.cnblogs.com/blog/44804/201311/30203632-05af7f8077664bb6b3969a3f487a3743.png 当第一次链接远程主机时，会提示您当前主机的”公钥指纹”，询问您是否继续，如果选择继续后就可以输入密码进行登录了，当远程的主机接受以后，该台服务器的公钥就会保存到~/.ssh/known_hosts文件中。 2、基于密钥的验证 这种验证的前提是客户端需要生成一对密钥，将公钥放到需访问的远程服务器。这种验证比上一种的好处是，不能仿冒真正的服务器，因为要仿冒必须拿到客户端生成的公钥。缺点就是验证等待过程稍长些。 https://images0.cnblogs.com/blog/44804/201311/30204001-0f1deb20772042c3823b8527c147b074.png https://img-blog.csdn.net/20160319193556260 1.在A上生成公钥私钥。 2.将公钥拷贝给server B，要重命名成authorized_keys(从英文名就知道含义了) 3.Server A向Server B发送一个连接请求。 4.Server B得到Server A的信息后，在authorized_key中查找，如果有相应的用户名和IP，则随机生成一个字符串，并用Server A的公钥加密，发送给Server A。 5.Server A得到Server B发来的消息后，使用私钥进行解密，然后将解密后的字符串发送给Server B。Server B进行和生成的对比，如果一致，则允许免登录。 总之：A要免密码登录到B，B首先要拥有A的公钥，然后B要做一次加密验证。对于非对称加密，公钥加密的密文不能公钥解开，只能私钥解开。 解决多个ssh public key的问题 # 第一步 ssh-keygen -t rsa -C \"dongzhonghua03@kuaishou.com\" -f ~/.ssh/id_rsa_dongzhonghua03 # 第二步 添加公钥到gitlab # 第三步 添加密钥到ssh-agent中 eval $(ssh-agent) # exec ssh-agent bash ssh-add ~/.ssh/id_rsa_dongzhonghua03 ssh-add ~/.ssh/id_rsa # 第四步添加config配置文件分别映射不同的GitHub和码云的账户下 # 进入~/.ssh目录，新建config文件，并添加下面的内容 # 个人的GitHub公钥 Host github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_github # 指定特定的ssh私钥文件 # 公司的's gitee.com Host gitee.com HostName gitee.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa # 指定特定的ssh私钥文件 # 第五步 检查配置是否成功执行下面命令 ssh -T git@github.com new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/20.12/禁止Chrome通过两指轻划来切换页面.html":{"url":"notes/20.12/禁止Chrome通过两指轻划来切换页面.html","title":"禁止Chrome通过两指轻划来切换页面.md","keywords":"","body":"可以禁止触控板的两指清扫，但是其他的应用需要这个功能。 命令行运行这个： defaults write com.google.Chrome AppleEnableSwipeNavigateWithScrolls -bool false 网上说这个，但是mac的没有这个参数： chrome://flags/#overscroll-history-navigation new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/21.01/":{"url":"notes/21.01/","title":"21.01","keywords":"","body":" Java中为什么基本类型要有包装类型.md Nagle算法.md maven打包特别慢的解决方案.md 函数式接口.md 委派模式(Delegate).md.md) 定时器.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/21.01/Java中为什么基本类型要有包装类型.html":{"url":"notes/21.01/Java中为什么基本类型要有包装类型.html","title":"Java中为什么基本类型要有包装类型.md","keywords":"","body":"问为什么要有有时候不好回答，那就回答如果没有会怎么样呢？ 我们知道Java是一个面向对象的语言，而且所有的类都是继承自Object。而显然如int, boolean类型不是一个Object所以就造成了很多情况下传参或者包装类型使用起来非常的困难。所以Java里有了基本类型并且有自动装箱拆箱的功能。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/21.01/Nagle算法.html":{"url":"notes/21.01/Nagle算法.html","title":"Nagle算法.md","keywords":"","body":"Small Packet Problem 在使用一些协议通讯的时候，比如Telnet，会有一个字节字节的发送的情景，每次发送一个字节的有用数据，就会产生41个字节长的分组，20个字节的IP Header 和 20个字节的TCP Header，这就导致了1个字节的有用信息要浪费掉40个字节的头部信息，这是一笔巨大的字节开销，而且这种Small packet在广域网上会增加拥塞的出现。 如果解决这种问题？ Nagle就提出了一种通过减少需要通过网络发送包的数量来提高TCP/IP传输的效率，这就是Nagle算法 “只有收到前一数据的ACK消息时，Nagle算法才发送下一数据” https://img-blog.csdnimg.cn/20190402084354218.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNzMyMzUw,size_16,color_FFFFFF,t_70 TCP套接字默认使用Nagle算法交换数据，因此最大限度地进行缓冲，直到收到ACK。图左侧正是这种情况。为了发送字符串\"Nagle\", 将其传递到输出缓冲。这时头字符\"N\" 之前没有其他数据（没有需接收的ACK ), 因此立即传输。之后开始等待字符\"N\" 的ACK消息，等待 过程中，剩下的\"agle\" 填入输出缓冲。接下来，收到字符\"N\" 的ACK消息后，将输出缓冲的\"agle\" 装入一个数据包发送。也就是说，共需传递4个数据包以传输l 个字符串。 接下来分析未使用Nagl~算法时发送字符串\"Nagle\" 的过程。假设字符\"N\" 到\"e\" 依序传到输出缓冲。此时的发送过程与AC幻妾收与否无关，因此数据到达输出缓冲后将立即被发送出去。从图右侧可以看到，发送字符串\"Nagle\" 时共需10个数据包。由此可知，不使用Na.gl~算法将对网络流量(Traffic: 指网络负载或混杂程度）产生负面影响。即使只传输1 个字节的数据，其头信息都有可能是几十个字节。因此，为了提高网络传输效率，必须使用Naglej算法 缺点： 但Nagle算法并不是什么时候都适用。根据传输数据的特性，网络流最未受太大影响时，不使用Nagle算法要比使用它时传输速度快。 最典型的是传输大文件时，由于把数据输入到缓冲区的速度快，但是把缓冲区输出到网络上就慢，如果还要等待ACK的话，那就更慢，所以我们希望缓冲区的数据尽快发送出去，后面的数据才更好的输入到缓存区中。在这种情况下不使用Nagle算法不仅不会增加数据包的数撮， 反而会在无需等待ACK的前提下连续传输， 因此可以大大提高传输速度。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/21.01/maven打包特别慢的解决方案.html":{"url":"notes/21.01/maven打包特别慢的解决方案.html","title":"maven打包特别慢的解决方案.md","keywords":"","body":" 加命令 减依赖 加命令 https://ningyu1.github.io/site/post/93-maven-depenpency-analyze/ mvn -DincludeScope=runtime \\ clean package dependency:copy-dependencies \\ -Dcheckstyle.skip=true -U -Dmaven.compile.fork=true -Dmaven.test.skip=true \\ -Denforcer.skip=true || exit 1 减依赖 分析没有用到的依赖 mvn dependency:analyze -DignoreNonCompile new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/21.01/函数式接口.html":{"url":"notes/21.01/函数式接口.html","title":"函数式接口.md","keywords":"","body":" 函数式接口 @FunctionalInterface 常用函数式接口 Consumer：消费型接口 Supplier: 供给型接口 Function: 函数型接口 Predicate ： 断言型接口 [TOC] 函数式接口 函数式接口的本质是什么？ 函数式接口传递的是行为（函数定义了一个行为） @FunctionalInterface 有唯一一个抽象方法，也可以包含static和default的方法实现，像这样的接口就是具有functional的接口 可以把一个函数定义赋值给一个抽象函数接口。然后把这个函数接口类型作为参数传递到函数里面。在函数里面调用这个参数函数则使用接口中的方法。接口中的方法的参数则是这个参数函数的参数。 // 看到函数式接口第一反应是什么？ // 函数式接口引用的是一个函数。 // 他是一个函数，函数就涉及到调用和传参。调用这个函数就是用接口中的抽象方法，传参就是抽象函数中的参数， @FunctionalInterface public interface MyFunction { void call(T t); } 常用函数式接口 Consumer：消费型接口 抽象方法： void accept(T t)，接收一个参数进行消费，但无需返回结果。 使用方式： Consumer consumer = System.out::println; consumer.accept(\"hello function\"); 默认方法： andThen(Consumer after)，先消费然后在消费，先执行调用andThen接口的accept方法，然后在执行andThen方法参数after中的accept方法。 使用方式： // 这个例子就比较有意思 Consumer consumer1 = s -> System.out.print(\"车名：\"+s.split(\",\")[0]); Consumer consumer2 = s -> System.out.println(\"-->颜色：\"+s.split(\",\")[1]); String[] strings = {\"保时捷,白色\", \"法拉利,红色\"}; for (String string : strings) { consumer1.andThen(consumer2).accept(string); } 输出： 车名：保时捷-->颜色：白色 车名：法拉利-->颜色：红色 Supplier: 供给型接口 抽象方法：T get()，无参数，有返回值。 这类接口是和提供数据的场景。 Function: 函数型接口 抽象方法： R apply(T t)，传入一个参数，有返回值。 Predicate ： 断言型接口 抽象方法： boolean test(T t),传入一个参数，返回一个布尔值。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/21.01/定时器.html":{"url":"notes/21.01/定时器.html","title":"定时器.md","keywords":"","body":" Timer Timer TimserTask TaskQueue TimerThread [TOC] Timer 我觉得这个是一个写的非常好的组件，一个是他相对独立，把源码直接拿出来也可以运行，没有依赖其他的东西，易于理解，看完之后甚至可以自己写一个。二是这个工具有浓浓的JDK的味道。不知道怎么地，看这个我就发现，后续的很多JDK源码其实和这个是很像的，有渊源的，有时间多看看像这种的小源码是非常快乐的事情。 Timer timer两个重要的属性，queue是一个优先队列，他与TimerThread共享该队列。 private final TaskQueue queue = new TaskQueue(); private final TimerThread thread = new TimerThread(queue); Timer负责启动TimerThread，timerThread会启动一个mainloop来循环。 public Timer(String name) { thread.setName(name); thread.start(); } Timer添加任务使用schedule() public void schedule(TimerTask task, long delay, long period) { if (delay //安排指定的计时器任务在指定的时间以指定的时间（以毫秒为单位）执行。 //如果period为正，则计划任务重复执行；如果period为零，则将任务安排为一次性执行。 private void sched(TimerTask task, long time, long period) { if (time (Long.MAX_VALUE >> 1)) { period >>= 1; } // 锁定queue,任务入队 synchronized (queue) { if (!thread.newTasksMayBeScheduled) { throw new IllegalStateException(\"Timer already cancelled.\"); } synchronized (task.lock) { // 什么情况下会出现这种情况？这种情况下，任务两次提交 // timer.schedule(task, 0, 1000); // timer.schedule(task, 0, 1000); if (task.state != TimerTask.VIRGIN) { throw new IllegalStateException( \"Task already scheduled or cancelled\"); } task.nextExecutionTime = time; // period这个变量在哪里用到了？ task.period = period; task.state = TimerTask.SCHEDULED; } queue.add(task); // 这里有点不太明白，为什么如果这种情况下就要通知? if (queue.getMin() == task) { queue.notify(); } } } TimserTask public abstract class TimerTask extends TaskQueue implements Runnable 使用的时候只需要new一个TimerTask传入Timer（） 但是为什么会继承TaskQueue有点看不懂。 TaskQueue TaskQueue是一个优先队列，存放的是TimerTask。队列下标为1的是存放在最近需要执行的任务。 最重要的属性是queue。 private TimerTask[] queue = new TimerTask[128]; fixUp原理就是新加入的元素在队尾会不断与已有顺序的数组元素不断比较，不断向前找到自己的位置，堆顶的元素就是最早执行的 TimerThread timerThread继承Thread，在new Timer()的时候会启动。保存着任务队列。 可以看到他刚启动的时候就会调用mainLoop() public void run() { try { mainLoop(); } finally { // Someone killed this Thread, behave as if Timer cancelled synchronized (queue) { newTasksMayBeScheduled = false; queue.clear(); // Eliminate obsolete references } } } mainloop的任务执行是阻塞的，就是说执行顺序是ABC，如果A执行时间太长了，会影响后面的任务执行，所以在代码里面我改动了一下，可以吧task.run()交给线程池来做。这个是一个可以优化的点。但是其实jdk1.5已经给出了替代timer的更好地方案ScheduledThreadPoolExecutor。 ```Java private void mainLoop() { while (true) { try { TimerTask task; boolean taskFired; synchronized (queue) { // Wait for queue to become non-empty while (queue.isEmpty() && newTasksMayBeScheduled) { queue.wait(); } if (queue.isEmpty()) { break; // Queue is empty and will forever remain; die } // Queue nonempty; look at first evt(event?) and do the right thing long currentTime, executionTime; task = queue.getMin(); synchronized (task.lock) { if (task.state == TimerTask.CANCELLED) { queue.removeMin(); continue; // No action required, poll queue again } currentTime = System.currentTimeMillis(); // nextExecutionTime在提交任务时赋的值 executionTime = task.nextExecutionTime; if (taskFired = (executionTime } ```new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/21.02/":{"url":"notes/21.02/","title":"21.02","keywords":"","body":" 拍卖的相关概念.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/21.02/拍卖的相关概念.html":{"url":"notes/21.02/拍卖的相关概念.html","title":"拍卖的相关概念.md","keywords":"","body":"一、简单的拍卖 单项拍卖（Single-Item Auctions），一个卖方，一个物品， 个买方（bidder，也可以叫投标人），针对第 个买方，下面是几个参数。 估价（valuation，这个词怎么翻译没查到，我暂定为估价） ：对于卖品的最大支付意愿（maximum willingness-to-pay），其实也就是对真实价值的计算，一般买房不会花超过这个数值的钱去购买，我们这里假定 是私密（private）的，其他人不知道。 效用（utility） ：这里效用模型被叫拟线性效用模型（quasilinear utility model），是买方的实际效用。如果买方在拍卖中输了，什么也没得到，效用显然是 ；如果他赢了，支付了 ，那么 。 密封拍卖（Sealed-Bid Auctions），每个买方私密地向卖方提供报价 ，然后卖方选择谁获得该物品（可以是某个人，也可以谁也不给），最后决定支付价格 。一般都是出价最高的那个人获得商品，实际上一般也没其他选择，这个叫配置策略，而决定价格可以叫定价策略。 定价策略比较复杂，你要是大公无私可以成本价给出去，但我们一般是考虑卖方最大化收益的。所以接下来是几种模式。 第一价格拍卖（First-Price Auctions），每个人给一个价（不能反悔，没有改的机会），然后出价最高的那个人获得，并支付他报的价。但问题有两点：1.不好计算你该出多少价最好，机制设计者也不好计算预期收益；2.按照真实估价去报的话，效用永远为0，所以大家要有所隐瞒。 注意，一价拍卖不是先行的拍卖会，后者是可以不断加价的，前者不可以。 二、第二价格拍卖 第二价格拍卖（Second-Price Auctions），这个就简单多了，eBay就用这招，叫代理投标人（proxy bidder），还是出价最高的那个人获得，但他支付的钱是，第二高的人的报价，加上一个微小的类似手续费的东西。看起来这减少了收入，但实际上没有，比一价拍卖好。 优势策略（Dominant Strategy）：参与博弈的人选择这种策略，可以让效用最大化。 那么二价拍卖的优势策略就是， ，且这样一来 都不会变成负数。证明如下： 出价最高， ， 始终是第二高的人的出价，跟自己一毛钱关系没有，那么 与 显然无关。 出价不是最高，即 。倘若 ，那么不诚实的出价策略会导致 从正数变成 ；倘若 ，那么什么出价策略都是 。 最后讨论 ，效用为负，更糟糕。 证毕。 第二价格拍卖也叫维克瑞拍卖（Vickery Auctions），由维克瑞发明，第一章里提到过他拿了诺奖，一个原因就是二价拍卖，而另一个VCG机制就比较复杂了，这里先不表。 三、好的拍卖的标准 好的拍卖有三条标准。 1.优势策略激励相容（dominant-strategy incentive-compatible，简称DSIC），每个人都有一个优势策略，而且这个机制允许并激励他们一起采用优势策略。同时，DSIC保证真实报价（truthful bidding）是优势策略，从机制设计者角度来说，这样容易预测买方的行动，因为每一个理性+智能的博弈者都会采用这一策略。二价拍卖符合这一条，很容易看出来。 2.最大社会盈余（maximize social surplus），即 ，当然前提是每个人都如实报价，这条性质才能体现出来。这里 在单一商品二价拍卖里取 或 ，它的意思是配置，谁获得了这件物品。如果没有这条性质会发生什么？比如随机把一件商品免费送人也是DSIC的，但这样太扯淡了，所以需要这条性质来约束一下。二价拍卖是符合的。 3.多项式计算时间（computed in polynomial time），这条是计算机领域要求的，否则算不下去。二价拍卖是线性的，属于非常好的场景。 这三条性质对二价拍卖来说意义何在，我们只讨论前两条。这意味着：即使不知道大家的真实估价，卖方/机制设计者也是可以知道哪个人的真实估价最高。而且，如果他们知道了每个人的具体估价，那么社会盈余也就可以计算了。 四、赞助搜索拍卖 赞助搜索拍卖（Sponsored Search Auctions），是搜索引擎在广告栏的拍卖形式，把广告位卖给广告商。这里，搜索引擎的Page Rank算法就不提了，跟我们这个没什么关联，因为主要是哪些广告商竞标成功，以及他们要交多少钱，具体安排在哪个位置？ 简单的模型：对于某个关键词的搜索，有 个广告位，一般 ，这增大了难度；另一个，不同的广告位价值不一样，上面的那个一般点击率高于下面的，所以收费显然更高。 点击率（click-through-rate，CTRs） 代表用户在第 个广告位点击的概率，简单点我们假定 ，从上到下的顺序，然后不考虑广告内容对点击率的影响（反正这个锅得商家背，关搜索引擎P事）。 质量分数（quality score） ，是第 个广告商的广告的质量，越高越好。那么具体的点击率计算就是 ，与广告商和广告位都有关。我们需要满足上面三条性质，这个设计相对比较复杂，具体之后再提。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/netty/":{"url":"notes/netty/","title":"netty","keywords":"","body":" KStackNetty.md netty.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/netty/KStackNetty.html":{"url":"notes/netty/KStackNetty.html","title":"KStackNetty.md","keywords":"","body":" 一。基本概念 二。Netty 线程模型：EventLoop 1.Server&Client 工作流程图 一。基本概念 Channel：是个 facade，主要成员变量：java.nio.channels.Channel、Pipeline、Unsafe 及 EventLoop。 EventLoop：IO 操作执行线程，主要成员变量：java.nio.channels.Selector 和 Task-Queue。EventLoop 与 Channel 的数量关系是 1:N。 Pipeline & ChannelHandler：类似 j2ee 中 filter 机制，负责处理编解码及业务逻辑。Netty 把 ChannelHandler 封装为 ChannelHandlerContext 放在 Pipeline 的 head、tail 链表(正序链表、逆序链表)中;其中，IO 触发(eg:accept/read 等等)从 head 开始执行，用户发起 IO(eg:bind/connect/write 等)从 tail 开始执行。 Unsafe：非字面不安全意思，实际是指 Netty 的内部接口，不应该被外部直接调用。代理 Channel 中 IO 相关的操作。 Promise：相当于可设置结果的 Future。 ByteBuf：加强版的 ByteBuffer，支持自动扩容、Buffer 缓冲池等功能。 二。Netty 线程模型：EventLoop 1.Server&Client 工作流程图 Server new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/netty/netty.html":{"url":"notes/netty/netty.html","title":"netty.md","keywords":"","body":" CH1 CH2 CH3 EventLoop channelFuture ChennelHandler ChannelPipeline Netty in action 读书笔记 [TOC] CH1 CH2 CH3 netty的组件和设计。 Channel--Socket EventLoop--控制流，多线程处理 ChannelFuture--异步通知 EventLoop 一个EventLoopGroup包含一个或多个EventLoop 一个EventLoop在他的生命周期内只和一个Thread绑定 所有有EventLoop处理的I/O事件都将在他专有的Thread上被处理（消除了同步的需求） 一个channel在他的生命周期内只注册于一个EventLoop 一个EventLoop坑会被分配给一个或者多个channel channelFuture Netty中所有的I/O操作都是异步的。netty提供了ChannelFuture接口，其addListener（）方法注册了一个ChannelFutureListener，以便在某个操作完成时得到通知。 ChennelHandler 处理入站和出站数据的应用程序逻辑的容器 ChannelPipeline 提供了ChannelHandler链的容器，并定义了用于再改脸上传播入站和出站事件流的API。 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/":{"url":"notes/temp/","title":"temp","keywords":"","body":" BufferTrigger.md flink flink-demo.md gitbook gitbook.md hadoop jdk源码阅读.md mybatis日志模块与适配器模式.md mybatis源码阅读.md redis实现频次控制.md redis问题画像图待整理.md smart-framwork new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/BufferTrigger.html":{"url":"notes/temp/BufferTrigger.html","title":"BufferTrigger.md","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/flink/":{"url":"notes/temp/flink/","title":"flink","keywords":"","body":" 时间语义.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/flink/时间语义.html":{"url":"notes/temp/flink/时间语义.html","title":"时间语义.md","keywords":"","body":" 时间语义、Event Time和Watermark机制原理与实践 Flink的三种时间语义 Event Time Processing Time Ingestion Time 设置时间语义 Event Time和Watermark 分布式环境下Watermark的传播 抽取时间戳及生成Watermark Source 在Source之后通过TimestampAssigner设置 AssignerWithPeriodicWatermarks AssignerWithPunctuatedWatermarks 平衡延迟和准确性 [TOC] 时间语义、Event Time和Watermark机制原理与实践 在流处理中，时间是一个非常核心的概念，是整个系统的基石。比如，我们经常会遇到这样的需求：给定一个时间窗口，比如一个小时，统计时间窗口的内数据指标。那如何界定哪些数据将进入这个窗口呢？在窗口的定义之前，首先需要确定一个应用使用什么样的时间语义。 本文将介绍Flink的Event Time、Processing Time和Ingestion Time三种时间语义，接着会详细介绍Event Time和Watermark的工作机制，以及如何对数据流设置Event Time并生成Watermark。 Flink的三种时间语义 Event Time Event Time指的是数据流中每个元素或者每个事件自带的时间属性，一般是事件发生的时间。由于事件从发生到进入Flink时间算子之间有很多环节，一个较早发生的事件因为延迟可能较晚到达，因此使用Event Time意味着事件到达有可能是乱序的。 使用Event Time时，最理想的情况下，我们可以一直等待所有的事件到达后再进行时间窗口的处理。假设一个时间窗口内的所有数据都已经到达，基于Event Time的流处理会得到正确且一致的结果：无论我们是将同一个程序部署在不同的计算环境还是在相同的环境下多次计算同一份数据，都能够得到同样的计算结果。我们根本不同担心乱序到达的问题。但这只是理想情况，现实中无法实现，因为我们既不知道究竟要等多长时间才能确认所有事件都已经到达，更不可能无限地一直等待下去。在实际应用中，当涉及到对事件按照时间窗口进行统计时，Flink会将窗口内的事件缓存下来，直到接收到一个Watermark，以确认不会有更晚数据的到达。Watermark意味着在一个时间窗口下，Flink会等待一个有限的时间，这在一定程度上降低了计算结果的绝对准确性，而且增加了系统的延迟。在流处理领域，比起其他几种时间语义，使用Event Time的好处是某个事件的时间是确定的，这样能够保证计算结果在一定程度上的可预测性。 一个基于Event Time的Flink程序中必须定义Event Time，以及如何生成Watermark。我们可以使用元素中自带的时间，也可以在元素到达Flink后人为给Event Time赋值。 使用Event Time的优势是结果的可预测性，缺点是缓存较大，增加了延迟，且调试和定位问题更复杂。 Processing Time 对于某个算子来说，Processing Time指算子使用当前机器的系统时钟来定义时间。在Processing Time的时间窗口场景下，无论事件什么时候发生，只要该事件在某个时间段达到了某个算子，就会被归结到该窗口下，不需要Watermark机制。对于一个程序在同一个计算环境来说，每个算子都有一定的耗时，同一个事件的Processing Time，第n个算子和第n+1个算子不同。如果一个程序在不同的集群和环境下执行时，限于软硬件因素，不同环境下前序算子处理速度不同，对于下游算子来说，事件的Processing Time也会不同，不同环境下时间窗口的计算结果会发生变化。因此，Processing Time在时间窗口下的计算会有不确定性。 Processing Time只依赖当前执行机器的系统时钟，不需要依赖Watermark，无需缓存。Processing Time是实现起来非常简单也是延迟最小的一种时间语义。 Ingestion Time Ingestion Time是事件到达Flink Souce的时间。从Source到下游各个算子中间可能有很多计算环节，任何一个算子的处理速度快慢可能影响到下游算子的Processing Time。而Ingestion Time定义的是数据流最早进入Flink的时间，因此不会被算子处理速度影响。 Ingestion Time通常是Event Time和Processing Time之间的一个折中方案。比起Event Time，Ingestion Time可以不需要设置复杂的Watermark，因此也不需要太多缓存，延迟较低。比起Processing Time，Ingestion Time的时间是Souce赋值的，一个事件在整个处理过程从头至尾都使用这个时间，而且后续算子不受前序算子处理速度的影响，计算结果相对准确一些，但计算成本稍高。 设置时间语义 在Flink中，我们需要在执行环境层面设置使用哪种时间语义。下面的代码使用Event Time： env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime) 如果想用另外两种时间语义，需要替换为：TimeCharacteristic.ProcessingTime和TimeCharacteristic.IngestionTime。 Event Time和Watermark Flink的三种时间语义中，Processing Time和Ingestion Time都可以不用设置Watermark。如果我们要使用Event Time语义，以下两项配置缺一不可：第一，使用一个时间戳为数据流中每个事件的Event Time赋值；第二，生成Watermark。 实际上，Event Time是每个事件的元数据，Flink并不知道每个事件的发生时间是什么，我们必须要为每个事件的Event Time赋值一个时间戳。关于时间戳，包括Flink在内的绝大多数系统都支持Unix时间戳系统（Unix time或Unix epoch）。Unix时间戳系统以1970-01-01 00:00:00.000 为起始点，其他时间记为距离该起始时间的整数差值，一般是毫秒（millisecond）精度。 有了Event Time时间戳，我们还必须生成Watermark。Watermark是Flink插入到数据流中的一种特殊的数据结构，它包含一个时间戳，并假设后续不会有小于该时间戳的数据。下图展示了一个乱序数据流，其中方框是单个事件，方框中的数字是其对应的Event Time时间戳，圆圈为Watermark，圆圈中的数字为Watermark对应的时间戳。 Watermark的生成有以下几点需要注意： Watermark与事件的时间戳紧密相关。一个时间戳为T的Watermark假设后续到达的事件时间戳都大于T。 假如Flink算子接收到一个违背上述规则的事件，该事件将被认定为迟到数据，如上图中时间戳为19的事件比Watermark(20)更晚到达。Flink提供了一些其他机制来处理迟到数据。 Watermark时间戳必须单调递增，以保证时间不会倒流。 Watermark机制允许用户来控制准确度和延迟。Watermark设置得与事件时间戳相距紧凑，会产生不少迟到数据，影响计算结果的准确度，整个应用的延迟很低；Watermark设置得非常宽松，准确度能够得到提升，但应用的延迟较高，因为Flink必须等待更长的时间才进行计算。 分布式环境下Watermark的传播 在实际计算过程中，Flink的算子一般分布在多个并行的分区（或者称为实例）上，Flink需要将Watermark在并行环境下向前传播。如下图所示，Flink的每个并行算子子任务会维护针对该子任务的Event Time时钟，这个时钟记录了这个算子子任务Watermark处理进度，随着上游Watermark数据不断向下发送，算子子任务的Event Time时钟也要不断向前更新。由于上游各分区的处理速度不同，到达当前算子的Watermark也会有先后快慢之分，每个算子子任务会维护来自上游不同分区的Watermark信息，这是一个列表，列表内对应上游算子各分区的Watermark时间戳等信息。 当上游某分区有Watermark进入该算子子任务后，Flink先判断新流入的Watermark时间戳是否大于Partition Watermark列表内记录的该分区的历史Watermark时间戳，如果新流入的更大，则更新该分区的Watermark。例如，某个分区新流入的Watermark时间戳为4，算子子任务维护的该分区Watermark为1，那么Flink会更新Partition Watermark列表为最新的时间戳4。接着，Flink会遍历Partition Watermark列表中的所有时间戳，选择最小的一个作为该算子子任务的Event Time。同时，Flink会将更新的Event Time作为Watermark发送给下游所有算子子任务。算子子任务Event Time的更新意味着该子任务将时间推进到了这个时间，该时间之前的事件已经被处理并发送到下游。例如，图中第二步和第三步，Partition Watermark列表更新后，导致列表中最小时间戳发生了变化，算子子任务的Event Time时钟也相应进行了更新。整个过程完成了数据流中的Watermark推动算子子任务Watermark的时钟更新过程。Watermark像一个幕后推动者，不断将流处理系统的Event Time向前推进。我们可以将这种机制总结为： Flink某算子子任务根据各上游流入的Watermark来更新Partition Watermark列表。 选取Partition Watermark列表中最小的时间作为该算子的Event Time，并将这个时间发送给下游算子。 这样的设计机制满足了并行环境下Watermark在各算子中的传播问题，但是假如某个上游分区的Watermark一直不更新，Partition Watermark列表其他地方都在正常更新，唯独个别分区的时间停留在很早的某个时间，这会导致算子的Event Time时钟不更新，相应的时间窗口计算也不会被触发，大量的数据积压在算子内部得不到处理，整个流处理处于空转状态。这种问题可能出现在使用数据流自带的Watermark，自带的Watermark在某些分区下没有及时更新。针对这种问题，一种解决办法是根据机器当前的时钟周期性地生成Watermark。 此外，在union等多数据流处理时，Flink也使用上述Watermark更新机制，那就意味着，多个数据流的时间必须对齐，如果一方的Watermark时间较老，那整个应用的Event Time时钟也会使用这个较老的时间，其他数据流的数据会被积压。一旦发现某个数据流不再生成新的Watermark，我们要在SourceFunction中的SourceContext里调用markAsTemporarilyIdle设置该数据流为空闲状态。 抽取时间戳及生成Watermark 至此，我们已经了解了Flink的Event Time时间戳和Watermark机制的大致工作原理，接下来我们将展示如何在代码层面设置时间戳并生成Watermark。显然，对时间和Watermark的设置只对Event Time时间语义起作用，如果一个作业基于Processing Time或Ingestion Time，那时间的设置没有什么意义。因为时间在后续处理中都会用到，时间的设置要在任何时间窗口操作之前，总之，时间越早设置越好。Flink提供了以下方法设置时间戳和Watermark： Source 我们可以在Source阶段，通过自定义SourceFunction或RichSourceFunction，在SourceContext里重写void collectWithTimestamp(T element, long timestamp)和void emitWatermark(Watermark mark)两个方法，其中，collectWithTimestamp给数据流中的每个元素T赋值一个timestamp作为Event Time，emitWatermark生成Watermark。下面的代码展示了使用Scala调用这两个方法抽取时间戳并生成Watermark。 case class MyType(data: Double, eventTime: Long, hasWatermark:Boolean, watermarkTime: Long) class MySource extends RichSourceFunction[MyType] { override def run(ctx: SourceContext[MyType]): Unit = { while (/* condition */) { val next: MyType = getNext() ctx.collectWithTimestamp(next, next.eventTimestamp) if (next.hasWatermark) { ctx.emitWatermark(new Watermark(next.watermarkTime)) } } } } 复制代码 在Source之后通过TimestampAssigner设置 如果我们不想修改Source，也可以在Source之后，通过时间戳指定器（TimestampAssigner）来设置。TimestampAssigner是一个在DataStream[T]上调用的算子，它会给数据流生成时间戳和Watermark，但不改变数据流的类型T。比如，我们可以在Source之后，先过滤掉不需要的内容，然后设置时间戳和Watermark。下面的代码展示了使用TimestampAssigner的大致流程。 val env = StreamExecutionEnvironment.getExecutionEnvironment // 使用EventTime时间语义 env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime) val stream: DataStream[MyType] = env.addSource(...) // 先过滤不需要的内容，然后设置Timestamp和Watermark。 val withTimestampsAndWatermarks: DataStream[MyType] = stream .filter( item => \"ERROR\".equals(item.info) ) // 我们要实现一个MyTimestampsAndWatermarks，MyTimestampsAndWatermarks继承并实现了TimestampAssigner，告知Flink如何抽取时间戳并生成Watermark。 .assignTimestampsAndWatermarks(new MyTimestampsAndWatermarks()) withTimestampsAndWatermarks .keyBy(...) .timeWindow(Time.seconds(10)) .reduce( (a, b) => a.add(b) ) .addSink(...) 复制代码 MyTimestampsAndWatermarks需要继承并实现TimestampAssigner。TimestampAssigner是一个函数式接口类，它的源码如下： public interface TimestampAssigner extends Function { long extractTimestamp(T element, long previousElementTimestamp); } 复制代码 extractTimestamp方法为数据流中的每个元素T的Event Time赋值。 TimestampAssigner主要有两种实现方式，一种是周期性地（Periodic）生成Watermark，一种是逐个式地（Punctuated）生成Watermark。如果同时也在Source阶段设置了时间戳，那使用这种方式设置的时间戳和Watermark会将Source阶段的设置覆盖。 AssignerWithPeriodicWatermarks AssignerWithPeriodicWatermarks是一个继承了TimestampAssigner的接口类： public interface AssignerWithPeriodicWatermarks extends TimestampAssigner { Watermark getCurrentWatermark(); } 复制代码 它可以周期性地生成Watermark，其中，这个周期是可以设置的，默认情况下是每200毫秒生成一个Watermark，或者说Flink每200毫秒调用一次getCurrentWatermark方法。我们可以在执行环境中设置这个周期： // 每5000毫秒生成一个Watermark env.getConfig.setAutoWatermarkInterval(5000L) 复制代码 下面的代码具体实现了AssignerWithPeriodicWatermarks，它抽取元素中的第二个字段为Event Time，每次抽取完时间戳后，更新时间戳最大值，然后以时间戳最大值慢1分钟的时间作为Watermark发送出去。 input.assignTimestampsAndWatermarks(new MyPeriodicAssigner) // 假设数据流的元素有两个字段(String, Long)，其中第二个字段是该元素的时间戳 class MyPeriodicAssigner extends AssignerWithPeriodicWatermarks[(String, Long)] { val bound: Long = 60 * 1000 // 1分钟 var maxTs: Long = Long.MinValue // 已抽取的timestamp最大值 override def extractTimestamp(element: (String, Long), previousElementTimestamp: Long): Long = { // 更新maxTs为当前遇到的最大值 maxTs = maxTs.max(element._2) // 使用第二个字段作为这个元素的Event Time element._2 } override def getCurrentWatermark: Watermark = { // Watermark比Timestamp最大值慢1分钟 val watermark = new Watermark(maxTs - bound) watermark } } 复制代码 上面的代码假设了Watermark比已流入数据中时间戳最大者慢1分钟，超过1分钟的将被视为迟到数据。考虑到这种场景比较普遍，Flink已经帮我们封装好了这样的代码，名为BoundedOutOfOrdernessTimestampExtractor，其内部实现与上面的代码几乎一致，我们只需要将最大的延迟时间作为参数传入。 val boundedOutOfOrder = input.assignTimestampsAndWatermarks( new BoundedOutOfOrdernessTimestampExtractor[(String, Long)](Time.minutes(1)) { override def extractTimestamp(element: (String, Long)): Long = { element._2 } }) 复制代码 AssignerWithPunctuatedWatermarks public interface AssignerWithPunctuatedWatermarks extends TimestampAssigner { Watermark checkAndGetNextWatermark(T lastElement, long extractedTimestamp); } 复制代码 这种方式对数据流中的每个元素逐个进行检查，如果数据流的元素中有一些特殊标记，我们要在checkAndGetNextWatermark方法中加以判断，并生成Watermark。checkAndGetNextWatermark方法会在extractTimestamp方法之后调用。 // 数据流有三个字段 第二个字段是时间戳，第三个字段判断是否为Watermark的标记 class MyPunctuatedAssigner extends AssignerWithPunctuatedWatermarks[(String, Long, Boolean)] { override def extractTimestamp(element: (String, Long, Boolean), previousElementTimestamp: Long): Long = { element._2 } override def checkAndGetNextWatermark(element: (String, Long, Boolean), extractedTimestamp: Long): Watermark = { if (element._3) new Watermark(extractedTimestamp) else null } } 复制代码 上面的代码中，假设数据流有三个字段，第二个字段是Event Time时间戳，第三个字段标记是否是Watermark。checkAndGetNextWatermark对每个元素进行检查，判断是否需要生成新的Watermark。 平衡延迟和准确性 至此，我们已经了解了Flink的Event Time和Watermark生成方法，那么具体如何操作呢？实际上，这个问题可能并没有一个标准答案。批处理中，数据都已经准备好了，不需要考虑未来新流入的数据，而流处理中，我们无法完全预知有多少迟到数据，数据的流入依赖业务的场景、数据的输入、网络的传输、集群的性能等等。Watermark是一种在延迟和准确性之间平衡的策略：Watermark与事件的时间戳贴合较紧，一些重要数据将被当成迟到数据，影响计算结果的准确性；Watermark设置得较松，整个应用的延迟增加，更多的数据会先缓存起来以等待计算，会增加内存的压力。对待具体的业务场景，我们可能需要反复尝试，通过一些监控手段来不断迭代和调整时间策略。 作者：皮皮鲁的科技星球 链接：https://juejin.cn/post/6844904038727680008 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/flink-demo.html":{"url":"notes/temp/flink-demo.html","title":"flink-demo.md","keywords":"","body":" Flink学习 lambda架构 [TOC] Flink学习 看B战视频学习一下 https://www.bilibili.com/video/BV1qy4y1q728 lambda架构 new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/gitbook/":{"url":"notes/temp/gitbook/","title":"gitbook","keywords":"","body":" gitbook插件.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/gitbook/gitbook插件.html":{"url":"notes/temp/gitbook/gitbook插件.html","title":"gitbook插件.md","keywords":"","body":"作者：明月_ 链接：https://www.jianshu.com/p/427b8bb066e6 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/gitbook.html":{"url":"notes/temp/gitbook.html","title":"gitbook.md","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/hadoop/":{"url":"notes/temp/hadoop/","title":"hadoop","keywords":"","body":" 分布式文件系统和hadoop的由来.md new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"notes/temp/hadoop/分布式文件系统和hadoop的由来.html":{"url":"notes/temp/hadoop/分布式文件系统和hadoop的由来.html","title":"分布式文件系统和hadoop的由来.md","keywords":"","body":" 分布式文件系统 GlusterFS GFS HDFS [TOC] 分布式文件系统 GlusterFS GlusterFS 是由美国的 Gluster 公司开发的 POSIX 分布式文件系统（以 GPL 开源），2007 年发布第一个公开版本，2011 年被 Redhat 收购。 它的基本思路就是通过一个无状态的中间件把多个单机文件系统融合成统一的名字空间（namespace）提供给用户。这个中间件是由一系列可叠加的转换器（Translator）实现，每个转换器解决一个问题，比如数据分布、复制、拆分、缓存、锁等等，用户可以根据具体的应用场景需要灵活配置。 GFS Google 的 GFS 是分布式文件系统中的先驱和典型代表，由早期的 BigFiles 发展而来。在 2003 年发表的论文中详细阐述了它的设计理念和细节，对业界影响非常大，后来很多分布式文件系统都是参照它的设计。 顾名思义，BigFiles/GFS 是为大文件优化设计的，并不适合平均文件大小在 1MB 以内的场景。 GFS 的架构入下图所示。 GFS 有一个 Master 节点来管理元数据（全部加载到内存，快照和更新日志写到磁盘），文件划分成 64MB 的 Chunk 存储到几个 ChunkServer 上（直接使用单机文件系统）。文件只能追加写，不用担心 Chunk 的版本和一致性问题（可以用长度当做版本）。 这个使用完全不同的技术来解决元数据和数据的设计使得系统的复杂度大大简化，也有足够的扩展能力（如果平均文件大小大于 256MB，Master 节点每 GB 内存可以支撑约 1PB 的数据量）。放弃支持 POSIX 文件系统的部分功能（比如随机写、扩展属性、硬链接等）也进一步简化了系统复杂度，以换取更好的系统性能、鲁棒性和可扩展性。 因为 GFS 的成熟稳定，使得 Google 可以更容易地构建上层应用（MapReduce、BigTable 等）。后来，Google 开发了拥有更强可扩展能力的下一代存储系统 Colossus，把元数据和数据存储彻底分离，实现了元数据的分布式（自动 Sharding），以及使用 Reed Solomon 编码来降低存储空间占用从而降低成本。 HDFS 出自 Yahoo 的 Hadoop 算是 Google 的 GFS、MapReduce 等的开源 Java 实现版，HDFS 也是基本照搬 GFS 的设计，这里就不再重复了，下图是 HDFS 的架构图： HDFS 的可靠性和可扩展能力还是非常不错的，有不少几千节点和 100PB 级别的部署，支撑大数据应用表现还是很不错的，少有听说丢数据的案例（因为没有配置回收站导致数据被误删的除外）。 HDFS 的 HA 方案是后来补上的，做得比较复杂，以至于最早做这个 HA 方案的 Facebook 在很长一段时间（至少 3 年）内都是手动做故障切换（不信任自动故障切换）。 因为 NameNode 是 Java 实现的，依赖于预先分配的堆内存大小，分配不足容易触发 Full GC 而影响整个系统的性能。有一些团队尝试把它用 C++ 重写了，但还没看到有成熟的开源方案。 HDFS 也缺乏成熟的非 Java 客户端，使得大数据（Hadoop 等工具）以外的场景（比如深度学习等）使用起来不太方便。new Valine({el: \"#vcomments\",appId: 'TFSll9o8N2VjWuA0q0CXIBtk-gzGzoHsz',appKey: 'dnU9vjDuKzlEqzVJeIMbqVFX',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "}}